{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "> Functions to augment the user's dataset with information from official sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation as a transformer\n",
    "\n",
    "The package `scikit-learn` makes use of the concept of transformer, an object in python that adapts the transformation at hand to the training data, and then deploys it on the testing data. These transformers can be used as part of a pipeline.\n",
    "\n",
    "In order to ensure maximumm compatibility with packages that are widely used, `gingado`'s data augmentation function are implemented as an object that are funcional on their own, but also as a transformer as parte pines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import pandasdmx as sdmx\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "class ggdAugmentSDMX(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sources=['BIS', 'ECB', 'IMF', 'UNSD', 'WB'], variance_threshold=None, backend='memory'):\n",
    "        self.sources = sources\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.backend = backend\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        self.data_freq_ = X.index.to_series().diff().min().resolution_string\n",
    "        self.keys_ = {'FREQ': self.data_freq_}\n",
    "\n",
    "        self.params_ = {\"startPeriod\": min(X.index).year}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        data_sdmx = {}\n",
    "        for source in self.sources:\n",
    "            src_conn = sdmx.Request(source, backend=self.backend, expire_after=1800)\n",
    "            src_dflows = src_conn.dataflow()\n",
    "            dflows = {k: v for k, v in src_dflows.dataflow.items()}\n",
    "            for dflow in dflows.keys():\n",
    "                print(f\"Trying to download data from {source}'s dataflow {dflow}...\")\n",
    "                try:\n",
    "                    data = sdmx.to_pandas(src_conn.data(dflow, key=self.keys_, params=self.params_), datetime='TIME_PERIOD')\n",
    "                except:\n",
    "                    print(\"this dataflow does not have data in the desired frequency and time period.\")\n",
    "                    continue\n",
    "                data.columns = ['__'.join(col) for col in data.columns.to_flat_index()]\n",
    "                data_sdmx[source+\"__\"+dflow] = data\n",
    "\n",
    "        if len(data_sdmx.keys()) is None:\n",
    "            return X\n",
    "\n",
    "        df = pd.concat(data_sdmx, axis=1)\n",
    "        df.columns = ['_'.join(col) for col in df.columns.to_flat_index()]\n",
    "\n",
    "        feat_sel = VarianceThreshold() if self.variance_threshold is None else VarianceThreshold(threshold=self.variance_threshold)\n",
    "        feat_sel.fit(df)\n",
    "    \n",
    "        self.features_stay = df.columns[feat_sel.get_support()]\n",
    "        self.features_removed = df.columns[~feat_sel.get_support()]\n",
    "\n",
    "        df = df.iloc[:, feat_sel.get_support()]\n",
    "        df.dropna(axis=0, how='all', inplace=True)\n",
    "        df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "        self.augm_df_ = df\n",
    "        del(df)\n",
    "\n",
    "        X = pd.concat([X, self.augm_df_], axis=1, join='inner')\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ggdAugmentSDMX2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sources=['BIS', 'ECB', 'IMF', 'UNSD', 'WB'], variance_threshold=None, backend='memory'):\n",
    "        self.sources = sources\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.backend = backend\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.index_ = X.index if hasattr(X, \"index\") else None\n",
    "        self.data_freq_ = self.index_.to_series().diff().min().resolution_string\n",
    "        format_string = \"%Y-%m-%d\" if self.data_freq_ == 'D' else \"%Y-%m\" if self.data_freq_ == 'M' else \"%Y\"\n",
    "\n",
    "        X = self._validate_data(X)\n",
    "        \n",
    "        self.keys_ = {'FREQ': self.data_freq_}\n",
    "\n",
    "        self.params_ = {\n",
    "            \"startPeriod\": min(self.index_).strftime(format_string),\n",
    "            \"endPeriod\": max(self.index_).strftime(format_string),\n",
    "        }\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        data_sdmx = {}\n",
    "        for source in self.sources:\n",
    "            src_conn = sdmx.Request(source, backend=self.backend, expire_after=1800)\n",
    "            src_dflows = src_conn.dataflow()\n",
    "            dflows = {k: v for k, v in src_dflows.dataflow.items()}\n",
    "            for dflow in dflows.keys():\n",
    "                print(f\"Trying to download data from {source}'s dataflow {dflow}...\")\n",
    "                try:\n",
    "                    data = sdmx.to_pandas(src_conn.data(dflow, key=self.keys_, params=self.params_), datetime='TIME_PERIOD')\n",
    "                except:\n",
    "                    print(\"this dataflow does not have data in the desired frequency and time period.\")\n",
    "                    continue\n",
    "                data.columns = ['__'.join(col) for col in data.columns.to_flat_index()]\n",
    "                data_sdmx[source+\"__\"+dflow] = data\n",
    "\n",
    "        if len(data_sdmx.keys()) is None:\n",
    "            return X\n",
    "\n",
    "        df = pd.concat(data_sdmx, axis=1)\n",
    "        df.columns = ['_'.join(col) for col in df.columns.to_flat_index()]\n",
    "\n",
    "        feat_sel = VarianceThreshold() if self.variance_threshold is None else VarianceThreshold(threshold=self.variance_threshold)\n",
    "        feat_sel.fit(df)\n",
    "    \n",
    "        self.features_stay = df.columns[feat_sel.get_support()]\n",
    "        self.features_removed = df.columns[~feat_sel.get_support()]\n",
    "\n",
    "        df = df.iloc[:, feat_sel.get_support()]\n",
    "        df.dropna(axis=0, how='all', inplace=True)\n",
    "        df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "        self.augm_df_ = df\n",
    "        del(df)\n",
    "\n",
    "        X = pd.concat([X, self.augm_df_], axis=1, join='inner')\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ggdAugmentSDMX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, `gingado`'s transformers are built to be compatible with `scikit-learn`. The code below checks whether this is achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.utils import load_EURFX_data\n",
    "\n",
    "X = load_EURFX_data()\n",
    "y = X.pop('BRL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'startPeriod': '2003-01-02', 'endPeriod': '2022-05-20'}\n",
      "Trying to download data from ECB's dataflow AME...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow BKN...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow BLS...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow BNT...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow BOP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow BSI...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow BSP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow CBD...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow CBD2...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow CCP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow CISS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:04:54,856 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow CLIFS...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow CPP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow DCM...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow DD...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow EON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:05:33,653 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow ESA...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow ESB...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow EST...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow EXR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:06:12,601 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow FM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:09:55,295 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow FVC...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow FXI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:10:08,027 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow GST...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow ICB...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow ICO...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow ICP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow IFI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:10:57,771 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow ILM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:10:58,693 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow IRS...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow IVF...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow KRI...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow LIG...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow MFI...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow MIR...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow MMS...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow MMSR...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow MPD...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow OFI...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow PFB...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow PFBR...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow PSS...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RA...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RAI...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RDE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:11:23,622 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow RDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 06:11:36,976 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download data from ECB's dataflow RESC...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RESH...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RESR...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RESV...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RIR...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RPP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RPV...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow RTD...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SAFE...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SEC...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SEE...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SHI...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SHS...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SPF...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SSI...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SSP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SST...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow ST1...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow ST3...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow STP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow STS...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SUP...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow SUR...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow TGB...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow TRD...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow WTS...\n",
      "this dataflow does not have data in the desired frequency and time period.\n",
      "Trying to download data from ECB's dataflow YC...\n",
      "this dataflow does not have data in the desired frequency and time period.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUD</th>\n",
       "      <th>CAD</th>\n",
       "      <th>CHF</th>\n",
       "      <th>GBP</th>\n",
       "      <th>JPY</th>\n",
       "      <th>SGD</th>\n",
       "      <th>USD</th>\n",
       "      <th>ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX</th>\n",
       "      <th>ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX</th>\n",
       "      <th>ECB__CISS_D__CN__Z0Z__4F__EC__SS_CIN__IDX</th>\n",
       "      <th>...</th>\n",
       "      <th>ECB__RDE_D__D0__Z0Z__DE__EC__SRCB_COVAR__95P</th>\n",
       "      <th>ECB__RDE_D__D0__Z0Z__DE__EC__SRCB_COVAR__AVE</th>\n",
       "      <th>ECB__RDE_D__D0__Z0Z__DE__EC__SRCI_COVAR__5P</th>\n",
       "      <th>ECB__RDE_D__D0__Z0Z__DE__EC__SRCI_COVAR__95P</th>\n",
       "      <th>ECB__RDE_D__D0__Z0Z__DE__EC__SRCI_COVAR__AVE</th>\n",
       "      <th>ECB__RDF_D__D0__Z0Z__4F__EC__DFTLB__PR</th>\n",
       "      <th>ECB__RDF_D__U2__Z0Z__4F__EC__U2_CEB__HST</th>\n",
       "      <th>ECB__RDF_D__U2__Z0Z__4F__EC__U2_CI__HST</th>\n",
       "      <th>ECB__RDF_D__U2__Z0Z__4F__EC__U2_GRAI__HST</th>\n",
       "      <th>ECB__RDF_D__U2__Z0Z__4F__EC__U2_MM__HST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-02</th>\n",
       "      <td>1.8554</td>\n",
       "      <td>1.6422</td>\n",
       "      <td>1.4528</td>\n",
       "      <td>0.65200</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8188</td>\n",
       "      <td>1.0446</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>0.047823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>1.8440</td>\n",
       "      <td>1.6264</td>\n",
       "      <td>1.4555</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>124.56</td>\n",
       "      <td>1.8132</td>\n",
       "      <td>1.0392</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008989</td>\n",
       "      <td>-0.078866</td>\n",
       "      <td>-0.178504</td>\n",
       "      <td>-0.04966</td>\n",
       "      <td>-0.112854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>1.8281</td>\n",
       "      <td>1.6383</td>\n",
       "      <td>1.4563</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8210</td>\n",
       "      <td>1.0488</td>\n",
       "      <td>0.020801</td>\n",
       "      <td>0.039924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>1.8160</td>\n",
       "      <td>1.6257</td>\n",
       "      <td>1.4565</td>\n",
       "      <td>0.64960</td>\n",
       "      <td>124.82</td>\n",
       "      <td>1.8155</td>\n",
       "      <td>1.0425</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>1.8132</td>\n",
       "      <td>1.6231</td>\n",
       "      <td>1.4586</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1.8102</td>\n",
       "      <td>1.0377</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.040338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-16</th>\n",
       "      <td>1.5057</td>\n",
       "      <td>1.3473</td>\n",
       "      <td>1.0479</td>\n",
       "      <td>0.85045</td>\n",
       "      <td>135.01</td>\n",
       "      <td>1.4531</td>\n",
       "      <td>1.0422</td>\n",
       "      <td>0.284438</td>\n",
       "      <td>0.158944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-17</th>\n",
       "      <td>1.4993</td>\n",
       "      <td>1.3517</td>\n",
       "      <td>1.0457</td>\n",
       "      <td>0.84400</td>\n",
       "      <td>136.32</td>\n",
       "      <td>1.4589</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>0.303949</td>\n",
       "      <td>0.173353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18</th>\n",
       "      <td>1.4980</td>\n",
       "      <td>1.3488</td>\n",
       "      <td>1.0486</td>\n",
       "      <td>0.84670</td>\n",
       "      <td>135.76</td>\n",
       "      <td>1.4598</td>\n",
       "      <td>1.0523</td>\n",
       "      <td>0.307806</td>\n",
       "      <td>0.176587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-19</th>\n",
       "      <td>1.5036</td>\n",
       "      <td>1.3490</td>\n",
       "      <td>1.0265</td>\n",
       "      <td>0.84728</td>\n",
       "      <td>134.46</td>\n",
       "      <td>1.4576</td>\n",
       "      <td>1.0525</td>\n",
       "      <td>0.303497</td>\n",
       "      <td>0.192594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-20</th>\n",
       "      <td>1.4980</td>\n",
       "      <td>1.3526</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>0.84820</td>\n",
       "      <td>135.34</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>1.0577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4965 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AUD     CAD     CHF      GBP     JPY     SGD     USD  \\\n",
       "TIME_PERIOD                                                            \n",
       "2003-01-02   1.8554  1.6422  1.4528  0.65200  124.40  1.8188  1.0446   \n",
       "2003-01-03   1.8440  1.6264  1.4555  0.65000  124.56  1.8132  1.0392   \n",
       "2003-01-06   1.8281  1.6383  1.4563  0.64950  124.40  1.8210  1.0488   \n",
       "2003-01-07   1.8160  1.6257  1.4565  0.64960  124.82  1.8155  1.0425   \n",
       "2003-01-08   1.8132  1.6231  1.4586  0.64950  124.90  1.8102  1.0377   \n",
       "...             ...     ...     ...      ...     ...     ...     ...   \n",
       "2022-05-16   1.5057  1.3473  1.0479  0.85045  135.01  1.4531  1.0422   \n",
       "2022-05-17   1.4993  1.3517  1.0457  0.84400  136.32  1.4589  1.0541   \n",
       "2022-05-18   1.4980  1.3488  1.0486  0.84670  135.76  1.4598  1.0523   \n",
       "2022-05-19   1.5036  1.3490  1.0265  0.84728  134.46  1.4576  1.0525   \n",
       "2022-05-20   1.4980  1.3526  1.0280  0.84820  135.34  1.4588  1.0577   \n",
       "\n",
       "             ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX  \\\n",
       "TIME_PERIOD                                              \n",
       "2003-01-02                                    0.023427   \n",
       "2003-01-03                                    0.021899   \n",
       "2003-01-06                                    0.020801   \n",
       "2003-01-07                                    0.019738   \n",
       "2003-01-08                                    0.019947   \n",
       "...                                                ...   \n",
       "2022-05-16                                    0.284438   \n",
       "2022-05-17                                    0.303949   \n",
       "2022-05-18                                    0.307806   \n",
       "2022-05-19                                    0.303497   \n",
       "2022-05-20                                         NaN   \n",
       "\n",
       "             ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX  \\\n",
       "TIME_PERIOD                                              \n",
       "2003-01-02                                    0.047823   \n",
       "2003-01-03                                    0.043292   \n",
       "2003-01-06                                    0.039924   \n",
       "2003-01-07                                    0.038084   \n",
       "2003-01-08                                    0.040338   \n",
       "...                                                ...   \n",
       "2022-05-16                                    0.158944   \n",
       "2022-05-17                                    0.173353   \n",
       "2022-05-18                                    0.176587   \n",
       "2022-05-19                                    0.192594   \n",
       "2022-05-20                                         NaN   \n",
       "\n",
       "             ECB__CISS_D__CN__Z0Z__4F__EC__SS_CIN__IDX  ...  \\\n",
       "TIME_PERIOD                                             ...   \n",
       "2003-01-02                                         NaN  ...   \n",
       "2003-01-03                                         NaN  ...   \n",
       "2003-01-06                                         NaN  ...   \n",
       "2003-01-07                                         NaN  ...   \n",
       "2003-01-08                                         NaN  ...   \n",
       "...                                                ...  ...   \n",
       "2022-05-16                                         NaN  ...   \n",
       "2022-05-17                                         NaN  ...   \n",
       "2022-05-18                                         NaN  ...   \n",
       "2022-05-19                                         NaN  ...   \n",
       "2022-05-20                                         NaN  ...   \n",
       "\n",
       "             ECB__RDE_D__D0__Z0Z__DE__EC__SRCB_COVAR__95P  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-02                                            NaN   \n",
       "2003-01-03                                      -0.008989   \n",
       "2003-01-06                                            NaN   \n",
       "2003-01-07                                            NaN   \n",
       "2003-01-08                                            NaN   \n",
       "...                                                   ...   \n",
       "2022-05-16                                            NaN   \n",
       "2022-05-17                                            NaN   \n",
       "2022-05-18                                            NaN   \n",
       "2022-05-19                                            NaN   \n",
       "2022-05-20                                            NaN   \n",
       "\n",
       "             ECB__RDE_D__D0__Z0Z__DE__EC__SRCB_COVAR__AVE  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-02                                            NaN   \n",
       "2003-01-03                                      -0.078866   \n",
       "2003-01-06                                            NaN   \n",
       "2003-01-07                                            NaN   \n",
       "2003-01-08                                            NaN   \n",
       "...                                                   ...   \n",
       "2022-05-16                                            NaN   \n",
       "2022-05-17                                            NaN   \n",
       "2022-05-18                                            NaN   \n",
       "2022-05-19                                            NaN   \n",
       "2022-05-20                                            NaN   \n",
       "\n",
       "             ECB__RDE_D__D0__Z0Z__DE__EC__SRCI_COVAR__5P  \\\n",
       "TIME_PERIOD                                                \n",
       "2003-01-02                                           NaN   \n",
       "2003-01-03                                     -0.178504   \n",
       "2003-01-06                                           NaN   \n",
       "2003-01-07                                           NaN   \n",
       "2003-01-08                                           NaN   \n",
       "...                                                  ...   \n",
       "2022-05-16                                           NaN   \n",
       "2022-05-17                                           NaN   \n",
       "2022-05-18                                           NaN   \n",
       "2022-05-19                                           NaN   \n",
       "2022-05-20                                           NaN   \n",
       "\n",
       "             ECB__RDE_D__D0__Z0Z__DE__EC__SRCI_COVAR__95P  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-02                                            NaN   \n",
       "2003-01-03                                       -0.04966   \n",
       "2003-01-06                                            NaN   \n",
       "2003-01-07                                            NaN   \n",
       "2003-01-08                                            NaN   \n",
       "...                                                   ...   \n",
       "2022-05-16                                            NaN   \n",
       "2022-05-17                                            NaN   \n",
       "2022-05-18                                            NaN   \n",
       "2022-05-19                                            NaN   \n",
       "2022-05-20                                            NaN   \n",
       "\n",
       "             ECB__RDE_D__D0__Z0Z__DE__EC__SRCI_COVAR__AVE  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-02                                            NaN   \n",
       "2003-01-03                                      -0.112854   \n",
       "2003-01-06                                            NaN   \n",
       "2003-01-07                                            NaN   \n",
       "2003-01-08                                            NaN   \n",
       "...                                                   ...   \n",
       "2022-05-16                                            NaN   \n",
       "2022-05-17                                            NaN   \n",
       "2022-05-18                                            NaN   \n",
       "2022-05-19                                            NaN   \n",
       "2022-05-20                                            NaN   \n",
       "\n",
       "             ECB__RDF_D__D0__Z0Z__4F__EC__DFTLB__PR  \\\n",
       "TIME_PERIOD                                           \n",
       "2003-01-02                                      NaN   \n",
       "2003-01-03                                      NaN   \n",
       "2003-01-06                                      NaN   \n",
       "2003-01-07                                      NaN   \n",
       "2003-01-08                                      NaN   \n",
       "...                                             ...   \n",
       "2022-05-16                                      NaN   \n",
       "2022-05-17                                      NaN   \n",
       "2022-05-18                                      NaN   \n",
       "2022-05-19                                      NaN   \n",
       "2022-05-20                                      NaN   \n",
       "\n",
       "             ECB__RDF_D__U2__Z0Z__4F__EC__U2_CEB__HST  \\\n",
       "TIME_PERIOD                                             \n",
       "2003-01-02                                      -0.50   \n",
       "2003-01-03                                      -0.48   \n",
       "2003-01-06                                      -0.47   \n",
       "2003-01-07                                      -0.45   \n",
       "2003-01-08                                      -0.43   \n",
       "...                                               ...   \n",
       "2022-05-16                                        NaN   \n",
       "2022-05-17                                        NaN   \n",
       "2022-05-18                                        NaN   \n",
       "2022-05-19                                        NaN   \n",
       "2022-05-20                                        NaN   \n",
       "\n",
       "             ECB__RDF_D__U2__Z0Z__4F__EC__U2_CI__HST  \\\n",
       "TIME_PERIOD                                            \n",
       "2003-01-02                                     -0.42   \n",
       "2003-01-03                                     -0.40   \n",
       "2003-01-06                                     -0.36   \n",
       "2003-01-07                                     -0.34   \n",
       "2003-01-08                                     -0.30   \n",
       "...                                              ...   \n",
       "2022-05-16                                       NaN   \n",
       "2022-05-17                                       NaN   \n",
       "2022-05-18                                       NaN   \n",
       "2022-05-19                                       NaN   \n",
       "2022-05-20                                       NaN   \n",
       "\n",
       "             ECB__RDF_D__U2__Z0Z__4F__EC__U2_GRAI__HST  \\\n",
       "TIME_PERIOD                                              \n",
       "2003-01-02                                        1.17   \n",
       "2003-01-03                                        1.04   \n",
       "2003-01-06                                        0.78   \n",
       "2003-01-07                                        0.61   \n",
       "2003-01-08                                        0.90   \n",
       "...                                                ...   \n",
       "2022-05-16                                         NaN   \n",
       "2022-05-17                                         NaN   \n",
       "2022-05-18                                         NaN   \n",
       "2022-05-19                                         NaN   \n",
       "2022-05-20                                         NaN   \n",
       "\n",
       "             ECB__RDF_D__U2__Z0Z__4F__EC__U2_MM__HST  \n",
       "TIME_PERIOD                                           \n",
       "2003-01-02                                      0.08  \n",
       "2003-01-03                                      0.08  \n",
       "2003-01-06                                      0.11  \n",
       "2003-01-07                                      0.11  \n",
       "2003-01-08                                      0.13  \n",
       "...                                              ...  \n",
       "2022-05-16                                       NaN  \n",
       "2022-05-17                                       NaN  \n",
       "2022-05-18                                       NaN  \n",
       "2022-05-19                                       NaN  \n",
       "2022-05-20                                       NaN  \n",
       "\n",
       "[4965 rows x 182 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ggd2 = ggdAugmentSDMX2(sources=['ECB']).fit(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2003-01-02', '2003-01-03', '2003-01-06', '2003-01-07',\n",
       "               '2003-01-08', '2003-01-09', '2003-01-10', '2003-01-13',\n",
       "               '2003-01-14', '2003-01-15',\n",
       "               ...\n",
       "               '2022-05-09', '2022-05-10', '2022-05-11', '2022-05-12',\n",
       "               '2022-05-13', '2022-05-16', '2022-05-17', '2022-05-18',\n",
       "               '2022-05-19', '2022-05-20'],\n",
       "              dtype='datetime64[ns]', name='TIME_PERIOD', length=4965, freq=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augm_df = ggdAugmentSDMX(sources=['ECB']).fit_transform(EUR_FX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be part of a `Pipeline` object, which enables the use of grid search and other parameter search techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from gingado.augmentation import ggdAugmentSDMX\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('augmentation', ggdAugmentSDMX(sources=['ECB'])),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'augmentation__sources': (['ECB'], ['BIS']),\n",
    "    'regressor__n_estimators': ('100', '500')\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "grid_search.fit(X=X, y=y)\n",
    "\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall scheme:\n",
    "* Since sklearn `Pipeline` objects transform data into numpy arrays (and thus do not allow for things like looking at the index or title, etc), `gingado` will create a \"workflow\" object that:\n",
    "  * includes the data augmentation (useful to have pandas available!)\n",
    "  * the sklearn pipeline is a component that lies in the \"middle\" of the pipeline\n",
    "  * the documentation step benefits from the workflow retaining things like main dates, etc, so that it can also be used in the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions\n",
    "\n",
    "Most users will probably find it helpful to use the `DataAugment` transformer, which is compatible with `scikit-learn`, rather than the underlying functions. However, they are documented below in case their use might address some specific user need.\n",
    "\n",
    "## Sources of data\n",
    "\n",
    "`gingado` only lists official data sources by choice. This is meant to provide users with the trust that their dataset will be complemented by reliable sources. Unfortunately, it is not possible at this stage to include *all* official sources - let alone all reliable sources - because that requires substantial manual and maintenance work. `gingado` leverages the existence of the [Statistical Data and Metadata eXchange (SDMX)](https://sdmx.org), an organisation of official data sources that establishes common data and metadata formats, to download data that is relevant (and hopefully also useful) to users.\n",
    "\n",
    "The function below from the package [simpledmx](https://github.com/dkgaraujo/simpledmx) returns a list of codes corresponding to the data sources available to provide `gingado` users with data through SDMX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from simpledmx import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sdmx_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def augm_with_sdmx(df, freq, sources, variance_threshold=None):\n",
    "    \"\"\"Downloads relevant data from SDMX sources to complement the original dataset\n",
    "\n",
    "    Arguments:\n",
    "      df: a pandas DataFrame\n",
    "      freq: the frequency of the desired data from SDMX; for example, 'A' is annual\n",
    "      sources: the list of SDMX sources or None; a list of possible sources can be obtained by running the function list_sdmx_sources()    \n",
    "      variance_threshold: a value larger than or equal to 0 or None, where 0 will lead to the removal of all data that does not vary across the dataset and None uses the scikit-learn default\n",
    "    \"\"\"\n",
    "    start_date, end_date = min(df.index), max(df.index)\n",
    "        \n",
    "    sdmx_data = get_sdmx_data(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        freq=freq,\n",
    "        sources=sources\n",
    "        )\n",
    "    sdmx_data = sdmx_data.dropna(axis=1).sort_index()\n",
    "    sdmx_data.reset_index(inplace=True)\n",
    "    sdmx_data['TIME_PERIOD'] = pd.to_datetime(sdmx_data['TIME_PERIOD'])\n",
    "    sdmx_data.set_index('TIME_PERIOD', inplace=True)\n",
    "    \n",
    "    feat_sel = VarianceThreshold() if variance_threshold is None else VarianceThreshold(threshold=variance_threshold)\n",
    "    feat_sel.fit(sdmx_data)\n",
    "    \n",
    "    # TODO: log which features were not kept and why\n",
    "    sdmx_data = sdmx_data.iloc[:, feat_sel.get_support()]\n",
    "\n",
    "    #sdmx_data = feat_sel.fit_transform(sdmx_data)\n",
    "        \n",
    "    if df is None:\n",
    "        return sdmx_data\n",
    "    df = df.merge(sdmx_data, how='left', left_on=time_col, right_on='TIME_PERIOD')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(augm_with_sdmx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `gingado` to jumpstart a dataset\n",
    "\n",
    "Since `gingado` downloads data from official sources through SDMX, users may want to use this funcitonality to gather the dataset of interest instead of augmenting some previously existent data. In these cases, the argument `df` must be set to `None`, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = augm_with_sdmx(df=None, start_date='2018', end_date='2020', freq='A', time_col=None, sources='BIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses a greedy SDMX downloader that is not too concerned about selecting datasets in advance; rather, it downloads it data it possibly can from those official sources for the time period and frequency in question. It then filters out those data points that do not vary throughout the period, avoiding the use of memory to store data that does not contribute to the predictive power of the model. The dataset is then ready to be used.\n",
    "\n",
    "Two things are important to highlight. First, choosing even one source (the [BIS](www.bis.org) in this example) leads to the download of hundreds of variables. Some of them might be representing the same underlying concepts, but for different jurisdictions. The second thing to bear in mind is that download and in particular parsing of the SDMX data can take up some time depending on your local setting.\n",
    "\n",
    "To use `gingado` to augment your dataset instead of creating a completely new one as done above, simply pass the original DataFrame as the argument `df` and name the corresponding column with the time values in the argument `time_col`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv_gingado': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
