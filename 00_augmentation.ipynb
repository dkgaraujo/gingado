{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "> Functions to augment the user's dataset with information from official sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gingado` provides data augmentation functionalities that can help users to augment their datasets with a time series dimension. This can be done both on a stand-alone basis as the user incorporates new data on top of the original dataset, or as part of a `scikit-learn` [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that also includes other steps like data transformation and model estimation.\n",
    "\n",
    "## Data augmentation with SDMX\n",
    "\n",
    "The **S**tatistical **D**ata and **M**etadata e**X**change (SDMX) is an ISO standard comprising:\n",
    "* technical standards\n",
    "* statistical guidelines, including cross-domain concepts and codelists\n",
    "* an IT architecture and tools\n",
    "\n",
    "SDMX is sponsored by the Bank for International Settlements, European Central Bank, Eurostat, International Monetary Fund, Organisation for Economic Co-operation and Development, United Nations, and World Bank Group.\n",
    "\n",
    "More information about the SDMX is available on its [webpage](http://sdmx.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandas as pd\n",
    "import pandasdmx as sdmx\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "class AugmentSDMX(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    InputIndexMessage = \"The dataset to be augmented must have a row index with the date/time information\"\n",
    "    def _format_string(self):\n",
    "        return \"%Y-%m-%d\" if self.data_freq_ == 'D' else \"%Y-%m\" if self.data_freq_ == 'M' else \"%Y\"\n",
    "    \n",
    "    def _get_dates(self):\n",
    "        fstr = self._format_string()\n",
    "        return {\n",
    "            \"startPeriod\": min(self.index_).strftime(fstr),\n",
    "            \"endPeriod\": max(self.index_).strftime(fstr),\n",
    "        }\n",
    "\n",
    "    def _transform(self, X, training=True):\n",
    "        data_sdmx = {}\n",
    "        for source in self.sources.keys():\n",
    "            src_conn = sdmx.Request(source)\n",
    "            src_dflows = src_conn.dataflow()\n",
    "            if self.sources[source] == 'all':\n",
    "                dflows = {k: v for k, v in src_dflows.dataflow.items()}\n",
    "            else:\n",
    "                dflows = {k: v for k, v in src_dflows.dataflow.items() if k in self.sources[source]}\n",
    "            for dflow in dflows.keys():\n",
    "                if self.verbose: print(f\"Querying data from {source}'s dataflow '{dflow}' - {dflows[dflow].dict()['name']}...\")\n",
    "                try:\n",
    "                    data = sdmx.to_pandas(src_conn.data(dflow, key=self.keys_, params=self.params_), datetime='TIME_PERIOD')\n",
    "                except:\n",
    "                    if self.verbose: print(\"this dataflow does not have data in the desired frequency and time period.\")\n",
    "                    continue\n",
    "                data.columns = ['__'.join(col) for col in data.columns.to_flat_index()]\n",
    "                data_sdmx[source+\"__\"+dflow] = data\n",
    "        \n",
    "        if len(data_sdmx.keys()) is None:\n",
    "            return X\n",
    "\n",
    "        df = pd.concat(data_sdmx, axis=1)\n",
    "        df.columns = ['_'.join(col) for col in df.columns.to_flat_index()]\n",
    "\n",
    "        if training:\n",
    "            # test that the dataset `X` has the same dimension as the one\n",
    "            # used during training, which is an evidence they are the same\n",
    "            n_samples_in_transform, n_features_in_transform = X.shape\n",
    "            if n_samples_in_transform != self.n_samples_in_ or n_features_in_transform != self.n_features_in_:\n",
    "                raise ValueError(\"The X passed to the transform() method must be compatible with the X used by the fit() method.\")\n",
    "            # during testing, we don't want the possibility of a different\n",
    "            # set of columns being retained by virtue of different dynamics\n",
    "            # in both datasets. For example, if a feature is included in the\n",
    "            # training but during the test dates the variable didn't move, it\n",
    "            # should not be subject to the test below so that it is still\n",
    "            # included in the fitted data.\n",
    "            feat_sel = VarianceThreshold() if self.variance_threshold is None else VarianceThreshold(threshold=self.variance_threshold)\n",
    "            feat_sel.fit(df)\n",
    "            self.features_stay_ = df.columns[feat_sel.get_support()]\n",
    "            self.features_removed_ = df.columns[~feat_sel.get_support()]\n",
    "            \n",
    "            df = df.iloc[:, feat_sel.get_support()]\n",
    "            df.columns = feat_sel.get_feature_names_out()\n",
    "\n",
    "            df.dropna(axis=0, how='all', inplace=True)\n",
    "            df.dropna(axis=1, how='all', inplace=True)        \n",
    "\n",
    "        \n",
    "        X = pd.merge(left=X, right=df, how='left', left_index=True, right_on='TIME_PERIOD')\n",
    "        if 'TIME_PERIOD' in X.columns:\n",
    "            X.drop(columns='TIME_PERIOD', inplace=True)\n",
    "        if self.propagate_last_known_value:\n",
    "            X.fillna(method=\"ffill\", inplace=True)\n",
    "        if training:\n",
    "            X.index = self.index_\n",
    "        return X\n",
    "\n",
    "    def __init__(self, sources={'BIS': 'WS_CBPOL_D'}, variance_threshold=None, propagate_last_known_value=True, verbose=True):\n",
    "        self.sources = sources\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.propagate_last_known_value = propagate_last_known_value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fits transformer to `X`; `y` is kept as argument for API consistency only.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : a pandas Series or DataFrame with an index of datetime type\n",
    "            Input samples.\n",
    "        y : default=None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The fitted version of the instance of `AugmentSDMX`, ie after it learned \\\n",
    "        the frequency of the time series in `X`. The possible values fitted on the \\\n",
    "        data are described in: \\\n",
    "        https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timedelta.resolution_string.html.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data_freq_ = X.index.to_series().diff().min().resolution_string\n",
    "        except AttributeError:\n",
    "            print(self.InputIndexMessage)\n",
    "            raise\n",
    "        self.index_ = X.index\n",
    "        self.keys_ = {'FREQ': self.data_freq_}\n",
    "        X = self._validate_data(X)\n",
    "\n",
    "        # this variable below is only included to test for consistency \\\n",
    "        # if `fit` and `transform` are called separately with the same `X`\n",
    "        self.n_samples_in_ = X.shape[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, training=False):\n",
    "        check_is_fitted(self)\n",
    "        self.params_ = self._get_dates()\n",
    "        idx = X.index\n",
    "        transf_X = self._transform(X, training=training)\n",
    "        transf_X.index = idx\n",
    "        return transf_X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit to data, then transform it.\n",
    "        Fits transformer to `X` and returns a transformed version of `X`. \n",
    "        `y` is kept as argument for API consistency only.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : a pandas Series or DataFrame with an index of datetime type\n",
    "            Input samples.\n",
    "        y : default=None\n",
    "            Target values (None for unsupervised transformations).\n",
    "        training : True / False. default=False\n",
    "            The default value ensures that the when this transformer is called \\\n",
    "            by a pipeline\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : ndarray array of shape (n_samples, n_features_new)\n",
    "            Transformed array.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fit(X)\n",
    "        self.params_ = self._get_dates()\n",
    "        return self.transform(X, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"AugmentSDMX.fit\" class=\"doc_header\"><code>AugmentSDMX.fit</code><a href=\"__main__.py#L87\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>AugmentSDMX.fit</code>(**`X`**, **`y`**=*`None`*)\n",
       "\n",
       "Fits transformer to `X`; `y` is kept as argument for API consistency only.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X : a pandas Series or DataFrame with an index of datetime type\n",
       "    Input samples.\n",
       "y : default=None\n",
       "\n",
       "Returns\n",
       "-------\n",
       "The fitted version of the instance of [`AugmentSDMX`](/gingado/augmentation.html#AugmentSDMX), ie after it learned         the frequency of the time series in `X`. The possible values fitted on the         data are described in:         https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timedelta.resolution_string.html."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(AugmentSDMX.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, `gingado`'s transformers are built to be compatible with `scikit-learn`. The code below demonstrates this compatibility.\n",
    "\n",
    "First, we create the example dataset. In this case, it comprises the daily foreign exchange rate of selected currencies to the Euro. The Brazilian Real (BRL) is chosen for this example as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.utils import load_EURFX_data\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X = load_EURFX_data(keep_contemporaneous_X=True)\n",
    "y = X.pop('BRL')\n",
    "# retain only the lagged variables\n",
    "X = X[X.columns[X.columns.str.contains('_lag_')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4968, 8), (4968,), (1, 8), (1,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = X.iloc[:-1], X.tail(1)\n",
    "y_train, y_test = y.iloc[:-1], y.tail(1)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data augmentation object provided by `gingado` adds more data. In this case, for brevity only one dataflow from one source is listed. If users want to add more SDMX sources, simply add more keys to the dictionary. And if users want data from all dataflows from a given source (provided the keys and parameters such as frequency and dates are matched), the value should be set to `'all'`, as in `{'ECB': ['CISS'], 'BIS': 'all'}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:07:13,775 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from BIS's dataflow 'WS_CBPOL_D' - Policy rates daily...\n",
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:08:49,632 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from BIS's dataflow 'WS_CBPOL_D' - Policy rates daily...\n"
     ]
    }
   ],
   "source": [
    "from gingado.augmentation import AugmentSDMX\n",
    "\n",
    "test_src = {'ECB': ['CISS'], 'BIS': ['WS_CBPOL_D']}\n",
    "\n",
    "X_train__fit_transform = AugmentSDMX(sources=test_src).fit_transform(X=X_train)\n",
    "X_train__fit_then_transform = AugmentSDMX(sources=test_src).fit(X=X_train).transform(X=X_train, training=True)\n",
    "\n",
    "assert X_train__fit_transform.shape == X_train__fit_then_transform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AugmentSDMX` can also be part of a `Pipeline` object, which minimises operational errors during modelling and avoids using testing data during training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the dataset now after this particular augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of columns: 68 Index(['AUD_lag_1', 'BRL_lag_1', 'CAD_lag_1', 'CHF_lag_1', 'GBP_lag_1',\n",
      "       'JPY_lag_1', 'SGD_lag_1', 'USD_lag_1',\n",
      "       'ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__CN__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__DE__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__ES__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__FI__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__FR__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__GB__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__IE__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__IT__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__NL__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__PT__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_BM__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_CI__IDX',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_CO__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_EM__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_FI__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_FX__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_MM__CON',\n",
      "       'ECB__CISS_D__US__Z0Z__4F__EC__SS_CI__IDX',\n",
      "       'ECB__CISS_D__US__Z0Z__4F__EC__SS_CIN__IDX', 'BIS__WS_CBPOL_D_D__AR',\n",
      "       'BIS__WS_CBPOL_D_D__AU', 'BIS__WS_CBPOL_D_D__BR',\n",
      "       'BIS__WS_CBPOL_D_D__CA', 'BIS__WS_CBPOL_D_D__CH',\n",
      "       'BIS__WS_CBPOL_D_D__CL', 'BIS__WS_CBPOL_D_D__CN',\n",
      "       'BIS__WS_CBPOL_D_D__CO', 'BIS__WS_CBPOL_D_D__CZ',\n",
      "       'BIS__WS_CBPOL_D_D__DK', 'BIS__WS_CBPOL_D_D__GB',\n",
      "       'BIS__WS_CBPOL_D_D__HK', 'BIS__WS_CBPOL_D_D__HR',\n",
      "       'BIS__WS_CBPOL_D_D__HU', 'BIS__WS_CBPOL_D_D__ID',\n",
      "       'BIS__WS_CBPOL_D_D__IL', 'BIS__WS_CBPOL_D_D__IN',\n",
      "       'BIS__WS_CBPOL_D_D__IS', 'BIS__WS_CBPOL_D_D__JP',\n",
      "       'BIS__WS_CBPOL_D_D__KR', 'BIS__WS_CBPOL_D_D__MK',\n",
      "       'BIS__WS_CBPOL_D_D__MX', 'BIS__WS_CBPOL_D_D__MY',\n",
      "       'BIS__WS_CBPOL_D_D__NO', 'BIS__WS_CBPOL_D_D__NZ',\n",
      "       'BIS__WS_CBPOL_D_D__PE', 'BIS__WS_CBPOL_D_D__PH',\n",
      "       'BIS__WS_CBPOL_D_D__PL', 'BIS__WS_CBPOL_D_D__RO',\n",
      "       'BIS__WS_CBPOL_D_D__RS', 'BIS__WS_CBPOL_D_D__RU',\n",
      "       'BIS__WS_CBPOL_D_D__SA', 'BIS__WS_CBPOL_D_D__SE',\n",
      "       'BIS__WS_CBPOL_D_D__TH', 'BIS__WS_CBPOL_D_D__TR',\n",
      "       'BIS__WS_CBPOL_D_D__US', 'BIS__WS_CBPOL_D_D__XM',\n",
      "       'BIS__WS_CBPOL_D_D__ZA'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUD_lag_1</th>\n",
       "      <th>BRL_lag_1</th>\n",
       "      <th>CAD_lag_1</th>\n",
       "      <th>CHF_lag_1</th>\n",
       "      <th>GBP_lag_1</th>\n",
       "      <th>JPY_lag_1</th>\n",
       "      <th>SGD_lag_1</th>\n",
       "      <th>USD_lag_1</th>\n",
       "      <th>ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX</th>\n",
       "      <th>ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX</th>\n",
       "      <th>...</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__RO</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__RS</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__RU</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__SA</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__SE</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__TH</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__TR</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__US</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__XM</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__ZA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>1.8554</td>\n",
       "      <td>3.6770</td>\n",
       "      <td>1.6422</td>\n",
       "      <td>1.4528</td>\n",
       "      <td>0.65200</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8188</td>\n",
       "      <td>1.0446</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>1.8440</td>\n",
       "      <td>3.6112</td>\n",
       "      <td>1.6264</td>\n",
       "      <td>1.4555</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>124.56</td>\n",
       "      <td>1.8132</td>\n",
       "      <td>1.0392</td>\n",
       "      <td>0.020801</td>\n",
       "      <td>0.039924</td>\n",
       "      <td>...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>1.8281</td>\n",
       "      <td>3.5145</td>\n",
       "      <td>1.6383</td>\n",
       "      <td>1.4563</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8210</td>\n",
       "      <td>1.0488</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>1.8160</td>\n",
       "      <td>3.5139</td>\n",
       "      <td>1.6257</td>\n",
       "      <td>1.4565</td>\n",
       "      <td>0.64960</td>\n",
       "      <td>124.82</td>\n",
       "      <td>1.8155</td>\n",
       "      <td>1.0425</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.040338</td>\n",
       "      <td>...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-09</th>\n",
       "      <td>1.8132</td>\n",
       "      <td>3.4405</td>\n",
       "      <td>1.6231</td>\n",
       "      <td>1.4586</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1.8102</td>\n",
       "      <td>1.0377</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.040535</td>\n",
       "      <td>...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-20</th>\n",
       "      <td>1.5036</td>\n",
       "      <td>5.2094</td>\n",
       "      <td>1.3490</td>\n",
       "      <td>1.0265</td>\n",
       "      <td>0.84728</td>\n",
       "      <td>134.46</td>\n",
       "      <td>1.4576</td>\n",
       "      <td>1.0525</td>\n",
       "      <td>0.288026</td>\n",
       "      <td>0.189337</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23</th>\n",
       "      <td>1.4980</td>\n",
       "      <td>5.1989</td>\n",
       "      <td>1.3526</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>0.84820</td>\n",
       "      <td>135.34</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>1.0577</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.182845</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-24</th>\n",
       "      <td>1.4982</td>\n",
       "      <td>5.1623</td>\n",
       "      <td>1.3626</td>\n",
       "      <td>1.0310</td>\n",
       "      <td>0.84783</td>\n",
       "      <td>136.05</td>\n",
       "      <td>1.4639</td>\n",
       "      <td>1.0659</td>\n",
       "      <td>0.269618</td>\n",
       "      <td>0.200358</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>1.5152</td>\n",
       "      <td>5.1793</td>\n",
       "      <td>1.3714</td>\n",
       "      <td>1.0334</td>\n",
       "      <td>0.85750</td>\n",
       "      <td>136.49</td>\n",
       "      <td>1.4722</td>\n",
       "      <td>1.0720</td>\n",
       "      <td>0.264483</td>\n",
       "      <td>0.204047</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-26</th>\n",
       "      <td>1.5126</td>\n",
       "      <td>5.1736</td>\n",
       "      <td>1.3720</td>\n",
       "      <td>1.0269</td>\n",
       "      <td>0.85295</td>\n",
       "      <td>135.34</td>\n",
       "      <td>1.4676</td>\n",
       "      <td>1.0656</td>\n",
       "      <td>0.250493</td>\n",
       "      <td>0.198205</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4968 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUD_lag_1  BRL_lag_1  CAD_lag_1  CHF_lag_1  GBP_lag_1  JPY_lag_1  \\\n",
       "TIME_PERIOD                                                                     \n",
       "2003-01-03      1.8554     3.6770     1.6422     1.4528    0.65200     124.40   \n",
       "2003-01-06      1.8440     3.6112     1.6264     1.4555    0.65000     124.56   \n",
       "2003-01-07      1.8281     3.5145     1.6383     1.4563    0.64950     124.40   \n",
       "2003-01-08      1.8160     3.5139     1.6257     1.4565    0.64960     124.82   \n",
       "2003-01-09      1.8132     3.4405     1.6231     1.4586    0.64950     124.90   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "2022-05-20      1.5036     5.2094     1.3490     1.0265    0.84728     134.46   \n",
       "2022-05-23      1.4980     5.1989     1.3526     1.0280    0.84820     135.34   \n",
       "2022-05-24      1.4982     5.1623     1.3626     1.0310    0.84783     136.05   \n",
       "2022-05-25      1.5152     5.1793     1.3714     1.0334    0.85750     136.49   \n",
       "2022-05-26      1.5126     5.1736     1.3720     1.0269    0.85295     135.34   \n",
       "\n",
       "             SGD_lag_1  USD_lag_1  ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX  \\\n",
       "TIME_PERIOD                                                                    \n",
       "2003-01-03      1.8188     1.0446                                   0.021899   \n",
       "2003-01-06      1.8132     1.0392                                   0.020801   \n",
       "2003-01-07      1.8210     1.0488                                   0.019738   \n",
       "2003-01-08      1.8155     1.0425                                   0.019947   \n",
       "2003-01-09      1.8102     1.0377                                   0.017026   \n",
       "...                ...        ...                                        ...   \n",
       "2022-05-20      1.4576     1.0525                                   0.288026   \n",
       "2022-05-23      1.4588     1.0577                                   0.267919   \n",
       "2022-05-24      1.4639     1.0659                                   0.269618   \n",
       "2022-05-25      1.4722     1.0720                                   0.264483   \n",
       "2022-05-26      1.4676     1.0656                                   0.250493   \n",
       "\n",
       "             ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX  ...  \\\n",
       "TIME_PERIOD                                             ...   \n",
       "2003-01-03                                    0.043292  ...   \n",
       "2003-01-06                                    0.039924  ...   \n",
       "2003-01-07                                    0.038084  ...   \n",
       "2003-01-08                                    0.040338  ...   \n",
       "2003-01-09                                    0.040535  ...   \n",
       "...                                                ...  ...   \n",
       "2022-05-20                                    0.189337  ...   \n",
       "2022-05-23                                    0.182845  ...   \n",
       "2022-05-24                                    0.200358  ...   \n",
       "2022-05-25                                    0.204047  ...   \n",
       "2022-05-26                                    0.198205  ...   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__RO  BIS__WS_CBPOL_D_D__RS  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-03                     NaN                    9.5   \n",
       "2003-01-06                   19.75                    9.5   \n",
       "2003-01-07                   19.75                    9.5   \n",
       "2003-01-08                   19.75                    9.5   \n",
       "2003-01-09                   19.75                    9.5   \n",
       "...                            ...                    ...   \n",
       "2022-05-20                    3.75                    2.0   \n",
       "2022-05-23                    3.75                    2.0   \n",
       "2022-05-24                    3.75                    2.0   \n",
       "2022-05-25                    3.75                    2.0   \n",
       "2022-05-26                    3.75                    2.0   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__RU  BIS__WS_CBPOL_D_D__SA  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-03                     NaN                    NaN   \n",
       "2003-01-06                     NaN                   2.00   \n",
       "2003-01-07                     NaN                   2.00   \n",
       "2003-01-08                    21.0                   2.00   \n",
       "2003-01-09                    21.0                   2.00   \n",
       "...                            ...                    ...   \n",
       "2022-05-20                    14.0                   1.75   \n",
       "2022-05-23                    14.0                   1.75   \n",
       "2022-05-24                    14.0                   1.75   \n",
       "2022-05-25                    14.0                   1.75   \n",
       "2022-05-26                    14.0                   1.75   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__SE  BIS__WS_CBPOL_D_D__TH  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-03                    3.75                   1.75   \n",
       "2003-01-06                    3.75                   1.75   \n",
       "2003-01-07                    3.75                   1.75   \n",
       "2003-01-08                    3.75                   1.75   \n",
       "2003-01-09                    3.75                   1.75   \n",
       "...                            ...                    ...   \n",
       "2022-05-20                    0.25                   0.50   \n",
       "2022-05-23                    0.25                   0.50   \n",
       "2022-05-24                    0.25                   0.50   \n",
       "2022-05-25                    0.25                   0.50   \n",
       "2022-05-26                    0.25                   0.50   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__TR  BIS__WS_CBPOL_D_D__US  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-03                    44.0                  1.250   \n",
       "2003-01-06                    44.0                  1.250   \n",
       "2003-01-07                    44.0                  1.250   \n",
       "2003-01-08                    44.0                  1.250   \n",
       "2003-01-09                    44.0                  1.250   \n",
       "...                            ...                    ...   \n",
       "2022-05-20                    14.0                  0.875   \n",
       "2022-05-23                    14.0                  0.875   \n",
       "2022-05-24                    14.0                  0.875   \n",
       "2022-05-25                    14.0                  0.875   \n",
       "2022-05-26                    14.0                  0.875   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__XM  BIS__WS_CBPOL_D_D__ZA  \n",
       "TIME_PERIOD                                                \n",
       "2003-01-03                    2.75                  13.50  \n",
       "2003-01-06                    2.75                  13.50  \n",
       "2003-01-07                    2.75                  13.50  \n",
       "2003-01-08                    2.75                  13.50  \n",
       "2003-01-09                    2.75                  13.50  \n",
       "...                            ...                    ...  \n",
       "2022-05-20                    0.00                   4.75  \n",
       "2022-05-23                    0.00                   4.75  \n",
       "2022-05-24                    0.00                   4.75  \n",
       "2022-05-25                    0.00                   4.75  \n",
       "2022-05-26                    0.00                   4.75  \n",
       "\n",
       "[4968 rows x 68 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"No of columns: {len(X_train__fit_transform.columns)} {X_train__fit_transform.columns}\")\n",
    "X_train__fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.augmentation import AugmentSDMX\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('augmentation', AugmentSDMX(sources={'BIS': 'WS_CBPOL_D'})),\n",
    "    ('imp', IterativeImputer(max_iter=10)),\n",
    "    ('forest', RandomForestRegressor())\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since `AugmentSDMX` can be included in a `Pipeline`, it can also be fine-tuned by parameter search techniques (such as grid search), further helping users make the best of available data to enhance performance of their models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   0.3s\n",
      "[CV 1/5] END ..........augmentation=passthrough;, score=0.484 total time=   0.4s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   0.6s\n",
      "[CV 2/5] END ..........augmentation=passthrough;, score=0.437 total time=   0.6s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   0.9s\n",
      "[CV 3/5] END ..........augmentation=passthrough;, score=0.910 total time=   1.0s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   1.3s\n",
      "[CV 4/5] END ..........augmentation=passthrough;, score=0.947 total time=   1.3s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   1.7s\n",
      "[CV 5/5] END .........augmentation=passthrough;, score=-0.990 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:10:58,142 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   9.8s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:11:08,678 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV 1/5] END augmentation=AugmentSDMX(sources={'ECB': 'CISS'});, score=0.557 total time=  15.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:11:13,330 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   8.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.2s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:11:23,149 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV 2/5] END augmentation=AugmentSDMX(sources={'ECB': 'CISS'});, score=0.369 total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:11:32,241 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=  13.1s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.2s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   2.8s\n",
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:11:48,452 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END augmentation=AugmentSDMX(sources={'ECB': 'CISS'});, score=0.916 total time=  30.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:12:02,257 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=  18.1s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.3s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:12:24,799 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV 4/5] END augmentation=AugmentSDMX(sources={'ECB': 'CISS'});, score=0.928 total time=  40.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:12:43,088 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=  22.5s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.3s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 01:13:11,231 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV 5/5] END augmentation=AugmentSDMX(sources={'ECB': 'CISS'});, score=-1.438 total time=  50.3s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   1.9s\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid={'augmentation': ['passthrough', AugmentSDMX(sources={'ECB': 'CISS'})]},\n",
    "    verbose=3,\n",
    "    cv=TimeSeriesSplit()\n",
    "    )\n",
    "\n",
    "y_pred_grid = grid.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'augmentation': 'passthrough'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last value in the training dataset was [5.1741]. The predicted value was [5.181137], and the actual value was [5.0959].\n"
     ]
    }
   ],
   "source": [
    "print(f\"The last value in the training dataset was {y_train.tail(1).to_numpy()}. The predicted value was {y_pred_grid}, and the actual value was {y_test.to_numpy()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of data\n",
    "\n",
    "`gingado` seeks to only lists realiable data sources by choice, with a focus on official sources. This is meant to provide users with the trust that their dataset will be complemented by reliable sources. Unfortunately, it is not possible at this stage to include *all* official sources given the substantial manual and maintenance work. `gingado` leverages the existence of the [Statistical Data and Metadata eXchange (SDMX)](https://sdmx.org), an organisation of official data sources that establishes common data and metadata formats, to download data that is relevant (and hopefully also useful) to users.\n",
    "\n",
    "The function below from the package [simpledmx](https://github.com/dkgaraujo/simpledmx) returns a list of codes corresponding to the data sources available to provide `gingado` users with data through SDMX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABS',\n",
       " 'ABS_XML',\n",
       " 'BBK',\n",
       " 'BIS',\n",
       " 'CD2030',\n",
       " 'ECB',\n",
       " 'ESTAT',\n",
       " 'ILO',\n",
       " 'IMF',\n",
       " 'INEGI',\n",
       " 'INSEE',\n",
       " 'ISTAT',\n",
       " 'LSD',\n",
       " 'NB',\n",
       " 'NBB',\n",
       " 'OECD',\n",
       " 'SGR',\n",
       " 'SPC',\n",
       " 'STAT_EE',\n",
       " 'UNICEF',\n",
       " 'UNSD',\n",
       " 'WB',\n",
       " 'WB_WDI']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandasdmx as sdmx\n",
    "sdmx.list_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv_gingado': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
