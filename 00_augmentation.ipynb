{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "description: Functions to augment the user's dataset with information from official\n",
    "  sources.\n",
    "output-file: augmentation.html\n",
    "title: Data augmentation\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| echo: false\n",
    "! [ -e /content ] && pip install -Uqq gingado nbdev # install or upgrade gingado on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp augmentation\n",
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| echo: false\n",
    "\n",
    "# Code below included to ensure compatibility with scikit-learn v1.1.x\n",
    "from sklearn import set_config\n",
    "set_config(display='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gingado` provides data augmentation functionalities that can help users to augment their datasets with a time series dimension. This can be done both on a stand-alone basis as the user incorporates new data on top of the original dataset, or as part of a `scikit-learn` [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that also includes other steps like data transformation and model estimation.\n",
    "\n",
    "## Data augmentation with SDMX\n",
    "\n",
    "The **S**tatistical **D**ata and **M**etadata e**X**change (SDMX) is an ISO standard comprising:\n",
    "\n",
    "* technical standards\n",
    "\n",
    "* statistical guidelines, including cross-domain concepts and codelists\n",
    "\n",
    "* an IT architecture and tools\n",
    "\n",
    "SDMX is sponsored by the Bank for International Settlements, European Central Bank, Eurostat, International Monetary Fund, Organisation for Economic Co-operation and Development, United Nations, and World Bank Group.\n",
    "\n",
    "More information about the SDMX is available on its [webpage](http://sdmx.org).\n",
    "\n",
    "`gingado` uses SDMX to augment user datasets through the transformer `AugmentSDMX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "\n",
    "from gingado.utils import load_SDMX_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasdmx as sdmx\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "class AugmentSDMX(BaseEstimator, TransformerMixin):\n",
    "    \"A transformer that augments a dataset using SDMX\"\n",
    "    \n",
    "    InputIndexMessage = \"The dataset to be augmented must have a row index with the date/time information\"\n",
    "    def _format_string(self):\n",
    "        return \"%Y-%m-%d\" if self.data_freq_ == 'D' else \"%Y-%m\" if self.data_freq_ == 'M' else \"%Y\"\n",
    "    \n",
    "    def _get_dates(self):\n",
    "        fstr = self._format_string()\n",
    "        return {\n",
    "            \"startPeriod\": min(self.index_).strftime(fstr),\n",
    "            \"endPeriod\": max(self.index_).strftime(fstr),\n",
    "        }\n",
    "\n",
    "    def _transform(self, X, training=True):\n",
    "        df = load_SDMX_data(sources=self.sources, keys=self.keys_, params=self.params_, verbose=self.verbose)\n",
    "        if df is None:\n",
    "            return X\n",
    "\n",
    "        if training:\n",
    "            # test that the dataset `X` has the same dimension as the one\n",
    "            # used during training, which is an evidence they are the same\n",
    "            n_samples_in_transform, n_features_in_transform = X.shape\n",
    "            if n_samples_in_transform != self.n_samples_in_ or n_features_in_transform != self.n_features_in_:\n",
    "                raise ValueError(\"The X passed to the transform() method must be compatible with the X used by the fit() method.\")\n",
    "            # during testing, we don't want the possibility of a different\n",
    "            # set of columns being retained by virtue of different dynamics\n",
    "            # in both datasets. For example, if a feature is included in the\n",
    "            # training but during the test dates the variable didn't move, it\n",
    "            # should not be subject to the test below so that it is still\n",
    "            # included in the fitted data.\n",
    "            feat_sel = VarianceThreshold() if self.variance_threshold is None else VarianceThreshold(threshold=self.variance_threshold)\n",
    "            feat_sel.fit(df)\n",
    "            self.features_stay_ = df.columns[feat_sel.get_support()]\n",
    "            self.features_removed_ = df.columns[~feat_sel.get_support()]\n",
    "            \n",
    "            df = df.iloc[:, feat_sel.get_support()]\n",
    "            df.columns = feat_sel.get_feature_names_out()\n",
    "\n",
    "            df.dropna(axis=0, how='all', inplace=True)\n",
    "            df.dropna(axis=1, how='all', inplace=True)        \n",
    "        \n",
    "        X = pd.merge(left=X, right=df, how='left', left_index=True, right_on='TIME_PERIOD')\n",
    "        if 'TIME_PERIOD' in X.columns:\n",
    "            X.drop(columns='TIME_PERIOD', inplace=True)\n",
    "        if self.propagate_last_known_value:\n",
    "            X.fillna(method=\"ffill\", inplace=True)\n",
    "        if self.fillna is not None:\n",
    "            X.fillna(self.fillna)\n",
    "        if training:\n",
    "            X.index = self.index_\n",
    "        return X\n",
    "\n",
    "    def __init__(self, sources={'BIS': 'WS_CBPOL_D'}, variance_threshold=None, propagate_last_known_value=True, fillna = 0, verbose=True):\n",
    "        self.sources = sources\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.propagate_last_known_value = propagate_last_known_value\n",
    "        self.fillna = fillna\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            X, # a pandas Series or DataFrame with an index of datetime type\n",
    "            y:None=None # `y` is kept as argument for API consistency only\n",
    "        ): # A fitted version of the same AugmentSDMX instance\n",
    "        # Fits instance of AugmentSDMX to `X`, learning its time series frequency\n",
    "        \n",
    "        try:\n",
    "            self.data_freq_ = X.index.to_series().diff().min().resolution_string\n",
    "        except AttributeError:\n",
    "            print(self.InputIndexMessage)\n",
    "            raise\n",
    "        self.index_ = X.index\n",
    "        self.keys_ = {'FREQ': self.data_freq_}\n",
    "        X = self._validate_data(X)\n",
    "\n",
    "        # this variable below is only included to test for consistency \\\n",
    "        # if `fit` and `transform` are called separately with the same `X`\n",
    "        self.n_samples_in_ = X.shape[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "            self,\n",
    "            X, # a pandas Series or DataFrame with an index of datetime type\n",
    "            y:None=None, # `y` is kept as argument for API consistency only\n",
    "            training=False # `True` is `transform` is called during training; `False` if called during testing\n",
    "        ): # `X` augmented with data from SDMX\n",
    "        # Transforms input dataset `X` by adding the requested data using SDMX\n",
    "        check_is_fitted(self)\n",
    "        self.params_ = self._get_dates()\n",
    "        idx = X.index\n",
    "        transf_X = self._transform(X, training=training)\n",
    "        transf_X.index = idx\n",
    "        return transf_X\n",
    "\n",
    "    def fit_transform(\n",
    "            self, \n",
    "            X, # # a pandas Series or DataFrame with an index of datetime type\n",
    "            y:None=None # `y` is kept as argument for API consistency only\n",
    "            ) -> np.ndarray: # `X` augmented with data from SDMX with the same number of samples but more columns\n",
    "        # Fit to data, then transform it.\n",
    "        \n",
    "        self.fit(X)\n",
    "        self.params_ = self._get_dates()\n",
    "        return self.transform(X, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/augmentation.py#L16){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AugmentSDMX\n",
       "\n",
       ">      AugmentSDMX (sources={'BIS': 'WS_CBPOL_D'}, variance_threshold=None,\n",
       ">                   propagate_last_known_value=True, fillna=0, verbose=True)\n",
       "\n",
       "A transformer that augments a dataset using SDMX"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/augmentation.py#L16){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AugmentSDMX\n",
       "\n",
       ">      AugmentSDMX (sources={'BIS': 'WS_CBPOL_D'}, variance_threshold=None,\n",
       ">                   propagate_last_known_value=True, fillna=0, verbose=True)\n",
       "\n",
       "A transformer that augments a dataset using SDMX"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AugmentSDMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/augmentation.py#L76){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AugmentSDMX.fit\n",
       "\n",
       ">      AugmentSDMX.fit (X, y:None=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X |  |  | a pandas Series or DataFrame with an index of datetime type |\n",
       "| y | None | None | `y` is kept as argument for API consistency only |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/augmentation.py#L76){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AugmentSDMX.fit\n",
       "\n",
       ">      AugmentSDMX.fit (X, y:None=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X |  |  | a pandas Series or DataFrame with an index of datetime type |\n",
       "| y | None | None | `y` is kept as argument for API consistency only |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AugmentSDMX.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/augmentation.py#L98){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AugmentSDMX.transform\n",
       "\n",
       ">      AugmentSDMX.transform (X, y:None=None, training=False)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X |  |  | a pandas Series or DataFrame with an index of datetime type |\n",
       "| y | None | None | `y` is kept as argument for API consistency only |\n",
       "| training | bool | False | `True` is `transform` is called during training; `False` if called during testing |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/augmentation.py#L98){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AugmentSDMX.transform\n",
       "\n",
       ">      AugmentSDMX.transform (X, y:None=None, training=False)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X |  |  | a pandas Series or DataFrame with an index of datetime type |\n",
       "| y | None | None | `y` is kept as argument for API consistency only |\n",
       "| training | bool | False | `True` is `transform` is called during training; `False` if called during testing |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AugmentSDMX.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/augmentation.py#L112){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AugmentSDMX.fit_transform\n",
       "\n",
       ">      AugmentSDMX.fit_transform (X, y:None=None)\n",
       "\n",
       "Fit to data, then transform it.\n",
       "\n",
       "Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
       "and returns a transformed version of `X`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | array-like of shape (n_samples, n_features) |  | # a pandas Series or DataFrame with an index of datetime type |\n",
       "| y | array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None | None | `y` is kept as argument for API consistency only |\n",
       "| **Returns** | **ndarray** |  | **`X` augmented with data from SDMX with the same number of samples but more columns** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/augmentation.py#L112){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AugmentSDMX.fit_transform\n",
       "\n",
       ">      AugmentSDMX.fit_transform (X, y:None=None)\n",
       "\n",
       "Fit to data, then transform it.\n",
       "\n",
       "Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
       "and returns a transformed version of `X`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | array-like of shape (n_samples, n_features) |  | # a pandas Series or DataFrame with an index of datetime type |\n",
       "| y | array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None | None | `y` is kept as argument for API consistency only |\n",
       "| **Returns** | **ndarray** |  | **`X` augmented with data from SDMX with the same number of samples but more columns** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AugmentSDMX.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibility with `scikit-learn`\n",
    "\n",
    "As mentioned above, `gingado`'s transformers are built to be compatible with `scikit-learn`. The code below demonstrates this compatibility.\n",
    "\n",
    "First, we create the example dataset. In this case, it comprises the daily foreign exchange rate of selected currencies to the Euro. The Brazilian Real (BRL) is chosen for this example as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.utils import load_SDMX_data, Lag\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'EXR' - Exchange Rates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:27:30,812 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    }
   ],
   "source": [
    "X = load_SDMX_data(\n",
    "    sources={'ECB': 'EXR'}, \n",
    "    keys={'FREQ': 'D', 'CURRENCY': ['EUR', 'AUD', 'BRL', 'CAD', 'CHF', 'GBP', 'JPY', 'SGD', 'USD']},\n",
    "    params={\"startPeriod\": 2003}\n",
    "    )\n",
    "# drop rows with empty values\n",
    "X.dropna(inplace=True)\n",
    "# adjust column names in this simple example for ease of understanding:\n",
    "# remove parts related to source and dataflow names\n",
    "X.columns = X.columns.str.replace(\"ECB__EXR_D__\", \"\").str.replace(\"__EUR__SP00__A\", \"\")\n",
    "X = Lag(lags=1, jump=0, keep_contemporaneous_X=True).fit_transform(X)\n",
    "y = X.pop('BRL')\n",
    "# retain only the lagged variables in the X variable\n",
    "X = X[X.columns[X.columns.str.contains('_lag_')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5053, 8), (5053,), (1, 8), (1,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = X.iloc[:-1], X.tail(1)\n",
    "y_train, y_test = y.iloc[:-1], y.tail(1)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data augmentation object provided by `gingado` adds more data. In this case, for brevity only one dataflow from one source is listed. If users want to add more SDMX sources, simply add more keys to the dictionary. And if users want data from all dataflows from a given source provided the keys and parameters such as frequency and dates match, the value should be set to `'all'`, as in `{'ECB': ['CISS'], 'BIS': 'all'}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:27:54,989 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from BIS's dataflow 'WS_CBPOL_D' - Policy rates daily...\n",
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:29:20,395 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from BIS's dataflow 'WS_CBPOL_D' - Policy rates daily...\n"
     ]
    }
   ],
   "source": [
    "test_src = {'ECB': ['CISS'], 'BIS': ['WS_CBPOL_D']}\n",
    "\n",
    "X_train__fit_transform = AugmentSDMX(sources=test_src).fit_transform(X=X_train)\n",
    "X_train__fit_then_transform = AugmentSDMX(sources=test_src).fit(X=X_train).transform(X=X_train, training=True)\n",
    "\n",
    "assert X_train__fit_transform.shape == X_train__fit_then_transform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AugmentSDMX` can also be part of a `Pipeline` object, which minimises operational errors during modelling and avoids using testing data during training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the dataset now after this particular augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of columns: 68 Index(['AUD_lag_1', 'BRL_lag_1', 'CAD_lag_1', 'CHF_lag_1', 'GBP_lag_1',\n",
      "       'JPY_lag_1', 'SGD_lag_1', 'USD_lag_1',\n",
      "       'ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__CN__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__DE__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__ES__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__FI__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__FR__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__GB__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__IE__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__IT__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__NL__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__PT__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_BM__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_CI__IDX',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_CIN__IDX',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_CO__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_EM__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_FI__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_FX__CON',\n",
      "       'ECB__CISS_D__U2__Z0Z__4F__EC__SS_MM__CON',\n",
      "       'ECB__CISS_D__US__Z0Z__4F__EC__SS_CI__IDX',\n",
      "       'ECB__CISS_D__US__Z0Z__4F__EC__SS_CIN__IDX', 'BIS__WS_CBPOL_D_D__AR',\n",
      "       'BIS__WS_CBPOL_D_D__AU', 'BIS__WS_CBPOL_D_D__BR',\n",
      "       'BIS__WS_CBPOL_D_D__CA', 'BIS__WS_CBPOL_D_D__CH',\n",
      "       'BIS__WS_CBPOL_D_D__CL', 'BIS__WS_CBPOL_D_D__CN',\n",
      "       'BIS__WS_CBPOL_D_D__CO', 'BIS__WS_CBPOL_D_D__CZ',\n",
      "       'BIS__WS_CBPOL_D_D__DK', 'BIS__WS_CBPOL_D_D__GB',\n",
      "       'BIS__WS_CBPOL_D_D__HK', 'BIS__WS_CBPOL_D_D__HR',\n",
      "       'BIS__WS_CBPOL_D_D__HU', 'BIS__WS_CBPOL_D_D__ID',\n",
      "       'BIS__WS_CBPOL_D_D__IL', 'BIS__WS_CBPOL_D_D__IN',\n",
      "       'BIS__WS_CBPOL_D_D__IS', 'BIS__WS_CBPOL_D_D__JP',\n",
      "       'BIS__WS_CBPOL_D_D__KR', 'BIS__WS_CBPOL_D_D__MK',\n",
      "       'BIS__WS_CBPOL_D_D__MX', 'BIS__WS_CBPOL_D_D__MY',\n",
      "       'BIS__WS_CBPOL_D_D__NO', 'BIS__WS_CBPOL_D_D__NZ',\n",
      "       'BIS__WS_CBPOL_D_D__PE', 'BIS__WS_CBPOL_D_D__PH',\n",
      "       'BIS__WS_CBPOL_D_D__PL', 'BIS__WS_CBPOL_D_D__RO',\n",
      "       'BIS__WS_CBPOL_D_D__RS', 'BIS__WS_CBPOL_D_D__RU',\n",
      "       'BIS__WS_CBPOL_D_D__SA', 'BIS__WS_CBPOL_D_D__SE',\n",
      "       'BIS__WS_CBPOL_D_D__TH', 'BIS__WS_CBPOL_D_D__TR',\n",
      "       'BIS__WS_CBPOL_D_D__US', 'BIS__WS_CBPOL_D_D__XM',\n",
      "       'BIS__WS_CBPOL_D_D__ZA'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUD_lag_1</th>\n",
       "      <th>BRL_lag_1</th>\n",
       "      <th>CAD_lag_1</th>\n",
       "      <th>CHF_lag_1</th>\n",
       "      <th>GBP_lag_1</th>\n",
       "      <th>JPY_lag_1</th>\n",
       "      <th>SGD_lag_1</th>\n",
       "      <th>USD_lag_1</th>\n",
       "      <th>ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX</th>\n",
       "      <th>ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX</th>\n",
       "      <th>...</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__RO</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__RS</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__RU</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__SA</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__SE</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__TH</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__TR</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__US</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__XM</th>\n",
       "      <th>BIS__WS_CBPOL_D_D__ZA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>1.8554</td>\n",
       "      <td>3.6770</td>\n",
       "      <td>1.6422</td>\n",
       "      <td>1.4528</td>\n",
       "      <td>0.65200</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8188</td>\n",
       "      <td>1.0446</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>1.8440</td>\n",
       "      <td>3.6112</td>\n",
       "      <td>1.6264</td>\n",
       "      <td>1.4555</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>124.56</td>\n",
       "      <td>1.8132</td>\n",
       "      <td>1.0392</td>\n",
       "      <td>0.020801</td>\n",
       "      <td>0.039924</td>\n",
       "      <td>...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>1.8281</td>\n",
       "      <td>3.5145</td>\n",
       "      <td>1.6383</td>\n",
       "      <td>1.4563</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8210</td>\n",
       "      <td>1.0488</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>1.8160</td>\n",
       "      <td>3.5139</td>\n",
       "      <td>1.6257</td>\n",
       "      <td>1.4565</td>\n",
       "      <td>0.64960</td>\n",
       "      <td>124.82</td>\n",
       "      <td>1.8155</td>\n",
       "      <td>1.0425</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.040338</td>\n",
       "      <td>...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-09</th>\n",
       "      <td>1.8132</td>\n",
       "      <td>3.4405</td>\n",
       "      <td>1.6231</td>\n",
       "      <td>1.4586</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1.8102</td>\n",
       "      <td>1.0377</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.040535</td>\n",
       "      <td>...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.75</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>1.4853</td>\n",
       "      <td>5.1837</td>\n",
       "      <td>1.3172</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>0.86934</td>\n",
       "      <td>143.43</td>\n",
       "      <td>1.4062</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.421614</td>\n",
       "      <td>0.404585</td>\n",
       "      <td>...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-19</th>\n",
       "      <td>1.4894</td>\n",
       "      <td>5.2279</td>\n",
       "      <td>1.3226</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.87400</td>\n",
       "      <td>142.53</td>\n",
       "      <td>1.4025</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.408356</td>\n",
       "      <td>0.395996</td>\n",
       "      <td>...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-20</th>\n",
       "      <td>1.4950</td>\n",
       "      <td>5.2886</td>\n",
       "      <td>1.3294</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.87785</td>\n",
       "      <td>143.42</td>\n",
       "      <td>1.4082</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.407552</td>\n",
       "      <td>0.401103</td>\n",
       "      <td>...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>1.4893</td>\n",
       "      <td>5.2139</td>\n",
       "      <td>1.3268</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.87395</td>\n",
       "      <td>143.34</td>\n",
       "      <td>1.4074</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.416440</td>\n",
       "      <td>0.393851</td>\n",
       "      <td>...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22</th>\n",
       "      <td>1.4851</td>\n",
       "      <td>5.0924</td>\n",
       "      <td>1.3262</td>\n",
       "      <td>0.9549</td>\n",
       "      <td>0.87335</td>\n",
       "      <td>142.66</td>\n",
       "      <td>1.4006</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>0.430397</td>\n",
       "      <td>0.406241</td>\n",
       "      <td>...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5053 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUD_lag_1  BRL_lag_1  CAD_lag_1  CHF_lag_1  GBP_lag_1  JPY_lag_1  \\\n",
       "TIME_PERIOD                                                                     \n",
       "2003-01-03      1.8554     3.6770     1.6422     1.4528    0.65200     124.40   \n",
       "2003-01-06      1.8440     3.6112     1.6264     1.4555    0.65000     124.56   \n",
       "2003-01-07      1.8281     3.5145     1.6383     1.4563    0.64950     124.40   \n",
       "2003-01-08      1.8160     3.5139     1.6257     1.4565    0.64960     124.82   \n",
       "2003-01-09      1.8132     3.4405     1.6231     1.4586    0.64950     124.90   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "2022-09-16      1.4853     5.1837     1.3172     0.9572    0.86934     143.43   \n",
       "2022-09-19      1.4894     5.2279     1.3226     0.9579    0.87400     142.53   \n",
       "2022-09-20      1.4950     5.2886     1.3294     0.9658    0.87785     143.42   \n",
       "2022-09-21      1.4893     5.2139     1.3268     0.9644    0.87395     143.34   \n",
       "2022-09-22      1.4851     5.0924     1.3262     0.9549    0.87335     142.66   \n",
       "\n",
       "             SGD_lag_1  USD_lag_1  ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX  \\\n",
       "TIME_PERIOD                                                                    \n",
       "2003-01-03      1.8188     1.0446                                   0.021899   \n",
       "2003-01-06      1.8132     1.0392                                   0.020801   \n",
       "2003-01-07      1.8210     1.0488                                   0.019738   \n",
       "2003-01-08      1.8155     1.0425                                   0.019947   \n",
       "2003-01-09      1.8102     1.0377                                   0.017026   \n",
       "...                ...        ...                                        ...   \n",
       "2022-09-16      1.4062     0.9992                                   0.421614   \n",
       "2022-09-19      1.4025     0.9954                                   0.408356   \n",
       "2022-09-20      1.4082     0.9990                                   0.407552   \n",
       "2022-09-21      1.4074     0.9986                                   0.416440   \n",
       "2022-09-22      1.4006     0.9906                                   0.430397   \n",
       "\n",
       "             ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX  ...  \\\n",
       "TIME_PERIOD                                             ...   \n",
       "2003-01-03                                    0.043292  ...   \n",
       "2003-01-06                                    0.039924  ...   \n",
       "2003-01-07                                    0.038084  ...   \n",
       "2003-01-08                                    0.040338  ...   \n",
       "2003-01-09                                    0.040535  ...   \n",
       "...                                                ...  ...   \n",
       "2022-09-16                                    0.404585  ...   \n",
       "2022-09-19                                    0.395996  ...   \n",
       "2022-09-20                                    0.401103  ...   \n",
       "2022-09-21                                    0.393851  ...   \n",
       "2022-09-22                                    0.406241  ...   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__RO  BIS__WS_CBPOL_D_D__RS  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-03                     NaN                    9.5   \n",
       "2003-01-06                   19.75                    9.5   \n",
       "2003-01-07                   19.75                    9.5   \n",
       "2003-01-08                   19.75                    9.5   \n",
       "2003-01-09                   19.75                    9.5   \n",
       "...                            ...                    ...   \n",
       "2022-09-16                    5.50                    3.5   \n",
       "2022-09-19                    5.50                    3.5   \n",
       "2022-09-20                    5.50                    3.5   \n",
       "2022-09-21                    5.50                    3.5   \n",
       "2022-09-22                    5.50                    3.5   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__RU  BIS__WS_CBPOL_D_D__SA  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-03                     NaN                    NaN   \n",
       "2003-01-06                     NaN                    2.0   \n",
       "2003-01-07                     NaN                    2.0   \n",
       "2003-01-08                    21.0                    2.0   \n",
       "2003-01-09                    21.0                    2.0   \n",
       "...                            ...                    ...   \n",
       "2022-09-16                     8.0                    3.0   \n",
       "2022-09-19                     7.5                    3.0   \n",
       "2022-09-20                     7.5                    3.0   \n",
       "2022-09-21                     7.5                    3.0   \n",
       "2022-09-22                     7.5                    3.0   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__SE  BIS__WS_CBPOL_D_D__TH  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-03                    3.75                   1.75   \n",
       "2003-01-06                    3.75                   1.75   \n",
       "2003-01-07                    3.75                   1.75   \n",
       "2003-01-08                    3.75                   1.75   \n",
       "2003-01-09                    3.75                   1.75   \n",
       "...                            ...                    ...   \n",
       "2022-09-16                    0.75                   0.75   \n",
       "2022-09-19                    0.75                   0.75   \n",
       "2022-09-20                    0.75                   0.75   \n",
       "2022-09-21                    0.75                   0.75   \n",
       "2022-09-22                    0.75                   0.75   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__TR  BIS__WS_CBPOL_D_D__US  \\\n",
       "TIME_PERIOD                                                 \n",
       "2003-01-03                    44.0                  1.250   \n",
       "2003-01-06                    44.0                  1.250   \n",
       "2003-01-07                    44.0                  1.250   \n",
       "2003-01-08                    44.0                  1.250   \n",
       "2003-01-09                    44.0                  1.250   \n",
       "...                            ...                    ...   \n",
       "2022-09-16                    13.0                  2.375   \n",
       "2022-09-19                    13.0                  2.375   \n",
       "2022-09-20                    13.0                  2.375   \n",
       "2022-09-21                    13.0                  2.375   \n",
       "2022-09-22                    13.0                  2.375   \n",
       "\n",
       "             BIS__WS_CBPOL_D_D__XM  BIS__WS_CBPOL_D_D__ZA  \n",
       "TIME_PERIOD                                                \n",
       "2003-01-03                    2.75                   13.5  \n",
       "2003-01-06                    2.75                   13.5  \n",
       "2003-01-07                    2.75                   13.5  \n",
       "2003-01-08                    2.75                   13.5  \n",
       "2003-01-09                    2.75                   13.5  \n",
       "...                            ...                    ...  \n",
       "2022-09-16                    1.25                    5.5  \n",
       "2022-09-19                    1.25                    5.5  \n",
       "2022-09-20                    1.25                    5.5  \n",
       "2022-09-21                    1.25                    5.5  \n",
       "2022-09-22                    1.25                    5.5  \n",
       "\n",
       "[5053 rows x 68 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"No of columns: {len(X_train__fit_transform.columns)} {X_train__fit_transform.columns}\")\n",
    "X_train__fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.augmentation import AugmentSDMX\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('augmentation', AugmentSDMX(sources={'BIS': 'WS_CBPOL_D'})),\n",
    "    ('imp', IterativeImputer(max_iter=10)),\n",
    "    ('forest', RandomForestRegressor())\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the data augmentation to enhance model performance\n",
    "\n",
    "And since `AugmentSDMX` can be included in a `Pipeline`, it can also be fine-tuned by parameter search techniques (such as grid search), further helping users make the best of available data to enhance performance of their models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   0.3s\n",
      "[CV] END ...........................augmentation=passthrough; total time=   0.3s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   0.6s\n",
      "[CV] END ...........................augmentation=passthrough; total time=   0.6s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   0.8s\n",
      "[CV] END ...........................augmentation=passthrough; total time=   0.9s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   1.1s\n",
      "[CV] END ...........................augmentation=passthrough; total time=   1.2s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   1.5s\n",
      "[CV] END ...........................augmentation=passthrough; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:30:53,437 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   3.4s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:30:57,459 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV] END ..augmentation=AugmentSDMX(sources={'ECB': 'CISS'}); total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:31:00,855 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   6.6s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.2s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:31:09,269 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV] END ..augmentation=AugmentSDMX(sources={'ECB': 'CISS'}); total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:31:22,786 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=  12.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.2s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:31:37,654 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV] END ..augmentation=AugmentSDMX(sources={'ECB': 'CISS'}); total time=  26.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:31:49,582 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=  16.4s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.2s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:32:09,995 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV] END ..augmentation=AugmentSDMX(sources={'ECB': 'CISS'}); total time=  38.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:32:27,800 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=  21.9s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.4s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:32:54,962 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n",
      "[CV] END ..augmentation=AugmentSDMX(sources={'ECB': 'CISS'}); total time=  46.3s\n",
      "[Pipeline] ...... (step 1 of 3) Processing augmentation, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing imp, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing forest, total=   1.8s\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid={\n",
    "        'augmentation': ['passthrough', AugmentSDMX(sources={'ECB': 'CISS'})]\n",
    "    },\n",
    "    verbose=2,\n",
    "    cv=TimeSeriesSplit()\n",
    "    )\n",
    "\n",
    "y_pred_grid = grid.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'augmentation': 'passthrough'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this particular case, the best model was achieved by not using the data augmentation.\n"
     ]
    }
   ],
   "source": [
    "print(f\"In this particular case, the best model was achieved by {'not ' if grid.best_params_['augmentation'] == 'passthrough' else ''}using the data augmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last value in the training dataset was [5.0677]. The predicted value was [5.090424], and the actual value was [5.0456].\n"
     ]
    }
   ],
   "source": [
    "print(f\"The last value in the training dataset was {y_train.tail(1).to_numpy()}. The predicted value was {y_pred_grid}, and the actual value was {y_test.to_numpy()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources of data\n",
    "\n",
    "`gingado` seeks to only lists realiable data sources by choice, with a focus on official sources. This is meant to provide users with the trust that their dataset will be complemented by reliable sources. Unfortunately, it is not possible at this stage to include *all* official sources given the substantial manual and maintenance work. `gingado` leverages the existence of the [Statistical Data and Metadata eXchange (SDMX)](https://sdmx.org), an organisation of official data sources that establishes common data and metadata formats, to download data that is relevant (and hopefully also useful) to users.\n",
    "\n",
    "The function below from the package [simpledmx](https://github.com/dkgaraujo/simpledmx) returns a list of codes corresponding to the data sources available to provide `gingado` users with data through SDMX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.utils import list_SDMX_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABS',\n",
       " 'ABS_XML',\n",
       " 'BBK',\n",
       " 'BIS',\n",
       " 'CD2030',\n",
       " 'ECB',\n",
       " 'ESTAT',\n",
       " 'ILO',\n",
       " 'IMF',\n",
       " 'INEGI',\n",
       " 'INSEE',\n",
       " 'ISTAT',\n",
       " 'LSD',\n",
       " 'NB',\n",
       " 'NBB',\n",
       " 'OECD',\n",
       " 'SGR',\n",
       " 'SPC',\n",
       " 'STAT_EE',\n",
       " 'UNICEF',\n",
       " 'UNSD',\n",
       " 'WB',\n",
       " 'WB_WDI']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_SDMX_sources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see what the available dataflows are. The code below returns a dictionary where each key is the code for an SDMX source, and the values associated with each key are the code and name for the respective dataflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.utils import list_all_dataflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 00:33:43,228 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2022-09-24 00:33:47,587 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2022-09-24 00:33:48,328 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2022-09-24 00:33:51,471 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2022-09-24 00:33:52,246 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ABS_XML  ABORIGINAL_POP_PROJ                 Projected population, Aboriginal and Torres St...\n",
       "         ABORIGINAL_POP_PROJ_REMOTE          Projected population, Aboriginal and Torres St...\n",
       "         ABS_ABORIGINAL_POPPROJ_INDREGION    Projected population, Aboriginal and Torres St...\n",
       "         ABS_ACLD_LFSTATUS                   Australian Census Longitudinal Dataset (ACLD):...\n",
       "         ABS_ACLD_TENURE                     Australian Census Longitudinal Dataset (ACLD):...\n",
       "                                                                   ...                        \n",
       "UNSD     DF_UNData_UNFCC                                                       SDMX_GHG_UNDATA\n",
       "WB       DF_WITS_Tariff_TRAINS                                WITS - UNCTAD TRAINS Tariff Data\n",
       "         DF_WITS_TradeStats_Development                             WITS TradeStats Devlopment\n",
       "         DF_WITS_TradeStats_Tariff                                      WITS TradeStats Tariff\n",
       "         DF_WITS_TradeStats_Trade                                        WITS TradeStats Trade\n",
       "Name: dataflow, Length: 9548, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflows = list_all_dataflows()\n",
    "dflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the dataflows from the World Bank are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DF_WITS_Tariff_TRAINS             WITS - UNCTAD TRAINS Tariff Data\n",
       "DF_WITS_TradeStats_Development          WITS TradeStats Devlopment\n",
       "DF_WITS_TradeStats_Tariff                   WITS TradeStats Tariff\n",
       "DF_WITS_TradeStats_Trade                     WITS TradeStats Trade\n",
       "Name: dataflow, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflows['WB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv_gingado': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
