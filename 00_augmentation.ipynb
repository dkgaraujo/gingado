{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "> Functions to augment the user's dataset with information from official sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation as a transformer\n",
    "\n",
    "The package `scikit-learn` makes use of the concept of transformer, an object in python that adapts the transformation at hand to the training data, and then deploys it on the testing data. These transformers can be used as part of a pipeline.\n",
    "\n",
    "In order to ensure maximumm compatibility with packages that are widely used, `gingado`'s data augmentation function are implemented as an object that are funcional on their own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Now moving on to b the stories também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import pandasdmx as sdmx\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "class AugmentSDMX(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sources={'BIS': 'all'}, variance_threshold=None, backend='memory', verbose=True):\n",
    "        self.sources = sources\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.backend = backend\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.index_ = X.index if hasattr(X, \"index\") else None\n",
    "        self.data_freq_ = self.index_.to_series().diff().min().resolution_string\n",
    "        format_string = \"%Y-%m-%d\" if self.data_freq_ == 'D' else \"%Y-%m\" if self.data_freq_ == 'M' else \"%Y\"\n",
    "\n",
    "        X = self._validate_data(X)\n",
    "        \n",
    "        self.keys_ = {'FREQ': self.data_freq_}\n",
    "\n",
    "        self.params_ = {\n",
    "            \"startPeriod\": min(self.index_).strftime(format_string),\n",
    "            \"endPeriod\": max(self.index_).strftime(format_string),\n",
    "        }\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        data_sdmx = {}\n",
    "        for source in self.sources.keys():\n",
    "            src_conn = sdmx.Request(source, backend=self.backend, expire_after=1800)\n",
    "            src_dflows = src_conn.dataflow()\n",
    "            if self.sources[source] == 'all':\n",
    "                dflows = {k: v for k, v in src_dflows.dataflow.items()}\n",
    "            else:\n",
    "                dflows = {k: v for k, v in src_dflows.dataflow.items() if k in self.sources[source]}\n",
    "            for dflow in dflows.keys():\n",
    "                if self.verbose: print(f\"Querying data from {source}'s dataflow '{dflow}' - {dflows[dflow].dict()['name']}...\")\n",
    "                try:\n",
    "                    data = sdmx.to_pandas(src_conn.data(dflow, key=self.keys_, params=self.params_), datetime='TIME_PERIOD')\n",
    "                except:\n",
    "                    if self.verbose: print(\"this dataflow does not have data in the desired frequency and time period.\")\n",
    "                    continue\n",
    "                data.columns = ['__'.join(col) for col in data.columns.to_flat_index()]\n",
    "                data_sdmx[source+\"__\"+dflow] = data\n",
    "\n",
    "        if len(data_sdmx.keys()) is None:\n",
    "            return X\n",
    "\n",
    "        df = pd.concat(data_sdmx, axis=1)\n",
    "        df.columns = ['_'.join(col) for col in df.columns.to_flat_index()]\n",
    "\n",
    "        feat_sel = VarianceThreshold() if self.variance_threshold is None else VarianceThreshold(threshold=self.variance_threshold)\n",
    "        feat_sel.fit(df)\n",
    "    \n",
    "        self.features_stay = df.columns[feat_sel.get_support()]\n",
    "        self.features_removed = df.columns[~feat_sel.get_support()]\n",
    "\n",
    "        df = df.iloc[:, feat_sel.get_support()]\n",
    "        df.dropna(axis=0, how='all', inplace=True)\n",
    "        df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "        self.augm_df_ = df\n",
    "        del(df)\n",
    "\n",
    "        X = pd.concat([X, self.augm_df_], axis=1, join='inner')\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, `gingado`'s transformers are built to be compatible with `scikit-learn`. The code below checks whether this is achieved.\n",
    "\n",
    "First, we create the example dataset comprising the foreign exchange rate of a number of currencies to the Euro. The Brazilian Real is chosen for this example as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.utils import load_EURFX_data\n",
    "\n",
    "X = load_EURFX_data()\n",
    "y = X.pop('BRL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data augmentation object provided by `gingado` adds more data. In this case, for brevity only one dataflow from one source is listed. If users want to add more SDMX sources, simply add more keys to the dictionary. And if users want data from all dataflows from a given source (provided the keys and parameters such as frequency and dates are matched), the value should be set to `'all'`, as in `{'ECB': ['CISS'], 'BIS': 'all'}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 02:06:48,523 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n"
     ]
    }
   ],
   "source": [
    "X_augm = AugmentSDMX(sources={'ECB': ['CISS']}).fit_transform(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of features just went from 7 to 29 with one dataflow!\n",
      "\n",
      "                 AUD     CAD     CHF     GBP     JPY     SGD     USD  \\\n",
      "TIME_PERIOD                                                           \n",
      "2003-01-02   1.8554  1.6422  1.4528  0.6520  124.40  1.8188  1.0446   \n",
      "2003-01-03   1.8440  1.6264  1.4555  0.6500  124.56  1.8132  1.0392   \n",
      "2003-01-06   1.8281  1.6383  1.4563  0.6495  124.40  1.8210  1.0488   \n",
      "2003-01-07   1.8160  1.6257  1.4565  0.6496  124.82  1.8155  1.0425   \n",
      "2003-01-08   1.8132  1.6231  1.4586  0.6495  124.90  1.8102  1.0377   \n",
      "\n",
      "             ECB__CISS_D__AT__Z0Z__4F__EC__SS_CIN__IDX  \\\n",
      "TIME_PERIOD                                              \n",
      "2003-01-02                                    0.023427   \n",
      "2003-01-03                                    0.021899   \n",
      "2003-01-06                                    0.020801   \n",
      "2003-01-07                                    0.019738   \n",
      "2003-01-08                                    0.019947   \n",
      "\n",
      "             ECB__CISS_D__BE__Z0Z__4F__EC__SS_CIN__IDX  \\\n",
      "TIME_PERIOD                                              \n",
      "2003-01-02                                    0.047823   \n",
      "2003-01-03                                    0.043292   \n",
      "2003-01-06                                    0.039924   \n",
      "2003-01-07                                    0.038084   \n",
      "2003-01-08                                    0.040338   \n",
      "\n",
      "             ECB__CISS_D__CN__Z0Z__4F__EC__SS_CIN__IDX  ...  \\\n",
      "TIME_PERIOD                                             ...   \n",
      "2003-01-02                                         NaN  ...   \n",
      "2003-01-03                                         NaN  ...   \n",
      "2003-01-06                                         NaN  ...   \n",
      "2003-01-07                                         NaN  ...   \n",
      "2003-01-08                                         NaN  ...   \n",
      "\n",
      "             ECB__CISS_D__U2__Z0Z__4F__EC__SS_BM__CON  \\\n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                        NaN   \n",
      "2003-01-03                                   0.032193   \n",
      "2003-01-06                                        NaN   \n",
      "2003-01-07                                        NaN   \n",
      "2003-01-08                                        NaN   \n",
      "\n",
      "             ECB__CISS_D__U2__Z0Z__4F__EC__SS_CI__IDX  \\\n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                        NaN   \n",
      "2003-01-03                                   0.132775   \n",
      "2003-01-06                                        NaN   \n",
      "2003-01-07                                        NaN   \n",
      "2003-01-08                                        NaN   \n",
      "\n",
      "             ECB__CISS_D__U2__Z0Z__4F__EC__SS_CIN__IDX  \\\n",
      "TIME_PERIOD                                              \n",
      "2003-01-02                                    0.051668   \n",
      "2003-01-03                                    0.056262   \n",
      "2003-01-06                                    0.058146   \n",
      "2003-01-07                                    0.059180   \n",
      "2003-01-08                                    0.060996   \n",
      "\n",
      "             ECB__CISS_D__U2__Z0Z__4F__EC__SS_CO__CON  \\\n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                        NaN   \n",
      "2003-01-03                                  -0.281764   \n",
      "2003-01-06                                        NaN   \n",
      "2003-01-07                                        NaN   \n",
      "2003-01-08                                        NaN   \n",
      "\n",
      "             ECB__CISS_D__U2__Z0Z__4F__EC__SS_EM__CON  \\\n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                        NaN   \n",
      "2003-01-03                                   0.146698   \n",
      "2003-01-06                                        NaN   \n",
      "2003-01-07                                        NaN   \n",
      "2003-01-08                                        NaN   \n",
      "\n",
      "             ECB__CISS_D__U2__Z0Z__4F__EC__SS_FI__CON  \\\n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                        NaN   \n",
      "2003-01-03                                   0.135404   \n",
      "2003-01-06                                        NaN   \n",
      "2003-01-07                                        NaN   \n",
      "2003-01-08                                        NaN   \n",
      "\n",
      "             ECB__CISS_D__U2__Z0Z__4F__EC__SS_FX__CON  \\\n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                        NaN   \n",
      "2003-01-03                                   0.036013   \n",
      "2003-01-06                                        NaN   \n",
      "2003-01-07                                        NaN   \n",
      "2003-01-08                                        NaN   \n",
      "\n",
      "             ECB__CISS_D__U2__Z0Z__4F__EC__SS_MM__CON  \\\n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                        NaN   \n",
      "2003-01-03                                   0.064231   \n",
      "2003-01-06                                        NaN   \n",
      "2003-01-07                                        NaN   \n",
      "2003-01-08                                        NaN   \n",
      "\n",
      "             ECB__CISS_D__US__Z0Z__4F__EC__SS_CI__IDX  \\\n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                        NaN   \n",
      "2003-01-03                                   0.249646   \n",
      "2003-01-06                                        NaN   \n",
      "2003-01-07                                        NaN   \n",
      "2003-01-08                                        NaN   \n",
      "\n",
      "             ECB__CISS_D__US__Z0Z__4F__EC__SS_CIN__IDX  \n",
      "TIME_PERIOD                                             \n",
      "2003-01-02                                    0.123014  \n",
      "2003-01-03                                    0.133552  \n",
      "2003-01-06                                    0.145265  \n",
      "2003-01-07                                    0.151408  \n",
      "2003-01-08                                    0.161252  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nThe number of features just went from {X.shape[1]} to {X_augm.shape[1]} with one dataflow!\\n\\n\" , X_augm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be part of a `Pipeline` object, which enables the use of grid search and other parameter search techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from gingado.augmentation import AugmentSDMX\n",
    "\n",
    "lags=2\n",
    "jump=5\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('augmentation', AugmentSDMX(verbose=False)),\n",
    "    ('imputer', KNNImputer()),\n",
    "    #('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "pipeline.fit_transform(X)\n",
    "# parameters = {\n",
    "#     'augmentation': ('passthrough', AugmentSDMX(sources={'BIS': 'WS_CBPOL_D'})),\n",
    "#     'regressor__n_estimators': ('10', '20')\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "# grid_search.fit(X=X, y=y)\n",
    "\n",
    "\n",
    "# best_parameters = grid_search.best_estimator_\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall scheme:\n",
    "* Since sklearn `Pipeline` objects transform data into numpy arrays (and thus do not allow for things like looking at the index or title, etc), `gingado` will create a \"workflow\" object that:\n",
    "  * includes the data augmentation (useful to have pandas available!)\n",
    "  * the sklearn pipeline is a component that lies in the \"middle\" of the pipeline\n",
    "  * the documentation step benefits from the workflow retaining things like main dates, etc, so that it can also be used in the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions\n",
    "\n",
    "Most users will probably find it helpful to use the `DataAugment` transformer, which is compatible with `scikit-learn`, rather than the underlying functions. However, they are documented below in case their use might address some specific user need.\n",
    "\n",
    "## Sources of data\n",
    "\n",
    "`gingado` only lists official data sources by choice. This is meant to provide users with the trust that their dataset will be complemented by reliable sources. Unfortunately, it is not possible at this stage to include *all* official sources - let alone all reliable sources - because that requires substantial manual and maintenance work. `gingado` leverages the existence of the [Statistical Data and Metadata eXchange (SDMX)](https://sdmx.org), an organisation of official data sources that establishes common data and metadata formats, to download data that is relevant (and hopefully also useful) to users.\n",
    "\n",
    "The function below from the package [simpledmx](https://github.com/dkgaraujo/simpledmx) returns a list of codes corresponding to the data sources available to provide `gingado` users with data through SDMX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from simpledmx import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sdmx_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def augm_with_sdmx(df, freq, sources, variance_threshold=None):\n",
    "    \"\"\"Downloads relevant data from SDMX sources to complement the original dataset\n",
    "\n",
    "    Arguments:\n",
    "      df: a pandas DataFrame\n",
    "      freq: the frequency of the desired data from SDMX; for example, 'A' is annual\n",
    "      sources: the list of SDMX sources or None; a list of possible sources can be obtained by running the function list_sdmx_sources()    \n",
    "      variance_threshold: a value larger than or equal to 0 or None, where 0 will lead to the removal of all data that does not vary across the dataset and None uses the scikit-learn default\n",
    "    \"\"\"\n",
    "    start_date, end_date = min(df.index), max(df.index)\n",
    "        \n",
    "    sdmx_data = get_sdmx_data(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        freq=freq,\n",
    "        sources=sources\n",
    "        )\n",
    "    sdmx_data = sdmx_data.dropna(axis=1).sort_index()\n",
    "    sdmx_data.reset_index(inplace=True)\n",
    "    sdmx_data['TIME_PERIOD'] = pd.to_datetime(sdmx_data['TIME_PERIOD'])\n",
    "    sdmx_data.set_index('TIME_PERIOD', inplace=True)\n",
    "    \n",
    "    feat_sel = VarianceThreshold() if variance_threshold is None else VarianceThreshold(threshold=variance_threshold)\n",
    "    feat_sel.fit(sdmx_data)\n",
    "    \n",
    "    # TODO: log which features were not kept and why\n",
    "    sdmx_data = sdmx_data.iloc[:, feat_sel.get_support()]\n",
    "\n",
    "    #sdmx_data = feat_sel.fit_transform(sdmx_data)\n",
    "        \n",
    "    if df is None:\n",
    "        return sdmx_data\n",
    "    df , blacksoack= df.merge(sdmx_data, how='left', left_on=time_col, right_on='TIME_PERIOD')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv_gingado': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
