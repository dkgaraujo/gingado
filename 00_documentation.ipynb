{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model_documentation\n",
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model documentation\n",
    "> Functions to jumpstat and facilitate model documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each user has a specific documentation need, ranging from the simply logging the model training to a more complex description of the model pipeline with a discusson of its predictions. `gingado` addresses this variety of needs by offering a class of objects, \"Documenters\", that facilitate model documentation in a generic way, as well as one specific model documentation type as described below. \n",
    "\n",
    "The model documentation is performed by Documenters, objects that subclass from the base class `ggdModelDocumentation`. This base class offers code that can be used by any Documenter to read the pipeline in question and to save the resulting documentation in a JSON format. One current area of development is the automatic filing of some fields related to the model. The objective is to automatise documentation of the information that can be fetched automatically from the model, leaving time for the analyst to concentrate on other tasks, such as considering the ethical implications of the machine learning model being trained.\n",
    "\n",
    "Documenters save the underlying information using the JSON format. With the JSON documentation file at hand, the user can then use existing third-party libraries to transform the information stored in JSON into a variety of formats (eg, HTML, PDF) as needed.\n",
    "\n",
    "`ModelCard` - the model documentation template inspired by the work of [Mitchell et al, 2019](https://dl.acm.org/doi/abs/10.1145/3287560.3287596?casa_token=3JORxBYy_DQAAAAA:0RsTpg5NsCX8B2lEwMg81rCxHiQlkZIuP1rPjAmOOF1fP0NTi3Vv3-WT75gwQm6bysUYxdXLkgqUuA) already comes with `gingado`. Its template can be used by users as is, or tweaked according to each need. The `ModelCard` template can also serve as inspiration for any custom documentation needs. Users with documentation needs beyond the out-of-the-box solutions provided by `gingado` can simply create their own class of Documenters, and compatibility with these custom documentation routines with the rest of the code is ensured. Users are encouraged to submit a pull request with their own documentation models subclassing `ggdModelDocumentation` if these custom templates can also benefit other users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import copy\n",
    "import json\n",
    "\n",
    "class ggdModelDocumentation:\n",
    "    \"Base class for gingado Documenters\"\n",
    "\n",
    "    def setup_template(self):\n",
    "        self.json_doc = copy.deepcopy(self.__class__.template)\n",
    "        for k in self.json_doc.keys():\n",
    "            self.json_doc[k].pop('field_description', \"\")\n",
    "\n",
    "    def show_template(self, indent=True):\n",
    "        if indent:\n",
    "            print(json.dumps(self.__class__.template, indent=self.indent_level))\n",
    "        else:\n",
    "            return self.__class__.template\n",
    "        \n",
    "    def documentation_path(self):\n",
    "        print(self.file_path)\n",
    "\n",
    "    def show_json(self):\n",
    "        print(json.dumps(self.json_doc, indent=self.indent_level))\n",
    "\n",
    "    def save_json(self, file_path):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(self.json_doc, f)\n",
    "\n",
    "    def read_json(self, file_path=None):\n",
    "        if file_path is None:\n",
    "            file_path = self.file_path\n",
    "        f = open(file_path)\n",
    "        self.json_doc = json.load(f)\n",
    "\n",
    "    def open_questions(self):\n",
    "        return [\n",
    "                    k + \"__\" + v \n",
    "                    for k, v in self.json_doc.items()\n",
    "                    for v, i in v.items()\n",
    "                    if i == self.__class__.template[k][v]\n",
    "        ]\n",
    "\n",
    "    def fill_info(self, new_info):\n",
    "        for k, v in new_info.items():\n",
    "            if k not in self.__class__.template:\n",
    "                field_keys = list(self.__class__.template.keys())\n",
    "                raise KeyError(f\"key '{k}' is not in the documentation template. The template's keys are: {field_keys}\")\n",
    "            if isinstance(v, dict):\n",
    "                for v_k, v_v in v.items():\n",
    "                    if v_k == 'field_description':\n",
    "                        raise KeyError(\"The key 'field_description' is not supposed to be changed from the template definition.\")\n",
    "                    if v_k not in self.__class__.template[k]:\n",
    "                        field_keys = [k for k in self.__class__.template[k].keys() if k != 'field_description']\n",
    "                        raise KeyError(\n",
    "                            f\"key '{v_k}' is not in the documentation template's item {k}. These template item's keys are: {field_keys}\")\n",
    "                    self.json_doc[k][v_k] = v_v\n",
    "            else:\n",
    "                self.json_doc[k] = v\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps(self.json_doc, indent=4)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__}()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"ggdModelDocumentation\" class=\"doc_header\"><code>class</code> <code>ggdModelDocumentation</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>ggdModelDocumentation</code>()\n",
       "\n",
       "Base class for gingado Documenters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ggdModelDocumentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "from gingado.utils import get_username, get_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "class ModelCard(ggdModelDocumentation):\n",
    "    template = {\n",
    "        'model_details': {\n",
    "            'field_description': \"Basic information about the model\",\n",
    "            'developer': \"Person or organisation developing the model\",\n",
    "            'datetime': \"Model date\",\n",
    "            'version': \"Model version\",\n",
    "            'type': \"Model type\",\n",
    "            'info': \"Information about training algorithms, parameters, fairness constraints or other applied approaches, and features\",\n",
    "            'paper': \"Paper or other resource for more information\",\n",
    "            'citation': \"Citation details\",\n",
    "            'license': \"License\",\n",
    "            'contact': \"Where to send questions or comments about the model\"\n",
    "        },\n",
    "        'intended_use': {\n",
    "            'field_description': \"Use cases that were envisioned during development\",\n",
    "            'primary_uses': \"Primary intended uses\",\n",
    "            'primary_users': \"Primary intended users\",\n",
    "            'out_of_scope': \"Out-of-scope use cases\"\n",
    "        },\n",
    "        'factors': {\n",
    "            'field_description': \"Factors could include demographic or phenotypic groups, environmental conditions, technical attributes, or others\",\n",
    "            'relevant': \"Relevant factors\",\n",
    "            'evaluation': \"Evaluation factors\" \n",
    "        },\n",
    "        'metrics': {\n",
    "            'field_description': \"Metrics should be chosen to reflect potential real world impacts of the model\",\n",
    "            'performance_measures': \"Model performance measures\",\n",
    "            'thresholds': \"Decision thresholds\",\n",
    "            'variation_approaches': \"Variation approaches\"\n",
    "        },\n",
    "        'evaluation_data': {\n",
    "            'field_description': \"Details on the dataset(s) used for the quantitative analyses in the documentation\",\n",
    "            'datasets': \"Datasets\",\n",
    "            'motivation': \"Motivation\",\n",
    "            'preprocessing': \"Preprocessing\"\n",
    "        },\n",
    "        'training_data': {\n",
    "            'field_description': \"\"\"\n",
    "            May not be possible to provide in practice. When possible, this section should mirror 'Evaluation Data'. \n",
    "            If such detail is not possible, minimal allowable information should be provided here, \n",
    "            such as details of the distribution over various factors in the training datasets.\"\"\",\n",
    "            'training_data': \"Information on training data\"\n",
    "        },\n",
    "        'quant_analyses': {\n",
    "            'field_description': \"Quantitative Analyses\",\n",
    "            'unitary': \"Unitary results\",\n",
    "            'intersectional': \"Intersectional results\"\n",
    "        },\n",
    "        'ethical_considerations': {\n",
    "            'field_description': \"\"\"\n",
    "            Ethical considerations that went into model development, surfacing ethical challenges and \n",
    "            solutions to stakeholders. Ethical analysis does not always lead to precise solutions, but the process \n",
    "            of ethical contemplation is worthwhile to inform on responsible practices and next steps in future work.\"\"\",\n",
    "            'sensitive_data': \"Does the model use any sensitive data (e.g., protected classes)?\",\n",
    "            'human_life': \"Is the model intended to inform decisions about mat- ters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?\",\n",
    "            'mitigations': \"What risk mitigation strategies were used during model development?\",\n",
    "            'risks_and_harms': \"\"\"\n",
    "            What risks may be present in model usage? Try to identify the potential recipients, likelihood, and magnitude of harms. \n",
    "            If these cannot be determined, note that they were consid- ered but remain unknown\"\"\",\n",
    "            'use_cases': \"Are there any known model use cases that are especially fraught?\",\n",
    "            'additional_information': \"\"\"\n",
    "            If possible, this section should also include any additional ethical considerations that went into model development, \n",
    "            for example, review by an external board, or testing with a specific community.\"\"\"\n",
    "        },\n",
    "        'caveats_recommendations': {\n",
    "            'field_description': \"Additional concerns that were not covered in the previous sections\",\n",
    "            'caveats': \"For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?\",\n",
    "            'recommendations': \"Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self, file_path=\"\", autofill=True, indent_level=2):\n",
    "        self.file_path = file_path\n",
    "        self.autofill = autofill\n",
    "        self.indent_level = indent_level\n",
    "        self.setup_template()\n",
    "        if self.autofill:\n",
    "            self.autofill_template()            \n",
    "\n",
    "    def autofill_template(self):\n",
    "        \"\"\"Creates an empty model card template, then fills it with information that is automatically obtained from the system\"\"\"\n",
    "        auto_info = {\n",
    "            'model_details': {\n",
    "                'developer': get_username(),\n",
    "                'datetime': get_datetime()\n",
    "            }\n",
    "        }\n",
    "        self.fill_info(auto_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"ModelCard\" class=\"doc_header\"><code>class</code> <code>ModelCard</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>ModelCard</code>(**`file_path`**=*`''`*, **`autofill`**=*`True`*, **`indent_level`**=*`2`*) :: [`ggdModelDocumentation`](/gingado/documentation.html#ggdModelDocumentation)\n",
       "\n",
       "Base class for gingado Documenters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModelCard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a Documenter object, such as `ModelCard` is instanciated, the user can see the underlying template with the module `show_template`, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_details\": {\n",
      "    \"field_description\": \"Basic information about the model\",\n",
      "    \"developer\": \"Person or organisation developing the model\",\n",
      "    \"datetime\": \"Model date\",\n",
      "    \"version\": \"Model version\",\n",
      "    \"type\": \"Model type\",\n",
      "    \"info\": \"Information about training algorithms, parameters, fairness constraints or other applied approaches, and features\",\n",
      "    \"paper\": \"Paper or other resource for more information\",\n",
      "    \"citation\": \"Citation details\",\n",
      "    \"license\": \"License\",\n",
      "    \"contact\": \"Where to send questions or comments about the model\"\n",
      "  },\n",
      "  \"intended_use\": {\n",
      "    \"field_description\": \"Use cases that were envisioned during development\",\n",
      "    \"primary_uses\": \"Primary intended uses\",\n",
      "    \"primary_users\": \"Primary intended users\",\n",
      "    \"out_of_scope\": \"Out-of-scope use cases\"\n",
      "  },\n",
      "  \"factors\": {\n",
      "    \"field_description\": \"Factors could include demographic or phenotypic groups, environmental conditions, technical attributes, or others\",\n",
      "    \"relevant\": \"Relevant factors\",\n",
      "    \"evaluation\": \"Evaluation factors\"\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"field_description\": \"Metrics should be chosen to reflect potential real world impacts of the model\",\n",
      "    \"performance_measures\": \"Model performance measures\",\n",
      "    \"thresholds\": \"Decision thresholds\",\n",
      "    \"variation_approaches\": \"Variation approaches\"\n",
      "  },\n",
      "  \"evaluation_data\": {\n",
      "    \"field_description\": \"Details on the dataset(s) used for the quantitative analyses in the documentation\",\n",
      "    \"datasets\": \"Datasets\",\n",
      "    \"motivation\": \"Motivation\",\n",
      "    \"preprocessing\": \"Preprocessing\"\n",
      "  },\n",
      "  \"training_data\": {\n",
      "    \"field_description\": \"\\n            May not be possible to provide in practice. When possible, this section should mirror 'Evaluation Data'. \\n            If such detail is not possible, minimal allowable information should be provided here, \\n            such as details of the distribution over various factors in the training datasets.\",\n",
      "    \"training_data\": \"Information on training data\"\n",
      "  },\n",
      "  \"quant_analyses\": {\n",
      "    \"field_description\": \"Quantitative Analyses\",\n",
      "    \"unitary\": \"Unitary results\",\n",
      "    \"intersectional\": \"Intersectional results\"\n",
      "  },\n",
      "  \"ethical_considerations\": {\n",
      "    \"field_description\": \"\\n            Ethical considerations that went into model development, surfacing ethical challenges and \\n            solutions to stakeholders. Ethical analysis does not always lead to precise solutions, but the process \\n            of ethical contemplation is worthwhile to inform on responsible practices and next steps in future work.\",\n",
      "    \"sensitive_data\": \"Does the model use any sensitive data (e.g., protected classes)?\",\n",
      "    \"human_life\": \"Is the model intended to inform decisions about mat- ters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?\",\n",
      "    \"mitigations\": \"What risk mitigation strategies were used during model development?\",\n",
      "    \"risks_and_harms\": \"\\n            What risks may be present in model usage? Try to identify the potential recipients, likelihood, and magnitude of harms. \\n            If these cannot be determined, note that they were consid- ered but remain unknown\",\n",
      "    \"use_cases\": \"Are there any known model use cases that are especially fraught?\",\n",
      "    \"additional_information\": \"\\n            If possible, this section should also include any additional ethical considerations that went into model development, \\n            for example, review by an external board, or testing with a specific community.\"\n",
      "  },\n",
      "  \"caveats_recommendations\": {\n",
      "    \"field_description\": \"Additional concerns that were not covered in the previous sections\",\n",
      "    \"caveats\": \"For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?\",\n",
      "    \"recommendations\": \"Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_doc = ModelCard(autofill=True)\n",
    "model_doc.show_template()\n",
    "\n",
    "assert model_doc.show_template(indent=False) == ModelCard.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template should be protected from editing once a Documenter has been created. This way, even if a user unwarrantedly changes the template, this does not interfere with the Documenter functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_details\": {\n",
      "    \"field_description\": \"Basic information about the model\",\n",
      "    \"developer\": \"Person or organisation developing the model\",\n",
      "    \"datetime\": \"Model date\",\n",
      "    \"version\": \"Model version\",\n",
      "    \"type\": \"Model type\",\n",
      "    \"info\": \"Information about training algorithms, parameters, fairness constraints or other applied approaches, and features\",\n",
      "    \"paper\": \"Paper or other resource for more information\",\n",
      "    \"citation\": \"Citation details\",\n",
      "    \"license\": \"License\",\n",
      "    \"contact\": \"Where to send questions or comments about the model\"\n",
      "  },\n",
      "  \"intended_use\": {\n",
      "    \"field_description\": \"Use cases that were envisioned during development\",\n",
      "    \"primary_uses\": \"Primary intended uses\",\n",
      "    \"primary_users\": \"Primary intended users\",\n",
      "    \"out_of_scope\": \"Out-of-scope use cases\"\n",
      "  },\n",
      "  \"factors\": {\n",
      "    \"field_description\": \"Factors could include demographic or phenotypic groups, environmental conditions, technical attributes, or others\",\n",
      "    \"relevant\": \"Relevant factors\",\n",
      "    \"evaluation\": \"Evaluation factors\"\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"field_description\": \"Metrics should be chosen to reflect potential real world impacts of the model\",\n",
      "    \"performance_measures\": \"Model performance measures\",\n",
      "    \"thresholds\": \"Decision thresholds\",\n",
      "    \"variation_approaches\": \"Variation approaches\"\n",
      "  },\n",
      "  \"evaluation_data\": {\n",
      "    \"field_description\": \"Details on the dataset(s) used for the quantitative analyses in the documentation\",\n",
      "    \"datasets\": \"Datasets\",\n",
      "    \"motivation\": \"Motivation\",\n",
      "    \"preprocessing\": \"Preprocessing\"\n",
      "  },\n",
      "  \"training_data\": {\n",
      "    \"field_description\": \"\\n            May not be possible to provide in practice. When possible, this section should mirror 'Evaluation Data'. \\n            If such detail is not possible, minimal allowable information should be provided here, \\n            such as details of the distribution over various factors in the training datasets.\",\n",
      "    \"training_data\": \"Information on training data\"\n",
      "  },\n",
      "  \"quant_analyses\": {\n",
      "    \"field_description\": \"Quantitative Analyses\",\n",
      "    \"unitary\": \"Unitary results\",\n",
      "    \"intersectional\": \"Intersectional results\"\n",
      "  },\n",
      "  \"ethical_considerations\": {\n",
      "    \"field_description\": \"\\n            Ethical considerations that went into model development, surfacing ethical challenges and \\n            solutions to stakeholders. Ethical analysis does not always lead to precise solutions, but the process \\n            of ethical contemplation is worthwhile to inform on responsible practices and next steps in future work.\",\n",
      "    \"sensitive_data\": \"Does the model use any sensitive data (e.g., protected classes)?\",\n",
      "    \"human_life\": \"Is the model intended to inform decisions about mat- ters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?\",\n",
      "    \"mitigations\": \"What risk mitigation strategies were used during model development?\",\n",
      "    \"risks_and_harms\": \"\\n            What risks may be present in model usage? Try to identify the potential recipients, likelihood, and magnitude of harms. \\n            If these cannot be determined, note that they were consid- ered but remain unknown\",\n",
      "    \"use_cases\": \"Are there any known model use cases that are especially fraught?\",\n",
      "    \"additional_information\": \"\\n            If possible, this section should also include any additional ethical considerations that went into model development, \\n            for example, review by an external board, or testing with a specific community.\"\n",
      "  },\n",
      "  \"caveats_recommendations\": {\n",
      "    \"field_description\": \"Additional concerns that were not covered in the previous sections\",\n",
      "    \"caveats\": \"For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?\",\n",
      "    \"recommendations\": \"Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_doc.template = None\n",
    "model_doc.show_template()\n",
    "\n",
    "assert model_doc.show_template(indent=False) == ModelCard.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template serves to provide specific instances of the Documenter object with a form-like structure, indicating which fields are open and thus require some answers or information. Consequently, the template should also not change when the actual document object changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['test'], {'field_description': 'Metrics should be chosen to reflect potential real world impacts of the model', 'performance_measures': 'Model performance measures', 'thresholds': 'Decision thresholds', 'variation_approaches': 'Variation approaches'}]\n"
     ]
    }
   ],
   "source": [
    "model_doc.fill_info({'metrics': ['test']})\n",
    "print([model_doc.json_doc['metrics'], ModelCard.template['metrics']])\n",
    "\n",
    "assert model_doc.show_template(indent=False) == ModelCard.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `show_template` prints the Documenter's documentation template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc.show_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can find which fields in their templates are still without response by using the module `open_questions`. The levels of the template are reflected in the resulting dictionary: double underscores separate levels in the underlying JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_details__developer',\n",
       " 'model_details__datetime',\n",
       " 'model_details__version',\n",
       " 'model_details__type',\n",
       " 'model_details__info',\n",
       " 'model_details__paper',\n",
       " 'model_details__citation',\n",
       " 'model_details__license',\n",
       " 'model_details__contact',\n",
       " 'intended_use__primary_uses',\n",
       " 'intended_use__primary_users',\n",
       " 'intended_use__out_of_scope',\n",
       " 'factors__relevant',\n",
       " 'factors__evaluation',\n",
       " 'metrics__performance_measures',\n",
       " 'metrics__thresholds',\n",
       " 'metrics__variation_approaches',\n",
       " 'evaluation_data__datasets',\n",
       " 'evaluation_data__motivation',\n",
       " 'evaluation_data__preprocessing',\n",
       " 'training_data__training_data',\n",
       " 'quant_analyses__unitary',\n",
       " 'quant_analyses__intersectional',\n",
       " 'ethical_considerations__sensitive_data',\n",
       " 'ethical_considerations__human_life',\n",
       " 'ethical_considerations__mitigations',\n",
       " 'ethical_considerations__risks_and_harms',\n",
       " 'ethical_considerations__use_cases',\n",
       " 'ethical_considerations__additional_information',\n",
       " 'caveats_recommendations__caveats',\n",
       " 'caveats_recommendations__recommendations']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc.open_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user wants to fill in an empty field such as the ones identified above by the method `open_questions`, the user simply needs to pass to the module `fill_info` a dictionary with the corresponding information. Depending on the template, the dictionary may be nested. \n",
    "\n",
    "> Note: it is technically possible to attribute the element directly to the attribute `json_doc`, but this should be avoided in favour of using the method `fill_info`. The latter tests whether the new information is valid according to the documentation template and also enables the filling of more than one question at the same time. Importantly, attributing information directly to `json_doc` is not logged, and may unwarrantedly create new entries that are not part of the template (eg, if a new dictionary key is created due to typos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_info = {\n",
    "    'metrics': {'performance_measures': \"This is a test\"},\n",
    "    'caveats_recommendations': {'caveats': \"This is another test\"}\n",
    "    }\n",
    "model_doc.fill_info(new_info)\n",
    "\n",
    "# technically possible but not recommended:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can check that the corresponding entry is part of the documentation, and thus no longer shown as an open question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model_doc.json_doc['caveats_recommendations']['caveats'] == \"This is another test\"\n",
    "model_doc.open_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_info\n",
    "new_info2 = dict(new_info)\n",
    "new_info2['metrics'] = None\n",
    "new_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a custom Documenter\n",
    "\n",
    "`gingado` users can easily transform their model documentation needs into a Documenter object. The main advantages of doing this are: \n",
    "* the documentation template becomes a \"recyclable\" object that can be saved, loaded, and used in other models or code routines; and\n",
    "* model documentation can be more closely aligned with model creation and training, thus decreasing the probability that the model and its documentation diverge during the process of model development.\n",
    "\n",
    "The requirements for an object to be a `gingado` Documenter are:\n",
    "* it must subclass `ggdModelDocumentation` (or implement all its methods if the user does not want to keep a dependency to `gingado`),\n",
    "* include the actual template for the documentation as a dictionary in a class attribute called `template`,\n",
    "* follow the `scikit-learn` convention of storing the `__init__` parameters in attributes with the same name,\n",
    "* implement the `autofill_template` method using the `fill_info` method to set the automatically filled information fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv_gingado': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
