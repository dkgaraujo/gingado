{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "description: Functions to support the use of `gingado`\n",
    "output-file: utils.html\n",
    "title: Utils\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq gingado nbdev # install or upgrade gingado on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| default_exp utils\n",
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| echo: false\n",
    "\n",
    "# Code below included to ensure compatibility with scikit-learn v1.1.x\n",
    "from sklearn import set_config\n",
    "set_config(display='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for model documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "def get_datetime():\n",
    "    \"Returns the time now\"\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S %Z\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L13){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_datetime\n",
       "\n",
       ">      get_datetime ()\n",
       "\n",
       "Returns the time now"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L13){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_datetime\n",
       "\n",
       ">      get_datetime ()\n",
       "\n",
       "Returns the time now"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_datetime()\n",
    "assert isinstance(d, str)\n",
    "assert len(d) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "def read_attr(\n",
    "    obj # Object from which to attributes will be read\n",
    "):\n",
    "    \"Read object type and values of attributes from fitted object\"\n",
    "    for a in dir(obj):\n",
    "        # if statement filters out non-interesting attributes\n",
    "        if a == '_estimator_type' or (a.endswith(\"_\") and not a.startswith(\"_\") and not a.endswith(\"__\")):\n",
    "            try:\n",
    "                model_attr = obj.__getattribute__(a)\n",
    "                yield {a: model_attr}\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### read_attr\n",
       "\n",
       ">      read_attr (obj)\n",
       "\n",
       "Read object type and values of attributes from fitted object\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| obj | Object from which to attributes will be read |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### read_attr\n",
       "\n",
       ">      read_attr (obj)\n",
       "\n",
       "Read object type and values of attributes from fitted object\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| obj | Object from which to attributes will be read |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(read_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `read_attr` helps gingado Documenters to read the object behind the scenes.\n",
    "\n",
    "It collects the type of estimator, and any attributes resulting from fitting an object (in ie, those that end in \"_\" without being double underscores).\n",
    "\n",
    "For example, the attributes of an untrained and a trained random forest are, in sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/p8z57lqd55xfk68xz34dg0s40000gn/T/ipykernel_45335/3975710638.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  .fit([[1, 0], [0, 1]], [[0.5], [0.5]]) # random numbers\n",
      "/Users/douglasaraujo/Coding/.venv_gingado/lib/python3.10/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `n_features_` was deprecated in version 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'_estimator_type': 'regressor'}],\n",
       " [{'_estimator_type': 'regressor'},\n",
       "  {'base_estimator_': DecisionTreeRegressor()},\n",
       "  {'estimators_': [DecisionTreeRegressor(max_features=1.0, random_state=1632148864),\n",
       "    DecisionTreeRegressor(max_features=1.0, random_state=1616501356),\n",
       "    DecisionTreeRegressor(max_features=1.0, random_state=2109419996)]},\n",
       "  {'feature_importances_': array([0., 0.])},\n",
       "  {'n_features_': 2},\n",
       "  {'n_features_in_': 2},\n",
       "  {'n_outputs_': 1}])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_unfit = RandomForestRegressor(n_estimators=3)\n",
    "rf_fit = RandomForestRegressor(n_estimators=3)\\\n",
    "    .fit([[1, 0], [0, 1]], [[0.5], [0.5]]) # random numbers\n",
    "list(read_attr(rf_unfit)), list(read_attr(rf_fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for time series\n",
    "\n",
    "Objects of the class `Lag` are similar to `scikit-learn`'s transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "\n",
    "class Lag(BaseEstimator, TransformerMixin):\n",
    "    \"A transformer that lags variables\"\n",
    "    def __init__(self, lags=1, jump=0, keep_contemporaneous_X=False):\n",
    "        self.lags = lags\n",
    "        self.jump = jump\n",
    "        self.keep_contemporaneous_X = keep_contemporaneous_X\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        X:np.ndarray, # Array-like data of shape (n_samples, n_features)\n",
    "        y=None # Array-like data of shape (n_samples,) or (n_samples, n_targets) or None\n",
    "    ): # A fitted version of the `Lag` instance\n",
    "        \"Fit the `Lag` transformer\"       \n",
    "        self.index = None\n",
    "        if hasattr(X, \"index\"):\n",
    "            self.index = X.index\n",
    "        else:\n",
    "            if y is not None and hasattr(y, \"index\"):\n",
    "                self.index = y.index\n",
    "        X = self._validate_data(X)\n",
    "\n",
    "        self.effective_lags_ = self.lags + self.jump\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, \n",
    "        X:np.ndarray, # Array-like data of shape (n_samples, n_features)\n",
    "    ): # A lagged version of `X`\n",
    "        \"Lag the dataset `X`\"\n",
    "        X_forlag = X\n",
    "        \n",
    "        X = self._validate_data(X)\n",
    "        check_is_fitted(self)\n",
    "        X_lags = []\n",
    "        X_colnames = list(self.feature_names_in_) if self.keep_contemporaneous_X else []\n",
    "        for lag in range(self.effective_lags_):\n",
    "            if lag < self.jump:\n",
    "                continue\n",
    "            lag_count = lag+1\n",
    "            lag_X = np.roll(X_forlag, lag_count, axis=0)\n",
    "            X_lags.append(lag_X)\n",
    "            if hasattr(self, \"feature_names_in_\"):\n",
    "                X_colnames = X_colnames + [col+\"_lag_\"+str(lag+1) for col in list(self.feature_names_in_)]\n",
    "        X = np.concatenate(X_lags, axis=1)\n",
    "        if self.keep_contemporaneous_X:\n",
    "            X = np.concatenate([X_forlag, X], axis=1)\n",
    "        X = X[self.effective_lags_:, :]\n",
    "        if hasattr(self, \"index\") and self.index is not None:\n",
    "            new_index = self.index[self.effective_lags_:]\n",
    "            X = pd.DataFrame(X, index=new_index, columns=X_colnames)\n",
    "        else:\n",
    "            X = pd.DataFrame(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L44){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Lag\n",
       "\n",
       ">      Lag (lags=1, jump=0, keep_contemporaneous_X=False)\n",
       "\n",
       "A transformer that lags variables"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L44){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Lag\n",
       "\n",
       ">      Lag (lags=1, jump=0, keep_contemporaneous_X=False)\n",
       "\n",
       "A transformer that lags variables"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L51){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Lag.fit\n",
       "\n",
       ">      Lag.fit (X:numpy.ndarray, y=None)\n",
       "\n",
       "Fit the `Lag` transformer\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | ndarray |  | Array-like data of shape (n_samples, n_features) |\n",
       "| y | NoneType | None | Array-like data of shape (n_samples,) or (n_samples, n_targets) or None |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L51){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Lag.fit\n",
       "\n",
       ">      Lag.fit (X:numpy.ndarray, y=None)\n",
       "\n",
       "Fit the `Lag` transformer\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | ndarray |  | Array-like data of shape (n_samples, n_features) |\n",
       "| y | NoneType | None | Array-like data of shape (n_samples,) or (n_samples, n_targets) or None |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Lag.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L68){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Lag.transform\n",
       "\n",
       ">      Lag.transform (X:numpy.ndarray)\n",
       "\n",
       "Lag the dataset `X`\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Array-like data of shape (n_samples, n_features) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L68){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Lag.transform\n",
       "\n",
       ">      Lag.transform (X:numpy.ndarray)\n",
       "\n",
       "Lag the dataset `X`\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Array-like data of shape (n_samples, n_features) |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Lag.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### TransformerMixin.fit_transform\n",
       "\n",
       ">      TransformerMixin.fit_transform (X, y=None, **fit_params)\n",
       "\n",
       "Fit to data, then transform it.\n",
       "\n",
       "Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
       "and returns a transformed version of `X`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | array-like of shape (n_samples, n_features) |  | Input samples. |\n",
       "| y | NoneType | None | Target values (None for unsupervised transformations). |\n",
       "| fit_params |  |  |  |\n",
       "| **Returns** | **ndarray array of shape (n_samples, n_features_new)** |  | **Transformed array.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### TransformerMixin.fit_transform\n",
       "\n",
       ">      TransformerMixin.fit_transform (X, y=None, **fit_params)\n",
       "\n",
       "Fit to data, then transform it.\n",
       "\n",
       "Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
       "and returns a transformed version of `X`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | array-like of shape (n_samples, n_features) |  | Input samples. |\n",
       "| y | NoneType | None | Target values (None for unsupervised transformations). |\n",
       "| fit_params |  |  |  |\n",
       "| **Returns** | **ndarray array of shape (n_samples, n_features_new)** |  | **Transformed array.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Lag.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates how `Lag` works in practice. Note in particular that, because `Lag` is a transformer, it can be used as part of a `scikit-learn`'s `Pipeline`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomX = np.random.rand(15, 2)\n",
    "randomY = np.random.rand(15)\n",
    "\n",
    "lags = 3\n",
    "jump = 2\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lagger', Lag(lags=lags, jump=jump, keep_contemporaneous_X=False))\n",
    "]).fit_transform(randomX, randomY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we confirm that the lagger removes the correct number of rows corresponding to the lagged observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert randomX.shape[0] - lags - jump == pipe.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And because `Lag` is a transformer, its parameters (`lags` and `jump`) can be calibrated using hyperparameter tuning to achieve the best performance for a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for data augmentation with SDMX\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "please note that working with SDMX may take some minutes depending on the amount of information you are downloading.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "import pandasdmx as sdmx\n",
    "\n",
    "def list_SDMX_sources(): # The list of codes representing the SDMX sources available for data download\n",
    "    \"Fetch the list of SDMX sources\"\n",
    "    return sdmx.list_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L102){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### list_SDMX_sources\n",
       "\n",
       ">      list_SDMX_sources ()\n",
       "\n",
       "Fetch the list of SDMX sources"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L102){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### list_SDMX_sources\n",
       "\n",
       ">      list_SDMX_sources ()\n",
       "\n",
       "Fetch the list of SDMX sources"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(list_SDMX_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABS', 'ABS_XML', 'BBK', 'BIS', 'CD2030', 'ECB', 'ESTAT', 'ILO', 'IMF', 'INEGI', 'INSEE', 'ISTAT', 'LSD', 'NB', 'NBB', 'OECD', 'SGR', 'SPC', 'STAT_EE', 'UNICEF', 'UNSD', 'WB', 'WB_WDI']\n"
     ]
    }
   ],
   "source": [
    "sources = list_SDMX_sources()\n",
    "print(sources)\n",
    "\n",
    "assert len(sources) > 0\n",
    "# all elements are of type 'str'\n",
    "assert sum([isinstance(src, str) for src in sources]) == len(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "import pandas as pd\n",
    "import pandasdmx as sdmx\n",
    "\n",
    "def list_all_dataflows(\n",
    "    codes_only:bool=False, # Whether to return only the dataflow codes\n",
    "    return_pandas:bool=True # Whether to return the result in a pandas DataFrame format\n",
    "): # All available dataflows for all SDMX sources used by gingado\n",
    "    \"List all SDMX dataflows. Note: When using as a parameter to an `AugmentSDMX` object or to the `load_SDMX_data` function, set `codes_only=True`\"\n",
    "    sources = sdmx.list_sources()\n",
    "    dflows = {}\n",
    "    for src in sources:\n",
    "        try:\n",
    "            dflows[src] = sdmx.to_pandas(sdmx.Request(src).dataflow().dataflow)\n",
    "            dflows[src] = dflows[src].index if codes_only else dflows[src].index.reset_index()\n",
    "        except:\n",
    "            pass\n",
    "    if return_pandas:\n",
    "        dflows = pd.concat({\n",
    "            src: pd.DataFrame.from_dict(dflows)\n",
    "            for src, dflows in dflows.items()\n",
    "            })[0].rename('dataflow')\n",
    "    return dflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L111){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### list_all_dataflows\n",
       "\n",
       ">      list_all_dataflows (codes_only:bool=False, return_pandas:bool=True)\n",
       "\n",
       "List all SDMX dataflows. Note: When using as a parameter to an `AugmentSDMX` object or to the `load_SDMX_data` function, set `codes_only=True`\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| codes_only | bool | False | Whether to return only the dataflow codes |\n",
       "| return_pandas | bool | True | Whether to return the result in a pandas DataFrame format |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L111){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### list_all_dataflows\n",
       "\n",
       ">      list_all_dataflows (codes_only:bool=False, return_pandas:bool=True)\n",
       "\n",
       "List all SDMX dataflows. Note: When using as a parameter to an `AugmentSDMX` object or to the `load_SDMX_data` function, set `codes_only=True`\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| codes_only | bool | False | Whether to return only the dataflow codes |\n",
       "| return_pandas | bool | True | Whether to return the result in a pandas DataFrame format |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(list_all_dataflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 00:49:48,202 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:50:09,352 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:50:10,173 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:50:19,614 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:50:20,660 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n"
     ]
    }
   ],
   "source": [
    "dflows = list_all_dataflows(return_pandas=False)\n",
    "\n",
    "assert isinstance(dflows, dict)\n",
    "all_sources = list_SDMX_sources()\n",
    "assert len([s for s in dflows.keys() if s in all_sources]) == len(dflows.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_all_dataflows` returns by default a pandas Series, facilitating data discovery by users like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 00:50:44,400 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:51:09,450 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:51:10,058 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:51:14,175 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:51:19,057 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ABS_XML  ABORIGINAL_POP_PROJ                 Projected population, Aboriginal and Torres St...\n",
       "         ABORIGINAL_POP_PROJ_REMOTE          Projected population, Aboriginal and Torres St...\n",
       "         ABS_ABORIGINAL_POPPROJ_INDREGION    Projected population, Aboriginal and Torres St...\n",
       "         ABS_ACLD_LFSTATUS                   Australian Census Longitudinal Dataset (ACLD):...\n",
       "         ABS_ACLD_TENURE                     Australian Census Longitudinal Dataset (ACLD):...\n",
       "                                                                   ...                        \n",
       "UNSD     DF_UNData_UNFCC                                                       SDMX_GHG_UNDATA\n",
       "WB       DF_WITS_Tariff_TRAINS                                WITS - UNCTAD TRAINS Tariff Data\n",
       "         DF_WITS_TradeStats_Development                             WITS TradeStats Devlopment\n",
       "         DF_WITS_TradeStats_Tariff                                      WITS TradeStats Tariff\n",
       "         DF_WITS_TradeStats_Trade                                        WITS TradeStats Trade\n",
       "Name: dataflow, Length: 3290, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflows = list_all_dataflows(return_pandas=True)\n",
    "assert type(dflows) == pd.core.series.Series\n",
    "\n",
    "dflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format allows for more easily searching `dflows` by source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 00:51:51,419 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:51:57,339 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:52:15,569 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:52:16,277 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2023-09-16 00:52:18,956 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ABS_XML  0                 ABORIGINAL_POP_PROJ\n",
       "         1          ABORIGINAL_POP_PROJ_REMOTE\n",
       "         2    ABS_ABORIGINAL_POPPROJ_INDREGION\n",
       "         3                   ABS_ACLD_LFSTATUS\n",
       "         4                     ABS_ACLD_TENURE\n",
       "                            ...               \n",
       "UNSD     5                     DF_UNData_UNFCC\n",
       "WB       0               DF_WITS_Tariff_TRAINS\n",
       "         1      DF_WITS_TradeStats_Development\n",
       "         2           DF_WITS_TradeStats_Tariff\n",
       "         3            DF_WITS_TradeStats_Trade\n",
       "Name: dataflow, Length: 3290, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_all_dataflows(codes_only=True, return_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WS_CBPOL_D                                    Policy rates daily\n",
       "WS_CBPOL_M                                  Policy rates monthly\n",
       "WS_CBS_PUB                              BIS consolidated banking\n",
       "WS_CPMI_CASHLESS                   CPMI cashless payments (T5-6)\n",
       "WS_CPMI_CT1                       CPMI comparative tables type 1\n",
       "WS_CPMI_CT2                       CPMI comparative tables type 2\n",
       "WS_CPMI_DEVICES                             CPMI payment devices\n",
       "WS_CPMI_INSTITUTIONS                           CPMI institutions\n",
       "WS_CPMI_MACRO                                         CPMI Macro\n",
       "WS_CPMI_PARTICIPANTS                           CPMI participants\n",
       "WS_CPMI_SYSTEMS         CPMI systems (T8-9-11-13-14-16-17-18-19)\n",
       "WS_CREDIT_GAP                             BIS credit-to-GDP gaps\n",
       "WS_DEBT_SEC2_PUB                             BIS debt securities\n",
       "WS_DER_OTC_TOV                          OTC derivatives turnover\n",
       "WS_DSR                                    BIS debt service ratio\n",
       "WS_EER_D                      BIS effective exchange rates daily\n",
       "WS_EER_M                    BIS effective exchange rates monthly\n",
       "WS_GLI                               Global liquidity indicators\n",
       "WS_LBS_D_PUB                              BIS locational banking\n",
       "WS_LONG_CPI                             BIS long consumer prices\n",
       "WS_OTC_DERIV2                        OTC derivatives outstanding\n",
       "WS_SPP                      BIS property prices: selected series\n",
       "WS_TC                            BIS long series on total credit\n",
       "WS_XRU                           US dollar exchange rates, m,q,a\n",
       "WS_XRU_D                         US dollar exchange rates, daily\n",
       "WS_XTD_DERIV                         Exchange traded derivatives\n",
       "Name: dataflow, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflows['BIS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the user can search dataflows by their human-readable name instead of their code. For example, this is one way to see if any dataflow has information on interest rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BBK  BBSDI       Discount interest rates pursuant to section 25...\n",
       "ECB  RIR                                     Retail Interest Rates\n",
       "IMF  6SR         M&B: Interest Rates and Share Prices (6SR) for...\n",
       "     INR                                            Interest rates\n",
       "     INR_NSTD                          Interest rates_Non-Standard\n",
       "Name: dataflow, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflows[dflows.str.contains('Interest rates', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `load_SDMX_data` is a convenience function that downloads data from SDMX sources (and any specific dataflows passed as arguments) if they match the key and parameters set by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| export\n",
    "import pandasdmx as sdmx\n",
    "\n",
    "def load_SDMX_data(\n",
    "    sources:dict, # A dictionary with the sources and dataflows per source\n",
    "    keys:dict, # The keys to be used in the SDMX query\n",
    "    params:dict, # The parameters to be used in the SDMX query\n",
    "    verbose:bool=True # Whether to communicate download steps to the user\n",
    "    ): # A pandas DataFrame with data from SDMX or None if no data matches the sources, keys and parameters\n",
    "    \"Loads datasets from SDMX.\"\n",
    "    data_sdmx = {}\n",
    "    for source in sources.keys():\n",
    "        src_conn = sdmx.Request(source)\n",
    "        src_dflows = src_conn.dataflow()\n",
    "        if sources[source] == 'all':\n",
    "            dflows = {k: v for k, v in src_dflows.dataflow.items()}\n",
    "        else:\n",
    "            dflows = {k: v for k, v in src_dflows.dataflow.items() if k in sources[source]}\n",
    "        for dflow in dflows.keys():\n",
    "            if verbose: print(f\"Querying data from {source}'s dataflow '{dflow}' - {dflows[dflow].dict()['name']}...\")\n",
    "            try:\n",
    "                data = sdmx.to_pandas(src_conn.data(dflow, key=keys, params=params), datetime='TIME_PERIOD')\n",
    "            except:\n",
    "                if verbose: print(\"this dataflow does not have data in the desired frequency and time period.\")\n",
    "                continue\n",
    "            data.columns = ['__'.join(col) for col in data.columns.to_flat_index()]\n",
    "            data_sdmx[source+\"__\"+dflow] = data\n",
    "\n",
    "    if len(data_sdmx.keys()) is None:\n",
    "        return\n",
    "\n",
    "    df = pd.concat(data_sdmx, axis=1)\n",
    "    df.columns = ['_'.join(col) for col in df.columns.to_flat_index()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L135){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### load_SDMX_data\n",
       "\n",
       ">      load_SDMX_data (sources:dict, keys:dict, params:dict, verbose:bool=True)\n",
       "\n",
       "Loads datasets from SDMX.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| sources | dict |  | A dictionary with the sources and dataflows per source |\n",
       "| keys | dict |  | The keys to be used in the SDMX query |\n",
       "| params | dict |  | The parameters to be used in the SDMX query |\n",
       "| verbose | bool | True | Whether to communicate download steps to the user |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/blob/main/gingado/utils.py#L135){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### load_SDMX_data\n",
       "\n",
       ">      load_SDMX_data (sources:dict, keys:dict, params:dict, verbose:bool=True)\n",
       "\n",
       "Loads datasets from SDMX.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| sources | dict |  | A dictionary with the sources and dataflows per source |\n",
       "| keys | dict |  | The keys to be used in the SDMX query |\n",
       "| params | dict |  | The parameters to be used in the SDMX query |\n",
       "| verbose | bool | True | Whether to communicate download steps to the user |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(load_SDMX_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 00:52:42,940 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from BIS's dataflow 'WS_CBPOL_D' - Policy rates daily...\n"
     ]
    }
   ],
   "source": [
    "df = load_SDMX_data(sources={'ECB': 'CISS', 'BIS': 'WS_CBPOL_D'}, keys={'FREQ': 'D'}, params={'startPeriod': 2003})\n",
    "\n",
    "assert type(df) == pd.DataFrame\n",
    "assert df.shape[0] > 0\n",
    "assert df.shape[1] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
