{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq gingado nbdev # install or upgrade gingado on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils\n",
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "> Functions to support the use of `gingado`\n",
    "\n",
    "- badges: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for model documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: Up until v0.0.1-11, function `get_username` existed. However, it was removed from `utils` since it depended on `pwd`, which is only available to Unix-like systems. Therefore, this [issue](https://github.com/dkgaraujo/gingado/issues/3) was preventing Windows users from importing `gingado.utils`. Since the function was not essential, it was removed until a suitable alternative that works in all major ystems can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "def get_datetime():\n",
    "    \"Returns the time now\"\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S %Z\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"get_datetime\" class=\"doc_header\"><code>get_datetime</code><a href=\"__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>get_datetime</code>()\n",
       "\n",
       "Returns the time now"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_datetime()\n",
    "assert isinstance(d, str)\n",
    "assert len(d) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for time series\n",
    "\n",
    "Objects of the class `Lag` are similar to `scikit-learn`'s transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class Lag(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lags=1, jump=0, keep_contemporaneous_X=False):\n",
    "        self.lags = lags\n",
    "        self.jump = jump\n",
    "        self.keep_contemporaneous_X = keep_contemporaneous_X\n",
    "    \n",
    "    def fit(self, X, y=None):        \n",
    "        self.index = None\n",
    "        if hasattr(X, \"index\"):\n",
    "            self.index = X.index\n",
    "        else:\n",
    "            if y is not None and hasattr(y, \"index\"):\n",
    "                self.index = y.index\n",
    "        X = self._validate_data(X)\n",
    "\n",
    "        self.effective_lags_ = self.lags + self.jump\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_forlag = X\n",
    "        \n",
    "        X = self._validate_data(X)\n",
    "        check_is_fitted(self)\n",
    "        X_lags = []\n",
    "        X_colnames = list(self.feature_names_in_) if self.keep_contemporaneous_X else []\n",
    "        for lag in range(self.effective_lags_):\n",
    "            if lag < self.jump:\n",
    "                continue\n",
    "            lag_count = lag+1\n",
    "            lag_X = np.roll(X_forlag, lag_count, axis=0)\n",
    "            X_lags.append(lag_X)\n",
    "            if hasattr(self, \"feature_names_in_\"):\n",
    "                X_colnames = X_colnames + [col+\"_lag_\"+str(lag+1) for col in list(self.feature_names_in_)]\n",
    "        X = np.concatenate(X_lags, axis=1)\n",
    "        if self.keep_contemporaneous_X:\n",
    "            X = np.concatenate([X_forlag, X], axis=1)\n",
    "        X = X[self.effective_lags_:, :]\n",
    "        if hasattr(self, \"index\") and self.index is not None:\n",
    "            new_index = self.index[self.effective_lags_:]\n",
    "            X = pd.DataFrame(X, index=new_index, columns=X_colnames)\n",
    "        else:\n",
    "            X = pd.DataFrame(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"Lag\" class=\"doc_header\"><code>class</code> <code>Lag</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>Lag</code>(**`lags`**=*`1`*, **`jump`**=*`0`*, **`keep_contemporaneous_X`**=*`False`*) :: `BaseEstimator`\n",
       "\n",
       "Base class for all estimators in scikit-learn.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "All estimators should specify all the parameters that can be set\n",
       "at the class level in their ``__init__`` as explicit keyword\n",
       "arguments (no ``*args`` or ``**kwargs``)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates how `Lag` works in practice. Note in particular that, because `Lag` is a transformer, it can be used as part of a `scikit-learn`'s `Pipeline`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "randomX = np.random.rand(15, 2)\n",
    "randomY = np.random.rand(15)\n",
    "\n",
    "lags = 3\n",
    "jump = 2\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lagger', Lag(lags=lags, jump=jump, keep_contemporaneous_X=False))\n",
    "]).fit_transform(randomX, randomY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we confirm that the lagger removes the correct number of rows corresponding to the lagged observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert randomX.shape[0] - lags - jump == pipe.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And because `Lag` is a transformer, its parameters (`lags` and `jump`) can be calibrated using hyperparameter tuning to achieve the best performance for a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for data augmentation with SDMX\n",
    "\n",
    "> Note: please note that working with SDMX may take some minutes depending on the amount of information you are downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandasdmx as sdmx\n",
    "\n",
    "def list_SDMX_sources():\n",
    "    \"Returns the list of codes representing the SDMX sources available for data download\"\n",
    "    return sdmx.list_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"list_SDMX_sources\" class=\"doc_header\"><code>list_SDMX_sources</code><a href=\"__main__.py#L5\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>list_SDMX_sources</code>()\n",
       "\n",
       "Returns the list of codes representing the SDMX sources available for data download"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(list_SDMX_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABS', 'ABS_XML', 'BBK', 'BIS', 'CD2030', 'ECB', 'ESTAT', 'ILO', 'IMF', 'INEGI', 'INSEE', 'ISTAT', 'LSD', 'NB', 'NBB', 'OECD', 'SGR', 'SPC', 'STAT_EE', 'UNICEF', 'UNSD', 'WB', 'WB_WDI']\n"
     ]
    }
   ],
   "source": [
    "sources = list_SDMX_sources()\n",
    "print(sources)\n",
    "\n",
    "assert len(sources) > 0\n",
    "# all elements are of type 'str'\n",
    "assert sum([isinstance(src, str) for src in sources]) == len(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandasdmx as sdmx\n",
    "\n",
    "def list_all_dataflows(codes_only=False):\n",
    "    \"Returns a dictionary listing all available dataflows for all sources. When using as a parameter to an `AugmentSDMX` object or to the `load_SDMX_data` function, set `codes_only=True`\"\n",
    "    sources = sdmx.list_sources()\n",
    "    dflows = {}\n",
    "    for src in sources:\n",
    "        try:\n",
    "            dflows[src] = sdmx.to_pandas(sdmx.Request(src).dataflow().dataflow)\n",
    "            dflows[src] = dflows[src].index if codes_only else dflows[src].index.reset_index()\n",
    "        except:\n",
    "            pass\n",
    "    return dflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"list_all_dataflows\" class=\"doc_header\"><code>list_all_dataflows</code><a href=\"__main__.py#L5\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>list_all_dataflows</code>(**`codes_only`**=*`False`*)\n",
       "\n",
       "Returns a dictionary listing all available dataflows for all sources. When using as a parameter to an [`AugmentSDMX`](/gingado/augmentation.html#AugmentSDMX) object or to the [`load_SDMX_data`](/gingado/utils.html#load_SDMX_data) function, set `codes_only=True`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(list_all_dataflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 22:58:08,594 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2022-05-31 22:59:46,534 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2022-05-31 22:59:53,245 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2022-05-31 22:59:57,240 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n",
      "2022-05-31 22:59:58,367 pandasdmx.reader.sdmxml - DEBUG: Truncate sub-microsecond time in <Prepared>\n"
     ]
    }
   ],
   "source": [
    "dflows = list_all_dataflows()\n",
    "\n",
    "assert isinstance(dflows, dict)\n",
    "all_sources = list_SDMX_sources()\n",
    "assert len([s for s in dflows.keys() if s in all_sources]) == len(dflows.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `load_SDMX_data` is a convenience function that downloads data from SDMX sources (and any specific dataflows passed as arguments) if they match the key and parameters set by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandasdmx as sdmx\n",
    "\n",
    "def load_SDMX_data(sources, keys, params, verbose=True):\n",
    "    \"Loads datasets from SDMX.\"\n",
    "    data_sdmx = {}\n",
    "    for source in sources.keys():\n",
    "        src_conn = sdmx.Request(source)\n",
    "        src_dflows = src_conn.dataflow()\n",
    "        if sources[source] == 'all':\n",
    "            dflows = {k: v for k, v in src_dflows.dataflow.items()}\n",
    "        else:\n",
    "            dflows = {k: v for k, v in src_dflows.dataflow.items() if k in sources[source]}\n",
    "        for dflow in dflows.keys():\n",
    "            if verbose: print(f\"Querying data from {source}'s dataflow '{dflow}' - {dflows[dflow].dict()['name']}...\")\n",
    "            try:\n",
    "                data = sdmx.to_pandas(src_conn.data(dflow, key=keys, params=params), datetime='TIME_PERIOD')\n",
    "            except:\n",
    "                if verbose: print(\"this dataflow does not have data in the desired frequency and time period.\")\n",
    "                continue\n",
    "            data.columns = ['__'.join(col) for col in data.columns.to_flat_index()]\n",
    "            data_sdmx[source+\"__\"+dflow] = data\n",
    "\n",
    "    if len(data_sdmx.keys()) is None:\n",
    "        return\n",
    "\n",
    "    df = pd.concat(data_sdmx, axis=1)\n",
    "    df.columns = ['_'.join(col) for col in df.columns.to_flat_index()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"load_SDMX_data\" class=\"doc_header\"><code>load_SDMX_data</code><a href=\"__main__.py#L5\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>load_SDMX_data</code>(**`sources`**, **`keys`**, **`params`**, **`verbose`**=*`True`*)\n",
       "\n",
       "Loads datasets from SDMX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(load_SDMX_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from ECB's dataflow 'CISS' - Composite Indicator of Systemic Stress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 01:43:59,553 pandasdmx.reader.sdmxml - INFO: Use supplied dsd=… argument for non–structure-specific message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from BIS's dataflow 'WS_CBPOL_D' - Policy rates daily...\n"
     ]
    }
   ],
   "source": [
    "df = load_SDMX_data(sources={'ECB': 'CISS', 'BIS': 'WS_CBPOL_D'}, keys={'FREQ': 'D'}, params={'startPeriod': 2003})\n",
    "\n",
    "assert type(df) == pd.DataFrame\n",
    "assert df.shape[0] > 0\n",
    "assert df.shape[1] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To be deprecated\n",
    "\n",
    "The function `load_EURFX_data` is a helper function to download a test dataset containing real life data. This dataset was chosen due to the assumption that most users have at least an intuitive understanding of what a foreign exchange is: the price of changing one currency for the other. This example dataset does not imply this data is more or less relevant than others; it is used only for pedagogical purposes.\n",
    "> Note: This function will be deprecated in `gingado` version 0.0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandasdmx as sdmx\n",
    "import warnings\n",
    "\n",
    "def load_EURFX_data(startYear=2003, lags=1, jump=0, keep_contemporaneous_X=True):\n",
    "    \"Loads a real-life dataset for testing use cases.\"\n",
    "    warnings.warn(message=\"Function 'load_EURFX_data' will no longer be present after gingado v0.0.2. Use 'load_SDMX_data(source={'ECB': 'EXR'}) instead.\", category=DeprecationWarning, stacklevel=2)\n",
    "    ecb = sdmx.Request('ECB')\n",
    "    exr_msg = ecb.dataflow('EXR')\n",
    "    exr_flow = exr_msg.dataflow.EXR\n",
    "    dsd = exr_flow.structure\n",
    "    key = {\n",
    "    \"CURRENCY\": ['EUR', 'AUD', 'BRL', 'CAD', 'CHF', 'GBP', 'JPY', 'SGD', 'USD'],\n",
    "    \"FREQ\": 'D'\n",
    "    }\n",
    "    params = {\"startPeriod\": startYear}\n",
    "    data_msg = ecb.data('EXR', key=key, params=params, dsd=dsd)\n",
    "    df = sdmx.to_pandas(data_msg.data[0], datetime='TIME_PERIOD')\n",
    "    df = df.droplevel(['FREQ', 'CURRENCY_DENOM', 'EXR_TYPE', 'EXR_SUFFIX'], axis=1).dropna(how='all')\n",
    "    \n",
    "    if lags or jump:\n",
    "        df = Lag(lags=lags, jump=jump, keep_contemporaneous_X=keep_contemporaneous_X).fit_transform(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"load_EURFX_data\" class=\"doc_header\"><code>load_EURFX_data</code><a href=\"__main__.py#L6\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>load_EURFX_data</code>(**`startYear`**=*`2003`*, **`lags`**=*`1`*, **`jump`**=*`0`*, **`keep_contemporaneous_X`**=*`True`*)\n",
       "\n",
       "Loads a real-life dataset for testing use cases."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(load_EURFX_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/p8z57lqd55xfk68xz34dg0s40000gn/T/ipykernel_32613/429544813.py:1: DeprecationWarning: Function 'load_EURFX_data' will no longer be present after gingado v0.0.2. Use 'load_SDMX_data(source={'ECB': 'EXR'}) instead.\n",
      "  EUR_FX = load_EURFX_data()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUD</th>\n",
       "      <th>BRL</th>\n",
       "      <th>CAD</th>\n",
       "      <th>CHF</th>\n",
       "      <th>GBP</th>\n",
       "      <th>JPY</th>\n",
       "      <th>SGD</th>\n",
       "      <th>USD</th>\n",
       "      <th>AUD_lag_1</th>\n",
       "      <th>BRL_lag_1</th>\n",
       "      <th>CAD_lag_1</th>\n",
       "      <th>CHF_lag_1</th>\n",
       "      <th>GBP_lag_1</th>\n",
       "      <th>JPY_lag_1</th>\n",
       "      <th>SGD_lag_1</th>\n",
       "      <th>USD_lag_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>1.8440</td>\n",
       "      <td>3.6112</td>\n",
       "      <td>1.6264</td>\n",
       "      <td>1.4555</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>124.56</td>\n",
       "      <td>1.8132</td>\n",
       "      <td>1.0392</td>\n",
       "      <td>1.8554</td>\n",
       "      <td>3.6770</td>\n",
       "      <td>1.6422</td>\n",
       "      <td>1.4528</td>\n",
       "      <td>0.65200</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8188</td>\n",
       "      <td>1.0446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>1.8281</td>\n",
       "      <td>3.5145</td>\n",
       "      <td>1.6383</td>\n",
       "      <td>1.4563</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8210</td>\n",
       "      <td>1.0488</td>\n",
       "      <td>1.8440</td>\n",
       "      <td>3.6112</td>\n",
       "      <td>1.6264</td>\n",
       "      <td>1.4555</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>124.56</td>\n",
       "      <td>1.8132</td>\n",
       "      <td>1.0392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>1.8160</td>\n",
       "      <td>3.5139</td>\n",
       "      <td>1.6257</td>\n",
       "      <td>1.4565</td>\n",
       "      <td>0.64960</td>\n",
       "      <td>124.82</td>\n",
       "      <td>1.8155</td>\n",
       "      <td>1.0425</td>\n",
       "      <td>1.8281</td>\n",
       "      <td>3.5145</td>\n",
       "      <td>1.6383</td>\n",
       "      <td>1.4563</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8210</td>\n",
       "      <td>1.0488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>1.8132</td>\n",
       "      <td>3.4405</td>\n",
       "      <td>1.6231</td>\n",
       "      <td>1.4586</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1.8102</td>\n",
       "      <td>1.0377</td>\n",
       "      <td>1.8160</td>\n",
       "      <td>3.5139</td>\n",
       "      <td>1.6257</td>\n",
       "      <td>1.4565</td>\n",
       "      <td>0.64960</td>\n",
       "      <td>124.82</td>\n",
       "      <td>1.8155</td>\n",
       "      <td>1.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-09</th>\n",
       "      <td>1.8172</td>\n",
       "      <td>3.4915</td>\n",
       "      <td>1.6371</td>\n",
       "      <td>1.4597</td>\n",
       "      <td>0.65300</td>\n",
       "      <td>125.16</td>\n",
       "      <td>1.8244</td>\n",
       "      <td>1.0507</td>\n",
       "      <td>1.8132</td>\n",
       "      <td>3.4405</td>\n",
       "      <td>1.6231</td>\n",
       "      <td>1.4586</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1.8102</td>\n",
       "      <td>1.0377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>1.5126</td>\n",
       "      <td>5.1736</td>\n",
       "      <td>1.3720</td>\n",
       "      <td>1.0269</td>\n",
       "      <td>0.85295</td>\n",
       "      <td>135.34</td>\n",
       "      <td>1.4676</td>\n",
       "      <td>1.0656</td>\n",
       "      <td>1.5152</td>\n",
       "      <td>5.1793</td>\n",
       "      <td>1.3714</td>\n",
       "      <td>1.0334</td>\n",
       "      <td>0.85750</td>\n",
       "      <td>136.49</td>\n",
       "      <td>1.4722</td>\n",
       "      <td>1.0720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-26</th>\n",
       "      <td>1.5110</td>\n",
       "      <td>5.1741</td>\n",
       "      <td>1.3715</td>\n",
       "      <td>1.0283</td>\n",
       "      <td>0.85073</td>\n",
       "      <td>135.95</td>\n",
       "      <td>1.4709</td>\n",
       "      <td>1.0697</td>\n",
       "      <td>1.5126</td>\n",
       "      <td>5.1736</td>\n",
       "      <td>1.3720</td>\n",
       "      <td>1.0269</td>\n",
       "      <td>0.85295</td>\n",
       "      <td>135.34</td>\n",
       "      <td>1.4676</td>\n",
       "      <td>1.0656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>1.4995</td>\n",
       "      <td>5.0959</td>\n",
       "      <td>1.3661</td>\n",
       "      <td>1.0258</td>\n",
       "      <td>0.84875</td>\n",
       "      <td>136.05</td>\n",
       "      <td>1.4679</td>\n",
       "      <td>1.0722</td>\n",
       "      <td>1.5110</td>\n",
       "      <td>5.1741</td>\n",
       "      <td>1.3715</td>\n",
       "      <td>1.0283</td>\n",
       "      <td>0.85073</td>\n",
       "      <td>135.95</td>\n",
       "      <td>1.4709</td>\n",
       "      <td>1.0697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-30</th>\n",
       "      <td>1.4982</td>\n",
       "      <td>5.0629</td>\n",
       "      <td>1.3647</td>\n",
       "      <td>1.0327</td>\n",
       "      <td>0.85150</td>\n",
       "      <td>137.25</td>\n",
       "      <td>1.4719</td>\n",
       "      <td>1.0764</td>\n",
       "      <td>1.4995</td>\n",
       "      <td>5.0959</td>\n",
       "      <td>1.3661</td>\n",
       "      <td>1.0258</td>\n",
       "      <td>0.84875</td>\n",
       "      <td>136.05</td>\n",
       "      <td>1.4679</td>\n",
       "      <td>1.0722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>1.4933</td>\n",
       "      <td>5.0965</td>\n",
       "      <td>1.3573</td>\n",
       "      <td>1.0281</td>\n",
       "      <td>0.85138</td>\n",
       "      <td>137.36</td>\n",
       "      <td>1.4687</td>\n",
       "      <td>1.0713</td>\n",
       "      <td>1.4982</td>\n",
       "      <td>5.0629</td>\n",
       "      <td>1.3647</td>\n",
       "      <td>1.0327</td>\n",
       "      <td>0.85150</td>\n",
       "      <td>137.25</td>\n",
       "      <td>1.4719</td>\n",
       "      <td>1.0764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4971 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AUD     BRL     CAD     CHF      GBP     JPY     SGD     USD  \\\n",
       "TIME_PERIOD                                                                    \n",
       "2003-01-03   1.8440  3.6112  1.6264  1.4555  0.65000  124.56  1.8132  1.0392   \n",
       "2003-01-06   1.8281  3.5145  1.6383  1.4563  0.64950  124.40  1.8210  1.0488   \n",
       "2003-01-07   1.8160  3.5139  1.6257  1.4565  0.64960  124.82  1.8155  1.0425   \n",
       "2003-01-08   1.8132  3.4405  1.6231  1.4586  0.64950  124.90  1.8102  1.0377   \n",
       "2003-01-09   1.8172  3.4915  1.6371  1.4597  0.65300  125.16  1.8244  1.0507   \n",
       "...             ...     ...     ...     ...      ...     ...     ...     ...   \n",
       "2022-05-25   1.5126  5.1736  1.3720  1.0269  0.85295  135.34  1.4676  1.0656   \n",
       "2022-05-26   1.5110  5.1741  1.3715  1.0283  0.85073  135.95  1.4709  1.0697   \n",
       "2022-05-27   1.4995  5.0959  1.3661  1.0258  0.84875  136.05  1.4679  1.0722   \n",
       "2022-05-30   1.4982  5.0629  1.3647  1.0327  0.85150  137.25  1.4719  1.0764   \n",
       "2022-05-31   1.4933  5.0965  1.3573  1.0281  0.85138  137.36  1.4687  1.0713   \n",
       "\n",
       "             AUD_lag_1  BRL_lag_1  CAD_lag_1  CHF_lag_1  GBP_lag_1  JPY_lag_1  \\\n",
       "TIME_PERIOD                                                                     \n",
       "2003-01-03      1.8554     3.6770     1.6422     1.4528    0.65200     124.40   \n",
       "2003-01-06      1.8440     3.6112     1.6264     1.4555    0.65000     124.56   \n",
       "2003-01-07      1.8281     3.5145     1.6383     1.4563    0.64950     124.40   \n",
       "2003-01-08      1.8160     3.5139     1.6257     1.4565    0.64960     124.82   \n",
       "2003-01-09      1.8132     3.4405     1.6231     1.4586    0.64950     124.90   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "2022-05-25      1.5152     5.1793     1.3714     1.0334    0.85750     136.49   \n",
       "2022-05-26      1.5126     5.1736     1.3720     1.0269    0.85295     135.34   \n",
       "2022-05-27      1.5110     5.1741     1.3715     1.0283    0.85073     135.95   \n",
       "2022-05-30      1.4995     5.0959     1.3661     1.0258    0.84875     136.05   \n",
       "2022-05-31      1.4982     5.0629     1.3647     1.0327    0.85150     137.25   \n",
       "\n",
       "             SGD_lag_1  USD_lag_1  \n",
       "TIME_PERIOD                        \n",
       "2003-01-03      1.8188     1.0446  \n",
       "2003-01-06      1.8132     1.0392  \n",
       "2003-01-07      1.8210     1.0488  \n",
       "2003-01-08      1.8155     1.0425  \n",
       "2003-01-09      1.8102     1.0377  \n",
       "...                ...        ...  \n",
       "2022-05-25      1.4722     1.0720  \n",
       "2022-05-26      1.4676     1.0656  \n",
       "2022-05-27      1.4709     1.0697  \n",
       "2022-05-30      1.4679     1.0722  \n",
       "2022-05-31      1.4719     1.0764  \n",
       "\n",
       "[4971 rows x 16 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EUR_FX = load_EURFX_data()\n",
    "\n",
    "assert type(EUR_FX) == pd.DataFrame\n",
    "assert EUR_FX.shape[0] > 0\n",
    "assert EUR_FX.shape[1] > 0\n",
    "\n",
    "EUR_FX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv_gingado': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
