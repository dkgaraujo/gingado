{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "description: Functions to jumpstart and facilitate model documentation\n",
    "output-file: documentation.html\n",
    "title: Model documentation\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq gingado nbdev # install or upgrade gingado on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each user has a specific documentation need, ranging from simply logging the model training to a more complex description of the model pipeline with a discusson of the model outcomes. `gingado` addresses this variety of needs by offering a class of objects, \"Documenters\", that facilitate model documentation. A base class facilitates the creation of  generic ways to document models, and `gingado` includes off-the-shelf one specific model documentation template as described below. \n",
    "\n",
    "The model documentation is performed by Documenters, objects that subclass from the base class [`ggdModelDocumentation`](https://dkgaraujo.github.io/gingado/documentation.html#ggdmodeldocumentation). This base class offers code that can be used by any Documenter to read the model in question, format the information according to a template and save the resulting documentation in a JSON format. Documenters save the underlying information using the JSON format. With the JSON documentation file at hand, the user can then use existing third-party libraries to transform the information stored in JSON into a variety of formats (eg, HTML, PDF) as needed.\n",
    "\n",
    "One current area of development is the automatic filing of some fields related to the model. The objective is to automatise documentation of the information that can be fetched automatically from the model, leaving time for the analyst to concentrate on other tasks, such as considering the ethical implications of the machine learning model being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L11){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation\n",
       "\n",
       ">      ggdModelDocumentation ()\n",
       "\n",
       "Base class for gingado Documenters"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L11){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation\n",
       "\n",
       ">      ggdModelDocumentation ()\n",
       "\n",
       "Base class for gingado Documenters"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ggdModelDocumentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L14){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.setup_template\n",
       "\n",
       ">      ggdModelDocumentation.setup_template ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L14){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.setup_template\n",
       "\n",
       ">      ggdModelDocumentation.setup_template ()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ggdModelDocumentation.setup_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L20){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.show_template\n",
       "\n",
       ">      ggdModelDocumentation.show_template (indent:bool=True)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| indent | bool | True | Whether to print JSON documentation template with indentation for easier human reading |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L20){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.show_template\n",
       "\n",
       ">      ggdModelDocumentation.show_template (indent:bool=True)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| indent | bool | True | Whether to print JSON documentation template with indentation for easier human reading |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ggdModelDocumentation.show_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L30){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.documentation_path\n",
       "\n",
       ">      ggdModelDocumentation.documentation_path ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L30){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.documentation_path\n",
       "\n",
       ">      ggdModelDocumentation.documentation_path ()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ggdModelDocumentation.documentation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.read_json\n",
       "\n",
       ">      ggdModelDocumentation.read_json (file_path)\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| file_path | Path to JSON file or path defined in `file_path` if None |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.read_json\n",
       "\n",
       ">      ggdModelDocumentation.read_json (file_path)\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| file_path | Path to JSON file or path defined in `file_path` if None |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ggdModelDocumentation.read_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L94){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.read_model\n",
       "\n",
       ">      ggdModelDocumentation.read_model (model)\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| model | The model to be documented |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L94){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.read_model\n",
       "\n",
       ">      ggdModelDocumentation.read_model (model)\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| model | The model to be documented |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ggdModelDocumentation.read_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L56){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.open_questions\n",
       "\n",
       ">      ggdModelDocumentation.open_questions ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L56){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.open_questions\n",
       "\n",
       ">      ggdModelDocumentation.open_questions ()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ggdModelDocumentation.open_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L34){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.show_json\n",
       "\n",
       ">      ggdModelDocumentation.show_json ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L34){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ggdModelDocumentation.show_json\n",
       "\n",
       ">      ggdModelDocumentation.show_json ()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ggdModelDocumentation.show_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelCard\n",
    "\n",
    "[`ModelCard`](https://dkgaraujo.github.io/gingado/documentation.html#modelcard) - the model documentation template inspired by the work of @ModelCards already comes with `gingado`. Its template can be used by users as is, or tweaked according to each need. The [`ModelCard`](https://dkgaraujo.github.io/gingado/documentation.html#modelcard) template can also serve as inspiration for any custom documentation needs. Users with documentation needs beyond the out-of-the-box solutions provided by `gingado` can create their own class of Documenters (more information on that below), and compatibility with these custom documentation routines with the rest of the code is ensured. Users are encouraged to submit a pull request with their own documentation models subclassing [`ggdModelDocumentation`](https://dkgaraujo.github.io/gingado/documentation.html#ggdmodeldocumentation) if these custom templates can also benefit other users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelCard\n",
       "\n",
       ">      ModelCard (file_path='', autofill=True, indent_level=2)\n",
       "\n",
       "A gingado Documenter based on @ModelCards"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelCard\n",
       "\n",
       ">      ModelCard (file_path='', autofill=True, indent_level=2)\n",
       "\n",
       "A gingado Documenter based on @ModelCards"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ModelCard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L204){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelCard.autofill_template\n",
       "\n",
       ">      ModelCard.autofill_template ()\n",
       "\n",
       "Create an empty model card template, then fills it with information that is automatically obtained from the system"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L204){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelCard.autofill_template\n",
       "\n",
       ">      ModelCard.autofill_template ()\n",
       "\n",
       "Create an empty model card template, then fills it with information that is automatically obtained from the system"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ModelCard.autofill_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L213){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelCard.fill_model_info\n",
       "\n",
       ">      ModelCard.fill_model_info (model_info)\n",
       "\n",
       "Called automatically, or by the user, to add model information to the documentation according to its template"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/dkgaraujo/gingado/tree/main/blob/main/gingado/model_documentation.py#L213){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelCard.fill_model_info\n",
       "\n",
       ">      ModelCard.fill_model_info (model_info)\n",
       "\n",
       "Called automatically, or by the user, to add model information to the documentation according to its template"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ModelCard.fill_model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functioning of model documentation\n",
    "\n",
    "After a Documenter object, such as [`ModelCard`](https://dkgaraujo.github.io/gingado/documentation.html#modelcard) is instanciated, the user can see the underlying template with the module `show_template`, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_details\": {\n",
      "    \"field_description\": \"Basic information about the model\",\n",
      "    \"developer\": \"Person or organisation developing the model\",\n",
      "    \"datetime\": \"Model date\",\n",
      "    \"version\": \"Model version\",\n",
      "    \"type\": \"Model type\",\n",
      "    \"info\": \"Information about training algorithms, parameters, fairness constraints or other applied approaches, and features\",\n",
      "    \"paper\": \"Paper or other resource for more information\",\n",
      "    \"citation\": \"Citation details\",\n",
      "    \"license\": \"License\",\n",
      "    \"contact\": \"Where to send questions or comments about the model\"\n",
      "  },\n",
      "  \"intended_use\": {\n",
      "    \"field_description\": \"Use cases that were envisioned during development\",\n",
      "    \"primary_uses\": \"Primary intended uses\",\n",
      "    \"primary_users\": \"Primary intended users\",\n",
      "    \"out_of_scope\": \"Out-of-scope use cases\"\n",
      "  },\n",
      "  \"factors\": {\n",
      "    \"field_description\": \"Factors could include demographic or phenotypic groups, environmental conditions, technical attributes, or others\",\n",
      "    \"relevant\": \"Relevant factors\",\n",
      "    \"evaluation\": \"Evaluation factors\"\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"field_description\": \"Metrics should be chosen to reflect potential real world impacts of the model\",\n",
      "    \"performance_measures\": \"Model performance measures\",\n",
      "    \"thresholds\": \"Decision thresholds\",\n",
      "    \"variation_approaches\": \"Variation approaches\"\n",
      "  },\n",
      "  \"evaluation_data\": {\n",
      "    \"field_description\": \"Details on the dataset(s) used for the quantitative analyses in the documentation\",\n",
      "    \"datasets\": \"Datasets\",\n",
      "    \"motivation\": \"Motivation\",\n",
      "    \"preprocessing\": \"Preprocessing\"\n",
      "  },\n",
      "  \"training_data\": {\n",
      "    \"field_description\": \"\\n            May not be possible to provide in practice. When possible, this section should mirror 'Evaluation Data'. \\n            If such detail is not possible, minimal allowable information should be provided here, \\n            such as details of the distribution over various factors in the training datasets.\",\n",
      "    \"training_data\": \"Information on training data\"\n",
      "  },\n",
      "  \"quant_analyses\": {\n",
      "    \"field_description\": \"Quantitative Analyses\",\n",
      "    \"unitary\": \"Unitary results\",\n",
      "    \"intersectional\": \"Intersectional results\"\n",
      "  },\n",
      "  \"ethical_considerations\": {\n",
      "    \"field_description\": \"\\n            Ethical considerations that went into model development, surfacing ethical challenges and \\n            solutions to stakeholders. Ethical analysis does not always lead to precise solutions, but the process \\n            of ethical contemplation is worthwhile to inform on responsible practices and next steps in future work.\",\n",
      "    \"sensitive_data\": \"Does the model use any sensitive data (e.g., protected classes)?\",\n",
      "    \"human_life\": \"Is the model intended to inform decisions about mat- ters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?\",\n",
      "    \"mitigations\": \"What risk mitigation strategies were used during model development?\",\n",
      "    \"risks_and_harms\": \"\\n            What risks may be present in model usage? Try to identify the potential recipients, likelihood, and magnitude of harms. \\n            If these cannot be determined, note that they were consid- ered but remain unknown\",\n",
      "    \"use_cases\": \"Are there any known model use cases that are especially fraught?\",\n",
      "    \"additional_information\": \"\\n            If possible, this section should also include any additional ethical considerations that went into model development, \\n            for example, review by an external board, or testing with a specific community.\"\n",
      "  },\n",
      "  \"caveats_recommendations\": {\n",
      "    \"field_description\": \"Additional concerns that were not covered in the previous sections\",\n",
      "    \"caveats\": \"For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?\",\n",
      "    \"recommendations\": \"Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_doc = ModelCard(autofill=False)\n",
    "assert model_doc.show_template(indent=False) == ModelCard.template\n",
    "\n",
    "model_doc.show_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `show_json` prints the Documenter's documentation template, where the unfilled information retains the descriptions from the original template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_details': {'developer': 'Person or organisation developing the model',\n",
       "  'datetime': '2022-09-23 02:56:08 ',\n",
       "  'version': 'Model version',\n",
       "  'type': 'Model type',\n",
       "  'info': 'Information about training algorithms, parameters, fairness constraints or other applied approaches, and features',\n",
       "  'paper': 'Paper or other resource for more information',\n",
       "  'citation': 'Citation details',\n",
       "  'license': 'License',\n",
       "  'contact': 'Where to send questions or comments about the model'},\n",
       " 'intended_use': {'primary_uses': 'Primary intended uses',\n",
       "  'primary_users': 'Primary intended users',\n",
       "  'out_of_scope': 'Out-of-scope use cases'},\n",
       " 'factors': {'relevant': 'Relevant factors',\n",
       "  'evaluation': 'Evaluation factors'},\n",
       " 'metrics': {'performance_measures': 'Model performance measures',\n",
       "  'thresholds': 'Decision thresholds',\n",
       "  'variation_approaches': 'Variation approaches'},\n",
       " 'evaluation_data': {'datasets': 'Datasets',\n",
       "  'motivation': 'Motivation',\n",
       "  'preprocessing': 'Preprocessing'},\n",
       " 'training_data': {'training_data': 'Information on training data'},\n",
       " 'quant_analyses': {'unitary': 'Unitary results',\n",
       "  'intersectional': 'Intersectional results'},\n",
       " 'ethical_considerations': {'sensitive_data': 'Does the model use any sensitive data (e.g., protected classes)?',\n",
       "  'human_life': 'Is the model intended to inform decisions about mat- ters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?',\n",
       "  'mitigations': 'What risk mitigation strategies were used during model development?',\n",
       "  'risks_and_harms': '\\n            What risks may be present in model usage? Try to identify the potential recipients, likelihood, and magnitude of harms. \\n            If these cannot be determined, note that they were consid- ered but remain unknown',\n",
       "  'use_cases': 'Are there any known model use cases that are especially fraught?',\n",
       "  'additional_information': '\\n            If possible, this section should also include any additional ethical considerations that went into model development, \\n            for example, review by an external board, or testing with a specific community.'},\n",
       " 'caveats_recommendations': {'caveats': 'For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?',\n",
       "  'recommendations': 'Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc = ModelCard(autofill=True)\n",
    "model_doc.show_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template is protected from editing once a Documenter has been created. This way, even if a user unwarrantedly changes the template, this does not interfere with the Documenter functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_details\": {\n",
      "    \"field_description\": \"Basic information about the model\",\n",
      "    \"developer\": \"Person or organisation developing the model\",\n",
      "    \"datetime\": \"Model date\",\n",
      "    \"version\": \"Model version\",\n",
      "    \"type\": \"Model type\",\n",
      "    \"info\": \"Information about training algorithms, parameters, fairness constraints or other applied approaches, and features\",\n",
      "    \"paper\": \"Paper or other resource for more information\",\n",
      "    \"citation\": \"Citation details\",\n",
      "    \"license\": \"License\",\n",
      "    \"contact\": \"Where to send questions or comments about the model\"\n",
      "  },\n",
      "  \"intended_use\": {\n",
      "    \"field_description\": \"Use cases that were envisioned during development\",\n",
      "    \"primary_uses\": \"Primary intended uses\",\n",
      "    \"primary_users\": \"Primary intended users\",\n",
      "    \"out_of_scope\": \"Out-of-scope use cases\"\n",
      "  },\n",
      "  \"factors\": {\n",
      "    \"field_description\": \"Factors could include demographic or phenotypic groups, environmental conditions, technical attributes, or others\",\n",
      "    \"relevant\": \"Relevant factors\",\n",
      "    \"evaluation\": \"Evaluation factors\"\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"field_description\": \"Metrics should be chosen to reflect potential real world impacts of the model\",\n",
      "    \"performance_measures\": \"Model performance measures\",\n",
      "    \"thresholds\": \"Decision thresholds\",\n",
      "    \"variation_approaches\": \"Variation approaches\"\n",
      "  },\n",
      "  \"evaluation_data\": {\n",
      "    \"field_description\": \"Details on the dataset(s) used for the quantitative analyses in the documentation\",\n",
      "    \"datasets\": \"Datasets\",\n",
      "    \"motivation\": \"Motivation\",\n",
      "    \"preprocessing\": \"Preprocessing\"\n",
      "  },\n",
      "  \"training_data\": {\n",
      "    \"field_description\": \"\\n            May not be possible to provide in practice. When possible, this section should mirror 'Evaluation Data'. \\n            If such detail is not possible, minimal allowable information should be provided here, \\n            such as details of the distribution over various factors in the training datasets.\",\n",
      "    \"training_data\": \"Information on training data\"\n",
      "  },\n",
      "  \"quant_analyses\": {\n",
      "    \"field_description\": \"Quantitative Analyses\",\n",
      "    \"unitary\": \"Unitary results\",\n",
      "    \"intersectional\": \"Intersectional results\"\n",
      "  },\n",
      "  \"ethical_considerations\": {\n",
      "    \"field_description\": \"\\n            Ethical considerations that went into model development, surfacing ethical challenges and \\n            solutions to stakeholders. Ethical analysis does not always lead to precise solutions, but the process \\n            of ethical contemplation is worthwhile to inform on responsible practices and next steps in future work.\",\n",
      "    \"sensitive_data\": \"Does the model use any sensitive data (e.g., protected classes)?\",\n",
      "    \"human_life\": \"Is the model intended to inform decisions about mat- ters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?\",\n",
      "    \"mitigations\": \"What risk mitigation strategies were used during model development?\",\n",
      "    \"risks_and_harms\": \"\\n            What risks may be present in model usage? Try to identify the potential recipients, likelihood, and magnitude of harms. \\n            If these cannot be determined, note that they were consid- ered but remain unknown\",\n",
      "    \"use_cases\": \"Are there any known model use cases that are especially fraught?\",\n",
      "    \"additional_information\": \"\\n            If possible, this section should also include any additional ethical considerations that went into model development, \\n            for example, review by an external board, or testing with a specific community.\"\n",
      "  },\n",
      "  \"caveats_recommendations\": {\n",
      "    \"field_description\": \"Additional concerns that were not covered in the previous sections\",\n",
      "    \"caveats\": \"For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?\",\n",
      "    \"recommendations\": \"Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_doc.template = None\n",
    "model_doc.show_template()\n",
    "\n",
    "assert model_doc.show_template(indent=False) == ModelCard.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can find which fields in their templates are still without response by using the module `open_questions`. The levels of the template are reflected in the resulting dictionary, with double underscores separating the different dictionary levels in the underlying template.\n",
    "\n",
    "Below we see that after inputting information for the item `caveats` in the section `caveats_recommendations`, this item does not appear in the results of the `open_questions` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caveats_recommendations__recommendations']\n"
     ]
    }
   ],
   "source": [
    "model_doc.fill_info({'caveats_recommendations': {'caveats': 'This is another test'}})\n",
    "assert model_doc.json_doc['caveats_recommendations']['caveats'] == \"This is another test\"\n",
    "\n",
    "# note that caveats_recommendations__caveats is no longer considered an open question\n",
    "# after being filled in through `fill_info`.\n",
    "print([oq for oq in model_doc.open_questions() if oq.startswith('caveats')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the complete result of the `open_questions` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_details__developer',\n",
       " 'model_details__version',\n",
       " 'model_details__type',\n",
       " 'model_details__info',\n",
       " 'model_details__paper',\n",
       " 'model_details__citation',\n",
       " 'model_details__license',\n",
       " 'model_details__contact',\n",
       " 'intended_use__primary_uses',\n",
       " 'intended_use__primary_users',\n",
       " 'intended_use__out_of_scope',\n",
       " 'factors__relevant',\n",
       " 'factors__evaluation',\n",
       " 'metrics__performance_measures',\n",
       " 'metrics__thresholds',\n",
       " 'metrics__variation_approaches',\n",
       " 'evaluation_data__datasets',\n",
       " 'evaluation_data__motivation',\n",
       " 'evaluation_data__preprocessing',\n",
       " 'training_data__training_data',\n",
       " 'quant_analyses__unitary',\n",
       " 'quant_analyses__intersectional',\n",
       " 'ethical_considerations__sensitive_data',\n",
       " 'ethical_considerations__human_life',\n",
       " 'ethical_considerations__mitigations',\n",
       " 'ethical_considerations__risks_and_harms',\n",
       " 'ethical_considerations__use_cases',\n",
       " 'ethical_considerations__additional_information',\n",
       " 'caveats_recommendations__recommendations']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc.open_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user wants to fill in an empty field such as the ones identified above by the method `open_questions`, the user simply needs to pass to the module `fill_info` a dictionary with the corresponding information. Depending on the template, the dictionary may be nested. \n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "it is technically possible to attribute the element directly to the attribute `json_doc`, but this should be avoided in favour of using the method `fill_info`. The latter tests whether the new information is valid according to the documentation template and also enables the filling of more than one question at the same time. In addition, attributing information directly to `json_doc` is not logged, and may unwarrantedly create new entries that are not part of the template (eg, if a new dictionary key is created due to typos).\n",
    "\n",
    ":::\n",
    "\n",
    "The template serves to provide specific instances of the Documenter object with a form-like structure, indicating which fields are open and thus require some answers or information. Consequently, the template does not change when the actual document object changes after information is added by `fill_info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'performance_measures': 'This is a test', 'thresholds': 'Decision thresholds', 'variation_approaches': 'Variation approaches'}, {'field_description': 'Metrics should be chosen to reflect potential real world impacts of the model', 'performance_measures': 'Model performance measures', 'thresholds': 'Decision thresholds', 'variation_approaches': 'Variation approaches'}]\n"
     ]
    }
   ],
   "source": [
    "new_info = {\n",
    "    'metrics': {'performance_measures': \"This is a test\"},\n",
    "    'caveats_recommendations': {'caveats': \"This is another test\"}\n",
    "    }\n",
    "\n",
    "model_doc.fill_info(new_info)\n",
    "print([model_doc.json_doc['metrics'], ModelCard.template['metrics']])\n",
    "\n",
    "assert model_doc.show_template(indent=False) == ModelCard.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading information from models\n",
    "\n",
    "`gingado`'s [`ggdModelDocumentation`](https://dkgaraujo.github.io/gingado/documentation.html#ggdmodeldocumentation) base class is able to extract information from machine learning models from a number of widely used libraries and make it available to the Documenter objects. This is done through the method `read_model`, which recognises whether the model is a `gingado` object or any of `scikit-learn`, `keras`, or `fastai` models and read the model characteristics appropriately. For filing out information from other models (eg, `pytorch` or even models coded from scratch, machine learning or not), the user can benefit from the module `fill_model_info` that every Documenter should have, as demonstrated below.\n",
    "\n",
    "In the case of [`ModelCard`](https://dkgaraujo.github.io/gingado/documentation.html#modelcard), these informations are included under `model_details`, item `info`. But the model information could be saved in another area of a custom Documenter.\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "the model-specific information saved is different depending on the model's original library.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "The mock dataset below is used to construct models using different libraries, to demonstrate how they are read by Documenters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 20), (100,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some mock up data\n",
    "X, y = make_classification()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gingado Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from gingado.benchmark import ClassificationBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=100;, score=0.850 total time=   0.1s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=100;, score=0.900 total time=   0.1s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=100;, score=0.900 total time=   0.1s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=100;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=250;, score=0.850 total time=   0.3s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=250;, score=0.900 total time=   0.3s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=250;, score=1.000 total time=   0.3s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=250;, score=0.800 total time=   0.3s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=250;, score=0.950 total time=   0.3s\n",
      "[CV 1/5] END max_features=log2, n_estimators=100;, score=0.850 total time=   0.1s\n",
      "[CV 2/5] END max_features=log2, n_estimators=100;, score=0.900 total time=   0.1s\n",
      "[CV 3/5] END max_features=log2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END max_features=log2, n_estimators=100;, score=0.800 total time=   0.1s\n",
      "[CV 5/5] END max_features=log2, n_estimators=100;, score=0.900 total time=   0.1s\n",
      "[CV 1/5] END max_features=log2, n_estimators=250;, score=0.900 total time=   0.3s\n",
      "[CV 2/5] END max_features=log2, n_estimators=250;, score=0.900 total time=   0.3s\n",
      "[CV 3/5] END max_features=log2, n_estimators=250;, score=1.000 total time=   0.3s\n",
      "[CV 4/5] END max_features=log2, n_estimators=250;, score=0.800 total time=   0.3s\n",
      "[CV 5/5] END max_features=log2, n_estimators=250;, score=0.950 total time=   0.3s\n",
      "[CV 1/5] END max_features=None, n_estimators=100;, score=0.850 total time=   0.1s\n",
      "[CV 2/5] END max_features=None, n_estimators=100;, score=0.850 total time=   0.1s\n",
      "[CV 3/5] END max_features=None, n_estimators=100;, score=0.900 total time=   0.1s\n",
      "[CV 4/5] END max_features=None, n_estimators=100;, score=0.900 total time=   0.1s\n",
      "[CV 5/5] END max_features=None, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END max_features=None, n_estimators=250;, score=0.850 total time=   0.3s\n",
      "[CV 2/5] END max_features=None, n_estimators=250;, score=0.850 total time=   0.3s\n",
      "[CV 3/5] END max_features=None, n_estimators=250;, score=0.900 total time=   0.3s\n",
      "[CV 4/5] END max_features=None, n_estimators=250;, score=0.850 total time=   0.3s\n",
      "[CV 5/5] END max_features=None, n_estimators=250;, score=1.000 total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "# the gingado benchmark\n",
    "gingado_clf = ClassificationBenchmark(verbose_grid=3).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_estimator_type': 'classifier', 'best_estimator_': RandomForestClassifier(max_features='sqrt', oob_score=True), 'best_index_': 0, 'best_params_': {'max_features': 'sqrt', 'n_estimators': 100}, 'best_score_': 0.9199999999999999, 'classes_': array([0, 1]), 'cv_results_': {'mean_fit_time': array([0.11530619, 0.26669745, 0.10973477, 0.26454501, 0.11575832,\n",
      "       0.28983746]), 'std_fit_time': array([0.00816642, 0.00363007, 0.00559109, 0.00181147, 0.00117145,\n",
      "       0.00829226]), 'mean_score_time': array([0.00746517, 0.01749239, 0.00705872, 0.01709967, 0.00695467,\n",
      "       0.01724391]), 'std_score_time': array([0.00076493, 0.00029243, 0.00026981, 0.0002537 , 0.00014866,\n",
      "       0.0001914 ]), 'param_max_features': masked_array(data=['sqrt', 'sqrt', 'log2', 'log2', None, None],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[100, 250, 100, 250, 100, 250],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_features': 'sqrt', 'n_estimators': 100}, {'max_features': 'sqrt', 'n_estimators': 250}, {'max_features': 'log2', 'n_estimators': 100}, {'max_features': 'log2', 'n_estimators': 250}, {'max_features': None, 'n_estimators': 100}, {'max_features': None, 'n_estimators': 250}], 'split0_test_score': array([0.85, 0.85, 0.85, 0.9 , 0.85, 0.85]), 'split1_test_score': array([0.9 , 0.9 , 0.9 , 0.9 , 0.85, 0.85]), 'split2_test_score': array([1. , 1. , 1. , 1. , 0.9, 0.9]), 'split3_test_score': array([0.9 , 0.8 , 0.8 , 0.8 , 0.9 , 0.85]), 'split4_test_score': array([0.95, 0.95, 0.9 , 0.95, 1.  , 1.  ]), 'mean_test_score': array([0.92, 0.9 , 0.89, 0.91, 0.9 , 0.89]), 'std_test_score': array([0.0509902 , 0.07071068, 0.0663325 , 0.0663325 , 0.05477226,\n",
      "       0.05830952]), 'rank_test_score': array([1, 3, 5, 2, 3, 5], dtype=int32)}, 'multimetric_': False, 'n_features_in_': 20, 'n_splits_': 5, 'refit_time_': 0.11097598075866699, 'scorer_': <function _passthrough_scorer>}\n"
     ]
    }
   ],
   "source": [
    "# a new instance of ModelCard is created and used to document the model\n",
    "model_doc_gingado = ModelCard()\n",
    "model_doc_gingado.read_model(gingado_clf.benchmark)\n",
    "print(model_doc_gingado.show_json()['model_details']['info'])\n",
    "\n",
    "# but given that gingado Benchmark objects already document the best model at every fit, we can check that they are equal:\n",
    "assert model_doc_gingado.show_json()['model_details']['info'] == gingado_clf.model_documentation.show_json()['model_details']['info']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "sklearn_clf = RandomForestClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_estimator_type': 'classifier', 'base_estimator_': DecisionTreeClassifier(), 'classes_': array([0, 1]), 'estimators_': [DecisionTreeClassifier(max_features='auto', random_state=173596357), DecisionTreeClassifier(max_features='auto', random_state=974586197), DecisionTreeClassifier(max_features='auto', random_state=1542220764), DecisionTreeClassifier(max_features='auto', random_state=8146903), DecisionTreeClassifier(max_features='auto', random_state=1143882836), DecisionTreeClassifier(max_features='auto', random_state=2139604217), DecisionTreeClassifier(max_features='auto', random_state=1341427065), DecisionTreeClassifier(max_features='auto', random_state=601504425), DecisionTreeClassifier(max_features='auto', random_state=875071171), DecisionTreeClassifier(max_features='auto', random_state=1929879648), DecisionTreeClassifier(max_features='auto', random_state=486033255), DecisionTreeClassifier(max_features='auto', random_state=284697411), DecisionTreeClassifier(max_features='auto', random_state=351574817), DecisionTreeClassifier(max_features='auto', random_state=890289032), DecisionTreeClassifier(max_features='auto', random_state=1374488249), DecisionTreeClassifier(max_features='auto', random_state=1268513819), DecisionTreeClassifier(max_features='auto', random_state=658592591), DecisionTreeClassifier(max_features='auto', random_state=2143092380), DecisionTreeClassifier(max_features='auto', random_state=772558508), DecisionTreeClassifier(max_features='auto', random_state=668770970), DecisionTreeClassifier(max_features='auto', random_state=1483050477), DecisionTreeClassifier(max_features='auto', random_state=1094484638), DecisionTreeClassifier(max_features='auto', random_state=1195425646), DecisionTreeClassifier(max_features='auto', random_state=1015021909), DecisionTreeClassifier(max_features='auto', random_state=1010668444), DecisionTreeClassifier(max_features='auto', random_state=1537516026), DecisionTreeClassifier(max_features='auto', random_state=1559474517), DecisionTreeClassifier(max_features='auto', random_state=2061956866), DecisionTreeClassifier(max_features='auto', random_state=1754020851), DecisionTreeClassifier(max_features='auto', random_state=614486474), DecisionTreeClassifier(max_features='auto', random_state=39570575), DecisionTreeClassifier(max_features='auto', random_state=71940600), DecisionTreeClassifier(max_features='auto', random_state=1657173672), DecisionTreeClassifier(max_features='auto', random_state=507650522), DecisionTreeClassifier(max_features='auto', random_state=1311088245), DecisionTreeClassifier(max_features='auto', random_state=141665083), DecisionTreeClassifier(max_features='auto', random_state=946822783), DecisionTreeClassifier(max_features='auto', random_state=1814700172), DecisionTreeClassifier(max_features='auto', random_state=286684935), DecisionTreeClassifier(max_features='auto', random_state=1040004677), DecisionTreeClassifier(max_features='auto', random_state=1122531694), DecisionTreeClassifier(max_features='auto', random_state=827010650), DecisionTreeClassifier(max_features='auto', random_state=1951808088), DecisionTreeClassifier(max_features='auto', random_state=1995096298), DecisionTreeClassifier(max_features='auto', random_state=2038676946), DecisionTreeClassifier(max_features='auto', random_state=22413878), DecisionTreeClassifier(max_features='auto', random_state=2112793915), DecisionTreeClassifier(max_features='auto', random_state=692412469), DecisionTreeClassifier(max_features='auto', random_state=1425528153), DecisionTreeClassifier(max_features='auto', random_state=1686359906), DecisionTreeClassifier(max_features='auto', random_state=724589573), DecisionTreeClassifier(max_features='auto', random_state=1406613531), DecisionTreeClassifier(max_features='auto', random_state=883018111), DecisionTreeClassifier(max_features='auto', random_state=958775585), DecisionTreeClassifier(max_features='auto', random_state=2132938332), DecisionTreeClassifier(max_features='auto', random_state=1453129603), DecisionTreeClassifier(max_features='auto', random_state=910901248), DecisionTreeClassifier(max_features='auto', random_state=269661217), DecisionTreeClassifier(max_features='auto', random_state=509249946), DecisionTreeClassifier(max_features='auto', random_state=901286902), DecisionTreeClassifier(max_features='auto', random_state=2137307343), DecisionTreeClassifier(max_features='auto', random_state=781639208), DecisionTreeClassifier(max_features='auto', random_state=167972170), DecisionTreeClassifier(max_features='auto', random_state=1158331214), DecisionTreeClassifier(max_features='auto', random_state=968827987), DecisionTreeClassifier(max_features='auto', random_state=681311447), DecisionTreeClassifier(max_features='auto', random_state=1863408699), DecisionTreeClassifier(max_features='auto', random_state=1628526736), DecisionTreeClassifier(max_features='auto', random_state=862205030), DecisionTreeClassifier(max_features='auto', random_state=845880395), DecisionTreeClassifier(max_features='auto', random_state=775674653), DecisionTreeClassifier(max_features='auto', random_state=1206801964), DecisionTreeClassifier(max_features='auto', random_state=1985980154), DecisionTreeClassifier(max_features='auto', random_state=1582392325), DecisionTreeClassifier(max_features='auto', random_state=606462288), DecisionTreeClassifier(max_features='auto', random_state=749371568), DecisionTreeClassifier(max_features='auto', random_state=85340676), DecisionTreeClassifier(max_features='auto', random_state=1946025612), DecisionTreeClassifier(max_features='auto', random_state=1258704830), DecisionTreeClassifier(max_features='auto', random_state=1975057532), DecisionTreeClassifier(max_features='auto', random_state=1081816487), DecisionTreeClassifier(max_features='auto', random_state=2102681341), DecisionTreeClassifier(max_features='auto', random_state=1897214164), DecisionTreeClassifier(max_features='auto', random_state=1350443029), DecisionTreeClassifier(max_features='auto', random_state=1544206909), DecisionTreeClassifier(max_features='auto', random_state=1454672133), DecisionTreeClassifier(max_features='auto', random_state=488123032), DecisionTreeClassifier(max_features='auto', random_state=1628722655), DecisionTreeClassifier(max_features='auto', random_state=1184804476), DecisionTreeClassifier(max_features='auto', random_state=1928022240), DecisionTreeClassifier(max_features='auto', random_state=980876561), DecisionTreeClassifier(max_features='auto', random_state=1615486472), DecisionTreeClassifier(max_features='auto', random_state=1149193670), DecisionTreeClassifier(max_features='auto', random_state=1824674932), DecisionTreeClassifier(max_features='auto', random_state=2087800437), DecisionTreeClassifier(max_features='auto', random_state=1977518943), DecisionTreeClassifier(max_features='auto', random_state=1983451040), DecisionTreeClassifier(max_features='auto', random_state=1427074871), DecisionTreeClassifier(max_features='auto', random_state=1652725834), DecisionTreeClassifier(max_features='auto', random_state=1025768522)], 'feature_importances_': array([0.01408221, 0.01363864, 0.01926392, 0.01986321, 0.01946962,\n",
      "       0.03808936, 0.03184404, 0.01927115, 0.30943989, 0.01722208,\n",
      "       0.01649191, 0.01931377, 0.0153458 , 0.03250955, 0.08696418,\n",
      "       0.21158095, 0.02497851, 0.01903849, 0.02917825, 0.04241445]), 'n_classes_': 2, 'n_features_': 20, 'n_features_in_': 20, 'n_outputs_': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/douglasaraujo/Coding/.venv_gingado/lib/python3.10/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `n_features_` was deprecated in version 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_doc_sklearn = ModelCard()\n",
    "model_doc_sklearn.read_model(sklearn_clf)\n",
    "print(model_doc_sklearn.show_json()['model_details']['info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 879us/step - loss: 0.6672\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 764us/step - loss: 0.6629\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 737us/step - loss: 0.6588\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 774us/step - loss: 0.6539\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 767us/step - loss: 0.6489\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 746us/step - loss: 0.6435\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 728us/step - loss: 0.6381\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 741us/step - loss: 0.6327\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 710us/step - loss: 0.6271\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 700us/step - loss: 0.6215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_clf = keras.Sequential()\n",
    "keras_clf.add(keras.layers.Dense(16, activation='relu', input_shape=(20,)))\n",
    "keras_clf.add(keras.layers.Dense(8, activation='relu'))\n",
    "keras_clf.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "keras_clf.compile(optimizer='sgd', loss='binary_crossentropy')\n",
    "keras_clf.fit(X, y, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 20], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_3_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"batch_input_shape\": [null, 20], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 8, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.8.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc_keras = ModelCard()\n",
    "model_doc_keras.read_model(keras_clf)\n",
    "model_doc_keras.show_json()['model_details']['info']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other models\n",
    "\n",
    "Native support for automatic documentation of other model types, such as from `fastai`, `pytorch` is expected to be available in future versions. Until then, these models,any models coded form scratch by the user as well as any other model can be documented by passing the information as an argument to the Documenter's `fill_model_info` method. This can be done in any core Python format (a string, a list, a dictionary, etc). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class MockDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.len = self.X.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class PytorchNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PytorchNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(20, 16)\n",
    "        self.layer2 = torch.nn.Linear(16, 8)\n",
    "        self.layer3 = torch.nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "pytorch_clf = PytorchNet()\n",
    "\n",
    "dataloader = MockDataset(X, y)\n",
    "\n",
    "\n",
    "loss_func = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(pytorch_clf.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        _X, _y = data\n",
    "        optimizer.zero_grad()\n",
    "        y_pred_epoch = pytorch_clf(_X)\n",
    "        loss = loss_func(y_pred_epoch, _y.reshape(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This model is a neural network consisting of two fully connected layers and ending in a linear layer with a sigmoid activation'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc_pytorch = ModelCard()\n",
    "model_doc_pytorch.fill_model_info(\"This model is a neural network consisting of two fully connected layers and ending in a linear layer with a sigmoid activation\")\n",
    "model_doc_pytorch.show_json()['model_details']['info']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a custom Documenter\n",
    "\n",
    "`gingado` users can easily transform their model documentation needs into a Documenter object. The main advantages of doing this are: \n",
    "* the documentation template becomes a \"recyclable\" object that can be saved, loaded, and used in other models or code routines; and\n",
    "* model documentation can be more closely aligned with model creation and training, thus decreasing the probability that the model and its documentation diverge during the process of model development.\n",
    "\n",
    "The requirements for an object to be a `gingado` Documenter are:\n",
    "* it must subclass [`ggdModelDocumentation`](https://dkgaraujo.github.io/gingado/documentation.html#ggdmodeldocumentation) (or implement all its methods if the user does not want to keep a dependency to `gingado`),\n",
    "* include the actual template for the documentation as a dictionary (with at most two levels of keys) in a class attribute called `template`,\n",
    "* follow the `scikit-learn` convention of storing the `__init__` parameters in attributes with the same name,\n",
    "* implement the `autofill_template` method using the `fill_info` method to set the automatically filled information fields, and\n",
    "* implement the `fill_model_info` method that assigns the information in `model_info` into the class custom template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "::: {#refs}\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv_gingado': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
