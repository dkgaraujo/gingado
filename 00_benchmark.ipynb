{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic benchmark model\n",
    "> Functions to create a relevant, fast and reasonably well-performing benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Benchmark object has a similar API to a `sciki-learn` estimator: you build an instance with the desired arguments, and fit it to the data at a later moment.\n",
    "\n",
    "Benchmarks is a convenience wrapper for reading the training data, passing it through a simplified pipeline consisting of data imputation and a standard scalar, and then the benchmark function calibrated with a grid search.\n",
    "\n",
    "A `gingado` Benchmark comprises the following steps, all glued together:\n",
    "* split the dataset into a training and a test datasets\n",
    "* a `Pipeline` consisting of a missing data imputation step and a random forest estimator\n",
    "* a grid search object that tunes the parameters of the random forest\n",
    "* a `compare` method that helps users evaluate if their model is better than the benchmark\n",
    "\n",
    "In addition to the estimator methods that a Benchmark object has by virtue of itself being an estimator, these objects also have a `compare` method, which takes as argument another fitted estimator (which could be itself a solo estimator or a whole pipeline) or a list of fitted estimators. \n",
    "\n",
    "Benchmarks start with default values, but the user is also free to choose any of the benchmark's components by passing as arguments the data split, pipeline, a dictionary of parameters for the hyperparameter tuning, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.metaestimators import available_if\n",
    "#from gingado.model_documentation import ModelCard\n",
    "\n",
    "class ModelCard:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "def _benchmark_has(attr):\n",
    "        def check(self):\n",
    "            getattr(self.benchmark, attr)\n",
    "            return True\n",
    "        return check\n",
    "        \n",
    "class ggdBenchmark:\n",
    "    \"\"\"\n",
    "    The base class for gingado's Benchmark objects.\n",
    "    \"\"\"\n",
    "    def _check_is_time_series(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Checks whether the data is a time series, and sets a data splitter\n",
    "        accordingly if no data splitter is provided by the user\n",
    "        Note: all data without an index (eg, a Numpy array) are considered to NOT be a time series\n",
    "        \"\"\"\n",
    "        if hasattr(X, \"index\"):\n",
    "            self.is_timeseries = pd.core.dtypes.common.is_datetime_or_timedelta_dtype(X.index)\n",
    "        else:\n",
    "            self.is_timeseries = False\n",
    "        if self.is_timeseries and y:\n",
    "            if hasattr(y, \"index\"):\n",
    "                self.is_timeseries = pd.core.dtypes.common.is_datetime_or_timedelta_dtype(y.index)\n",
    "            else:\n",
    "                self.is_timeseries = False\n",
    "\n",
    "        if self.cv is None:\n",
    "            self.cv = TimeSeriesSplit() if self.is_timeseries else StratifiedShuffleSplit()\n",
    "\n",
    "    def _creates_estimator(self):\n",
    "        if self.estimator is None:\n",
    "            pass\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        self._check_is_time_series(X, y)\n",
    "\n",
    "        X, y = self._validate_data(X, y)\n",
    "\n",
    "        if self.param_search and self.param_grid:                \n",
    "            self.benchmark = self.param_search(estimator=self.estimator, param_grid=self.param_grid, scoring=self.scoring)\n",
    "            self.benchmark.fit(X, y)\n",
    "\n",
    "        if self.auto_document:\n",
    "            self.document()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def set_benchmark(self, estimator):\n",
    "        self.benchmark = estimator\n",
    "\n",
    "    def compare(self, X, candidate):\n",
    "        \"\"\"\n",
    "        Uses a test dataset to compare the performance of the fitted benchmark model with one or more candidate models\n",
    "        This method achieves this by conducting a grid search \n",
    "        \"\"\"\n",
    "        # Step 1: create a param_grid *list* where the first item is the current benchmark,\n",
    "        # ... the other elements are the candidate model(s), and the final model is an ensemble\n",
    "        # ... of all the previous models (including the benchmark), with uniform weights (1/N)\n",
    "\n",
    "        # Step 2: Evaluate them using the same CV as strategy as defined in self.cv and select the best model\n",
    "\n",
    "        # Step 3: The best model (or the ensemble) is now the current benchmark\n",
    "        pass\n",
    "\n",
    "    def document(self):\n",
    "        pass\n",
    "\n",
    "    @available_if(_benchmark_has(\"predict\"))\n",
    "    def predict(self, X, **predict_params):\n",
    "        return self.benchmark.predict(X, **predict_params)\n",
    "\n",
    "    @available_if(_benchmark_has(\"fit_predict\"))\n",
    "    def fit_predict(self, X, y=None, **predict_params):\n",
    "        return self.benchmark.fit_predict(X, y, **predict_params)\n",
    "\n",
    "    @available_if(_benchmark_has(\"predict_proba\"))\n",
    "    def predict_proba(self, X, **predict_proba_params):\n",
    "        return self.benchmark.predict_proba(X, **predict_proba_params)\n",
    "\n",
    "    @available_if(_benchmark_has(\"decision_function\"))\n",
    "    def decision_function(self, X):\n",
    "        return self.benchmark.decision_function(X)\n",
    "    \n",
    "    @available_if(_benchmark_has(\"decision_function\"))\n",
    "    def decision_function(self, X):\n",
    "        return self.benchmark.decision_function(X)\n",
    "\n",
    "    @available_if(_benchmark_has(\"score_samples\"))\n",
    "    def score_samples(self, X):\n",
    "        return self.benchmark.score_samples(X)\n",
    "\n",
    "    @available_if(_benchmark_has(\"predict_log_proba\"))\n",
    "    def predict_log_proba(self, X, **predict_log_proba_params):\n",
    "        return self.benchmark.predict_log_proba(X, **predict_log_proba_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_doc(Benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification tasks\n",
    "\n",
    "The default benchmark for classification tasks is a [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) object. Its parameters are fine-tuned in each case according to the user's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class ClassificationBenchmark(ggdBenchmark):\n",
    "    def __init__(self, cv=None, estimator=RandomForestClassifier(), param_grid=None, param_search=GridSearchCV, scoring=None, auto_document=ModelCard()):\n",
    "        self.cv = cv\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.param_search = param_search\n",
    "        self.scoring = scoring\n",
    "        self.auto_document = auto_document\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._fit(X, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_doc(ClassificationBenchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression tasks\n",
    "\n",
    "The default benchmark for regression tasks is a [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) object.  Its parameters are fine-tuned in each case according to the user's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "class RegressionBenchmark(ggdBenchmark):\n",
    "    def __init__(self, cv=None, estimator=RandomForestRegressor(), param_search=GridSearchCV, param_grid=None, scoring=None, auto_document=ModelCard()):\n",
    "        self.cv = cv\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.param_search = param_search\n",
    "        self.scoring = scoring\n",
    "        self.auto_document = auto_document\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._fit(X, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also simple to define as benchmark a model that you already fitted and still benefit from the other functionalities provided by `Benchmark` class. This can also be done in case you are using a saved version of a fitted model (eg, the model you are using in production) and want to have that as the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from gingado.benchmark import RegressionBenchmark\n",
    "\n",
    "forest = RandomForestRegressor().fit(X, y)\n",
    "\n",
    "bm = RegressionBenchmark()\n",
    "bm.set_benchmark(estimator=forest)\n",
    "\n",
    "assert forest == bm.benchmark\n",
    "assert hasattr(bm.benchmark, \"predict\")\n",
    "# note that now the `bm` object can be used as the estimator: \n",
    "assert bm.predict(X).shape == y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split\n",
    "\n",
    "Please refer to [this page](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) for more information on the different `Splitter` classes available on `scikit-learn`, and [this page](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py) for practical advice on how to choose a splitter for data that are not time series. Any one of these objects (or a custom splitter that is compatible with them) can be passed to a `Benchmark` object.\n",
    "\n",
    "The API does not accept custom parameters for the splitters. USers that wish to use specific parameters should include the actual `Splitter` object as the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseEstimator.get_params() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/douglasaraujo/Coding/gingado/00_benchmark.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/douglasaraujo/Coding/gingado/00_benchmark.ipynb#ch0000020?line=0'>1</a>\u001b[0m bm\u001b[39m.\u001b[39;49mget_params()\n",
      "File \u001b[0;32m~/Coding/.venv_gingado/lib/python3.10/site-packages/sklearn/base.py:212\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/douglasaraujo/Coding/.venv_gingado/lib/python3.10/site-packages/sklearn/base.py?line=209'>210</a>\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, key)\n\u001b[1;32m    <a href='file:///Users/douglasaraujo/Coding/.venv_gingado/lib/python3.10/site-packages/sklearn/base.py?line=210'>211</a>\u001b[0m \u001b[39mif\u001b[39;00m deep \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///Users/douglasaraujo/Coding/.venv_gingado/lib/python3.10/site-packages/sklearn/base.py?line=211'>212</a>\u001b[0m     deep_items \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mget_params()\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    <a href='file:///Users/douglasaraujo/Coding/.venv_gingado/lib/python3.10/site-packages/sklearn/base.py?line=212'>213</a>\u001b[0m     out\u001b[39m.\u001b[39mupdate((key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m k, val) \u001b[39mfor\u001b[39;00m k, val \u001b[39min\u001b[39;00m deep_items)\n\u001b[1;32m    <a href='file:///Users/douglasaraujo/Coding/.venv_gingado/lib/python3.10/site-packages/sklearn/base.py?line=213'>214</a>\u001b[0m out[key] \u001b[39m=\u001b[39m value\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseEstimator.get_params() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "bm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "p = Pipeline([('scaler', StandardScaler), ('clf', RandomForestClassifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler', sklearn.preprocessing._data.StandardScaler),\n",
       " ('clf', sklearn.ensemble._forest.RandomForestClassifier)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.utils import load_EURFX_data\n",
    "X = load_EURFX_data()\n",
    "y = X.pop('BRL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CURRENCY</th>\n",
       "      <th>AUD</th>\n",
       "      <th>CAD</th>\n",
       "      <th>CHF</th>\n",
       "      <th>GBP</th>\n",
       "      <th>JPY</th>\n",
       "      <th>SGD</th>\n",
       "      <th>USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-02</th>\n",
       "      <td>1.8554</td>\n",
       "      <td>1.6422</td>\n",
       "      <td>1.4528</td>\n",
       "      <td>0.65200</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8188</td>\n",
       "      <td>1.0446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>1.8440</td>\n",
       "      <td>1.6264</td>\n",
       "      <td>1.4555</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>124.56</td>\n",
       "      <td>1.8132</td>\n",
       "      <td>1.0392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>1.8281</td>\n",
       "      <td>1.6383</td>\n",
       "      <td>1.4563</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.40</td>\n",
       "      <td>1.8210</td>\n",
       "      <td>1.0488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>1.8160</td>\n",
       "      <td>1.6257</td>\n",
       "      <td>1.4565</td>\n",
       "      <td>0.64960</td>\n",
       "      <td>124.82</td>\n",
       "      <td>1.8155</td>\n",
       "      <td>1.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>1.8132</td>\n",
       "      <td>1.6231</td>\n",
       "      <td>1.4586</td>\n",
       "      <td>0.64950</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1.8102</td>\n",
       "      <td>1.0377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-19</th>\n",
       "      <td>1.5036</td>\n",
       "      <td>1.3490</td>\n",
       "      <td>1.0265</td>\n",
       "      <td>0.84728</td>\n",
       "      <td>134.46</td>\n",
       "      <td>1.4576</td>\n",
       "      <td>1.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-20</th>\n",
       "      <td>1.4980</td>\n",
       "      <td>1.3526</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>0.84820</td>\n",
       "      <td>135.34</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>1.0577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23</th>\n",
       "      <td>1.4982</td>\n",
       "      <td>1.3626</td>\n",
       "      <td>1.0310</td>\n",
       "      <td>0.84783</td>\n",
       "      <td>136.05</td>\n",
       "      <td>1.4639</td>\n",
       "      <td>1.0659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-24</th>\n",
       "      <td>1.5152</td>\n",
       "      <td>1.3714</td>\n",
       "      <td>1.0334</td>\n",
       "      <td>0.85750</td>\n",
       "      <td>136.49</td>\n",
       "      <td>1.4722</td>\n",
       "      <td>1.0720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>1.5126</td>\n",
       "      <td>1.3720</td>\n",
       "      <td>1.0269</td>\n",
       "      <td>0.85295</td>\n",
       "      <td>135.34</td>\n",
       "      <td>1.4676</td>\n",
       "      <td>1.0656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4968 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "CURRENCY        AUD     CAD     CHF      GBP     JPY     SGD     USD\n",
       "TIME_PERIOD                                                         \n",
       "2003-01-02   1.8554  1.6422  1.4528  0.65200  124.40  1.8188  1.0446\n",
       "2003-01-03   1.8440  1.6264  1.4555  0.65000  124.56  1.8132  1.0392\n",
       "2003-01-06   1.8281  1.6383  1.4563  0.64950  124.40  1.8210  1.0488\n",
       "2003-01-07   1.8160  1.6257  1.4565  0.64960  124.82  1.8155  1.0425\n",
       "2003-01-08   1.8132  1.6231  1.4586  0.64950  124.90  1.8102  1.0377\n",
       "...             ...     ...     ...      ...     ...     ...     ...\n",
       "2022-05-19   1.5036  1.3490  1.0265  0.84728  134.46  1.4576  1.0525\n",
       "2022-05-20   1.4980  1.3526  1.0280  0.84820  135.34  1.4588  1.0577\n",
       "2022-05-23   1.4982  1.3626  1.0310  0.84783  136.05  1.4639  1.0659\n",
       "2022-05-24   1.5152  1.3714  1.0334  0.85750  136.49  1.4722  1.0720\n",
       "2022-05-25   1.5126  1.3720  1.0269  0.85295  135.34  1.4676  1.0656\n",
       "\n",
       "[4968 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom benchmarks\n",
    "\n",
    "`gingado` provides users with two `Benchmark` objects out of the box: `ClassificationBenchmark` and `RegressionBenchmark`, to be used depending on the task at hand. Both classes derive from a base class `ggdBenchmark`, which implements methods that facilitate model comparison. Users that want to create a customised benchmark model for themselves have two options:\n",
    "\n",
    "* the simpler possibility is to train the estimator as usual, and then assign the fitted estimator to a `Benchmark` object. \n",
    "* if the user wants more control over the fitting process of estimating the benchmark, they can create a class that subclasses from `ggdBenchmark` and either implements custom `fit`, `predict` and `score` methods, or also subclasses from [`scikit-learn`'s `BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html). \n",
    "  * In any case, if the user wants the benchmark to automatically detect if the data is a time series and also to document the model right after fitting, the `fit` method should call `self._fit` on the data. Otherwise, the user can simply implement any consistent logic in fit as the user sees fit (pun intended).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv_gingado': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
